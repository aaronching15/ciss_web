# -*- encoding:"utf-8"-*-
__author__ = " ruoyu.Cheng"

'''
===============================================
Function: realize active benchmark functions
åŠŸèƒ½ï¼šå®ç°ä¸»åŠ¨åŸºå‡†çš„å®ä¾‹æµ‹è¯•ã€‚
last update 181018 | since 181018
Menu :
1,2012-2018å¹´ï¼ŒæŠ“å» 5-31ï¼Œ11-30 çš„ä¸‰ä¸ªæŒ‡æ•°æˆä»½è‚¡ 
    csi300,500,1000 index | 000300.SH, 000905.SH,000852.SH
    base date,20041231,20041231,20041231
    issue date,20050408,20070115,20141017   
    000906.SH = 000300.SH + 000905.SH
    notes:20110531æŠ“å–ä¸åˆ° 000852 çš„CSI1000çš„æˆä»½è‚¡æ•°æ®ï¼Œ000905å¯ä»¥ã€‚å¯¹äº20140531
    æŠ“å–ä¸åˆ°csi1000çš„æ•°æ®ï¼Œä½†æ˜¯20141130å°±å¯ä»¥ï¼Œè¯´æ˜æ˜¯å¦æœ‰æ•°æ®æ˜¯è·Ÿç€issue date èµ°çš„ã€‚

    
Notes:
1,wind-apiæ•°æ®æå–ï¼š é™åˆ¶æ¡ä»¶ï¼šæ¯å‘¨50ä¸‡ä¸ªï¼Œå®‰å…¨èµ·è§ï¼Œæ¯å‘¨45ä¸‡ã€‚
2,wind api æ¯æ¬¡åªèƒ½æŠ“å–ä¸è¶…è¿‡100ä¸ªæ•°æ®ã€‚
===============================================
'''
import sys
sys.path.append("..")
### A test case 
## Get and save index weights, fundamental indicators
# from db.assets import stocks
# wind_api = stocks.wind_api()
# result = wind_api.Wind2Csv_test()
# result = wind_api.Data_funda_csvJson_test()

##################################################################

## Load and wash fundamental data 

## empirical steps å®è¯ç ”ç©¶æµç¨‹
## Algo: | base on p1_theory-model
'''
step 1 æ•°æ®å‡†å¤‡æµç¨‹ 
1.0ï¼Œinformation processï¼š
    TS --> strategy --> ranking --> signal --> portfolio rebalance 
1.1ï¼Œdata_in |åŸå§‹ç ”ç©¶æ•°æ®,data_in ç»è¿‡ç ”ç©¶å‘˜åˆæ­¥æ¢³ç†åçš„ç»“æ„åŒ–ä¿¡æ¯     
1.2ï¼Œestimates |æ ¹æ®data_in,ç”Ÿæˆå¯¹èµ„äº§çš„æŸç§é¢„æµ‹ï¼Œä»¥å˜é‡ï¼Œå‚æ•°ï¼Œæ–¹ç¨‹ç­‰å½¢å¼
1.3ï¼ŒTS | data_in --> estimatesï¼Œlogicåˆ†æé€»è¾‘ï¼Œstructureæ¡†æ¶ --> TS    æ—¶é—´åºåˆ—æ ‡å‡†åŒ–:
     TS_i = {ts_i_j for asset i and information j in M sources | data_in, estimtes, logic, structure, N assets, M information sources  }
1.4ï¼ŒAnalyzingï¼šalgo model,econ. model , ...... tail risk,active h_a ??
1.5, strategyï¼š
1.6ï¼Œranking
1.7ï¼Œtradeï¼športfolio rebalance
1.8ï¼Œport. evaluation performance and risk
'''
# step 1.1,data_in |åŸå§‹ç ”ç©¶æ•°æ®,data_in ç»è¿‡ç ”ç©¶å‘˜åˆæ­¥æ¢³ç†åçš„ç»“æ„åŒ–ä¿¡æ¯ 
'''At t0 time, we need to set an initial position, a natural idea might be replicate market 
portfolio.
Time horizon, at 20130531,8ä¸ªæŒ‡æ ‡ä¸­ï¼Œè¡Œä¸šæŒ‡æ ‡éæ•°å€¼ï¼Œå…¶ä»–7ä¸ªéœ€è¦è®¡ç®—å‡å€¼/ä¸­ä½æ•°ï¼Œå¹¶å¯¹ç¼ºå¤±å€¼åšå¤„ç†ã€‚
å¯¹ç‰¹å¾attributionæ ‡å‡†åŒ–ã€‚
    Qsï¼šå¦‚ä½•ç¡®å®šåˆå§‹å€¼ï¼Ÿ Ansï¼šé‡‡ç”¨å¸‚åœºç»„åˆï¼Œæˆ–è€…ä¸»è§‚çš„ä¸»åŠ¨ç»„åˆ(åŸºäºåŸºå‡†çš„å‡è®¾)
'''
### step1 data_in 
# 7ä¸ªindicatorä»å±äº æ ¸å¿ƒå› å­:[è¡Œä¸šï¼ŒæµåŠ¨æ€§ï¼ŒåŠ¨é‡ï¼Œä¸»åŠ¨æ”¶ç›Šï¼Œä»·å€¼ï¼Œæˆé•¿ï¼Œ
# èµ„æœ¬ç»“æ„ï¼Œè´¢åŠ¡ä¼˜åŠ¿ï¼Œç»è¥èƒ½åŠ›ï¼ŒäººåŠ›ä¼˜åŠ¿ï¼Œä¿¡æ¯ä¼˜åŠ¿]
#  
# 1ï¼Œmerge additional data into one pdï¼š create/import database file,update data 
# with imported new info, save to database file.

from db.assets import stocks
stocks = stocks()
funda_wash = stocks.data_wash_funda()
file_path_funda = "C:\\zd_zxjtzq\\RC_trashes\\temp\\keti_sys_stra_24h\\p1\\wind_data\\funda\\"
time_stamp_input= '20181114'
output_type = 'dict'
dataG = funda_wash.Get_json_groupdata('','',file_path_funda,time_stamp_input,output_type ) 
# for given temp_index in dataG.index_list and temp_date in dataG.date_list

wind_code = '000300.SH'
temp_date = '2014-05-31'
temp_list = dataG.datagroup[wind_code+'_'+temp_date]
print('==========================')
print('temp_list, length ', len(temp_list['code']) )
print(temp_list.sum() )
print(temp_list.head() )

# # 2,å› å­æ ‡å‡†åŒ–ï¼ˆZ-Scoreï¼‰ 
# print( dataG.datagroup_zscore[wind_code+'_'+temp_date])

################################################################## 
##### 2,æ¢³ç†æ•°æ®ç»“æ„å’Œä»£ç ç»“æ„ 
### 1.2ï¼Œestimates |æ ¹æ®data_in,ç”Ÿæˆå¯¹èµ„äº§çš„æŸç§é¢„æµ‹ï¼Œä»¥å˜é‡ï¼Œå‚æ•°ï¼Œæ–¹ç¨‹ç­‰å½¢å¼
# todo 1,è¡Œä¸šå› å­ä¸­æ€§åŒ–ï¼›2ï¼Œé£æ ¼å› å­

# å¯¹1,2,3,4çº§è¡Œä¸šè¿›è¡Œæ¢³ç† |åˆ†ç±»æ¢³ç† æ–°å»ºwindè¡Œä¸šå¯¹ç…§è¡¨
#Name: Wind Industry Name | Wind Industry Code | Wind Industry Index Code
#indicator: industry_gics |industry_gicscode | indexcode_wind
# Wind-ind-index NameåŒºåˆ«ï¼šSector\industry group\industry\sub-industry
#case: 10101020 882401.WI
# history è¡Œä¸šç®¡ç† with è‚¡ç¥¨æ± ç®¡ç†ï¼Œè¿™æ˜¯2ä¸ªæœ‰å…³è”ä½†æ˜¯ç‹¬ç«‹çš„æ¨¡å—ï¼
# process:å»ºç«‹Windä¸‹ ind_code å’Œind_index_code çš„å…³ç³»ï¼Œä¸€çº§åˆ°å››çº§è¡Œä¸šä¸€ä¸€å¯¹åº”

#0ï¼Œå‡†å¤‡Windåç§°ä¸‹ï¼Œè¡Œä¸šä»£ç ï¼Œè¡Œä¸šæŒ‡æ•°ä»£ç ï¼Œè¡Œä¸šåç§°ï¼Œè¡Œä¸šæŒ‡æ•°åç§°çš„å¯¹åº”å…³ç³»(Windæˆ–è€…GICSï¼Œå…¶è¡Œä¸šæœ¬èº«çš„å®šä¹‰æœªæ¥éƒ½å¯èƒ½ä¼šå˜åŒ–çš„)
#1ï¼Œæ ¹æ®t0æ—¶æ ·æœ¬ç©ºé—´å†…(ä¸­è¯300+500+1500)çš„è‚¡ç¥¨åˆ—è¡¨ï¼ŒæŠ“å–ä¸ªè‚¡å¯¹åº”çš„wind è¡Œä¸šå’Œè¡Œä¸šæˆåˆ†è‚¡
#2ï¼Œ
'''
file: codelist_ind4.csv 
path: C:\zd_zxjtzq\RC_trashes\temp\sys_stra_24h\CISS_rc\db\db_assets
content:
wind_code    sec_name    ind4_index_code ind3_index_code ind2_index_code ind1_index_code ind4_code   ind3_index_code ind2_index_code ind1_index_code
000001.SZ   å¹³å®‰é“¶è¡Œ    882493.WI   882241.WI   882115.WI   882007.WI   40101010    401010  4010    40

notes:ä¸œæ–¹æ˜ç ç­‰åª’ä½“IIIçš„è‚¡ç¥¨æ²¡æœ‰å››çº§çš„åˆ†ç±»ï¼Œå› æ­¤ç›®å‰ç”¨61ä¸ªä¸‰çº§è¡Œä¸šåˆ†ç±»ä»£è¡¨æ‰€æœ‰è¡Œä¸šã€‚
todo:
1,ç¡®å®šè¡Œä¸šå› å­çš„æ ‡å‡†åŒ–æ–¹å¼ï¼š
    zxjt P7 | ğ‘¤ğ‘–è¡¨ç¤ºè¡Œä¸š i ä¸­æ‰€æœ‰è‚¡ç¥¨æµé€šå¸‚å€¼å å…¨å¸‚åœºè‚¡ç¥¨æµé€šå¸‚å€¼çš„æ¯”ä¾‹ï¼Œçº¦æŸæ¡ä»¶çš„é€‰æ‹©ä¸ä¼šå½±å“æ¨¡å‹æ‹Ÿ
åˆï¼Œä¹Ÿä¸ä¼šå½±å“æ¨¡å‹çš„è§£é‡ŠåŠ›ï¼Œä½†å…¶ä¼šå¯¹å› å­è§£é‡Šäº§ç”Ÿç›´æ¥çš„å½±å“
    sum( wi*fi ) = 0 
2ï¼Œè®¡ç®—æ–¹æ³•ï¼šé€‰å‰40~100å¤©æ€»æˆäº¤é‡‘é¢ä½œä¸ºæµé€šå¸‚å€¼çš„ä¸€ç§æ›¿ä»£ã€‚?
    Ana:1ï¼Œè¡Œä¸šè§’åº¦ï¼Œé¦–å…ˆå‡è®¾å…¬å¸å…¨éƒ¨ä¸šåŠ¡å±äºæœ¬è¡Œä¸š(å¦‚æœä¸æ˜¯é‚£ä¹ˆç†è®ºä¸Šæœ‰é—®é¢˜)åº”è¯¥ç”¨é¢„æµ‹(å‡è®¾é¢„æµ‹å‡†ç¡®)çš„æ”¶å…¥æˆ–è€…åˆ©æ¶¦
        å¯¹åº”è¡Œä¸šå†…æƒé‡ã€‚ä¾‹å­ï¼š17Q4ï¼Œè‹¹æœçš„iphoneåœ¨æ™ºèƒ½æ‰‹æœºå¸‚åœºæ”¶å…¥å æ¯”,18%ï¼Œä½†åˆ©æ¶¦å æ¯”87%ï¼›ä½†è‹¹æœå…¬å¸ä¸šåŠ¡ä¸­58%æ”¶
        å…¥æ˜¯iphoneï¼Œä¼°è®¡åˆ©æ¶¦å æ¯”è¦æ˜¾è‘—è¶…è¿‡58%ã€‚
        2ï¼Œç†è®ºä¸Šæ›´åˆç†çš„æ–¹å¼å¯èƒ½æ˜¯å¯¹éæœ¬è¡Œä¸šçš„ä¼°å€¼ä¸æœ¬è¡Œä¸šä¼°å€¼æ¯”è¾ƒè®¡ç®—æ¢ç®—ç³»æ•°ï¼Œå°†å…¬å¸æ¨¡æ‹Ÿæˆä¸€ä¸ªåªæœ‰æœ¬è¡Œä¸šä¸šåŠ¡çš„ä¸»ä½“
        3ï¼Œæ•°æ®é™åˆ¶çš„æƒ…å†µä¸‹ï¼Œä½¿ç”¨å‡€åˆ©æ¶¦åŠå…¶é¢„æœŸå¢é€Ÿè¿›è¡Œè¡Œä¸šå†…åŠ æƒï¼Œå¯èƒ½æ˜¯æ›´åˆç†çš„ç­–ç•¥ã€‚
    todoï¼ŒæŠ“å–åˆ†å­£åº¦çš„è´¢åŠ¡æ•°æ®ï¼Œå‡€åˆ©æ¶¦ç­‰ç”¨äºã€‚

3ï¼Œnotesï¼šå¦‚æœè´¢åŠ¡æ•°æ®q1q2q3q4çš„æŠ«éœ²æ—¶é—´ï¼štime,æœ€æ—©ï¼Œæœ€æ™š,delay_max|days
    Q1,4-1,4-30,30
    Q2,7-1,9-1,60
    Q3,10-1,10-30,30
    Q4,1-1ï¼Œ4-30,120
2.1ï¼Œè´¢åŠ¡æ•°æ®ç®¡ç†ï¼šæŠ“å–å­£åº¦è´¢åŠ¡æ•°æ®ï¼Œ
file:tb_financeä¸“ä¸šè´¢åŠ¡.csv
path:D:\db_dzh_dfw
Choiceè´¢åŠ¡æ•°æ®æ¨¡æ¿ï¼šC:\Eastmoney\Choice\Office\Template\Excel\ä¸œè´¢è´¢åŠ¡ä¼°å€¼æ¨¡æ¿
source 20180108_æ–¹æ­£è¯åˆ¸_é‡‘èå·¥ç¨‹ä¸“é¢˜_éŸ©æŒ¯å›½_ã€æ–¹æ­£é‡‘å·¥ï¼Œä¸“é¢˜ã€‘â€œæ˜Ÿç«â€å¤šå› å­ç³»åˆ—æŠ¥å‘Šï¼ˆä¸€ï¼‰ï¼šBarraæ¨¡å‹åˆæ¢ï¼šAè‚¡å¸‚åœºé£æ ¼è§£æ
'''
'''
self è¡Œä¸šä¸­æ€§åŒ–ï¼šæ ·æœ¬ç©ºé—´å†…ï¼Œ
1ï¼Œæœé›†æ‰€æœ‰è¡Œä¸šåŠè¡Œä¸šå†…ä¸ªè‚¡ï¼›
2ï¼Œç”¨è´¢åŠ¡æŒ‡æ ‡ç¡®å®šè¡Œä¸šå†…ä»·å€¼æœ€å¤§å’Œæˆé•¿æœ€ä¼˜è´¨çš„è‚¡ç¥¨ä½œä¸ºé”šï¼›
(ä¾‹å¦‚2017å¹´çš„ä¸‡ååŒ–å­¦åœ¨windä¸‰çº§è¡Œä¸šä¸­ï¼šä»·å€¼è§’åº¦ï¼šå‡€åˆ©æ¶¦111ï¼Œå…¶ä»–å…¬å¸åˆè®¡157ï¼Œæœ¬å…¬å¸çš„è¡Œä¸šå æ¯”41.4%ï¼›æˆé•¿è§’åº¦ï¼šå‡€åˆ©æ¶¦å¢é•¿ç‡+200%,å…¶ä»–å…¬å¸å¹³å‡ä½äº30%ã€‚)
3ï¼Œè®¾ç½®åŸºäºé”šçš„ç®—æ³•ï¼Œå¯¹ä¸ªè‚¡è¿›è¡Œç›¸å¯¹å†…åœ¨ä»·å€¼ä¼°è®¡ã€‚|
3.0ï¼ŒQsï¼šè¿™æ ·çš„è¯ï¼Œè¡Œä¸šå› å­ä¼šä¸ä¼šå˜æˆå®è´¨ä¸Šçš„é£æ ¼å› å­ï¼ŸAnsï¼šæˆ‘ä»¬è®¤ä¸ºä¸ä¼šï¼Œå› ä¸ºç°æœ‰çš„é£æ ¼factors\ä»·å€¼ç±»,æˆé•¿ç±»å› å­éƒ½æ˜¯ç›¸å¯¹æ¯”ä¾‹å‹çš„æŒ‡æ ‡ï¼Œå¦‚PEï¼ŒPB,roe,roa,ç°é‡‘æµå¢é•¿ç‡ï¼Œå‡€åˆ©æ¶¦å¢é•¿ç‡ç­‰ï¼›è€Œç”¨å¸‚å€¼å’Œå‡€åˆ©æ¶¦ç­‰ç»å¯¹å€¼ç±»å‹æŒ‡æ ‡æ¥è®¡ç®—æƒé‡ï¼Œæ˜¯åˆ†ç»„å†…éƒ¨åˆç†çš„è®¡ç®—æƒé‡æ–¹å¼ã€‚
3.1ï¼Œå‡è®¾é”šè‚¡ç¥¨å†…åœ¨ä»·æ ¼1ï¼Œä¼ä¸šä»·å€¼1äº¿=å†…åœ¨ä»·æ ¼*è‚¡æœ¬ï¼Œè®¡ç®—å…¶ä»–è‚¡ç¥¨ä¼ä¸šä»·å€¼ï¼Œæ ¹æ®ä¼ä¸šä»·å€¼åœ¨è¡Œä¸šå†…è®¡ç®—ä¼ä¸šä»·å€¼æƒé‡ï¼Œå¾—åˆ°åœ¨è¡Œä¸šå†…çš„å› å­æš´éœ²
3.2ï¼Œå¯¹äºå…¨å¸‚åœºè¡Œä¸šï¼Œæ–¹æ¡ˆä¸€æ˜¯ç”¨é”šçš„ä¸ªè‚¡(1ä¸ªä¸ªè‚¡åŒæ—¶ä»£è¡¨ä»·å€¼å’Œæˆé•¿ï¼Œæˆ–2ä¸ªä¸ªè‚¡åˆ†åˆ«ä»£è¡¨ä»·å€¼å’Œæˆé•¿ï¼Œç”šè‡³è¿˜å¯ä»¥æ›´å¤šçš„ä¸ªè‚¡æ¥ä»£è¡¨ä¸»è¥ä¸šåŠ¡ç‰¹åˆ«æˆ–è€…ä¸ªè‚¡æ¯”è¾ƒç‰¹åˆ«çš„æƒ…å†µã€‚)ç›´æ¥ä»£æ›¿è¡Œä¸šï¼Œå¯¹å„ä¸ªè¡Œä¸šçš„é”šä¸ªè‚¡è®¡ç®—ä¼ä¸šä»·å€¼ï¼Œå¹¶è¿›è¡ŒåŠ æƒè®¡ç®—è¡Œä¸šå†…çš„å› å­æš´éœ²ï¼›æ–¹æ¡ˆäºŒæ˜¯ç”¨é”šçš„ä¸ªè‚¡è®¡ç®—å‡ºè¡Œä¸šçš„æ•°å€¼ã€‚
testï¼š
t1ï¼Œæ ¹æ®æˆ‘ä»¬çš„è¡Œä¸šå› å­ï¼Œä¸å¸‚åœºæŒ‡æ•°ï¼Œå¸‚åœºè¡Œä¸šæŒ‡æ•°æ¯”è¾ƒæ”¶ç›Šç‡å’Œæ³¢åŠ¨ç‡ç‰¹å¾ï¼Œä¿¡æ¯ç‡ç­‰ã€‚
t2ï¼Œå‚è€ƒzxjtï¼Œè®¡ç®—å„ä¸ªè¡Œä¸šå› å­çš„æ”¶ç›Šç‡å¹´åŒ–æ³¢åŠ¨ç‡ï¼Œæ˜¾è‘—æœˆä»½å æ¯”ï¼Œå¯¹äºå¸‚åœºçš„R^2å¢é‡ã€‚
4ï¼Œperformanceï¼šçº¯è¡Œä¸šå› å­ å¹´åŒ–è¶…é¢æ”¶ç›Šç‡% å¹´åŒ–æ³¢åŠ¨ç‡% ä¿¡æ¯æ¯”ä¾‹ |T|å¹³å‡å€¼ |T|>2 å æ¯”ï¼ˆ%ï¼‰

assumptions:1,ä¸åŒè¡Œä¸šéƒ½å­˜åœ¨å¼ºè€…æ’å¼ºçš„æƒ…å†µï¼Œä¸€æ–¹é¢é¾™å¤´è‚¡ç»è¥æ”¶å…¥å’Œåˆ©æ¶¦çš„å¸‚åœºå æ¯”æŒç»­æå‡ï¼Œå¦ä¸€æ–¹é¢é¾™å¤´è‚¡çš„å¸‚å€¼è¡Œä¸šå æ¯”åœ¨å‘å±•åˆæœŸä½äºç»è¥æ”¶å…¥å’Œåˆ©æ¶¦å æ¯”ï¼Œä½†åæœŸè¶‹åŒã€‚
todo æ¨¡å—è®¡ç®—æ­¥éª¤ï¼š 
1ï¼Œæ•°æ®å‡†å¤‡ï¼šå‡†å¤‡å†å¹´éœ€è¦çš„è´¢åŠ¡æ•°æ®ï¼Œå½¢æˆæœ¬æ¨¡å—/appéœ€è¦çš„indicatorsã€‚Keysï¼šä»Šå¹´å‡€åˆ©æ¶¦å’Œæ”¶å…¥ç­‰
2ï¼Œç®—æ³•è®¡ç®—ï¼šè®¡ç®—åˆ†è¡Œä¸šä¸ªè‚¡å†…åœ¨ä»·å€¼
3, ä»Basic Infoæ¨¡å—æŠ“å–Windè¡Œä¸šæ•°æ®(4æ¡£ï¼Œä½†ä¸€èˆ¬ç”¨3æ¡£)
...

3ï¼Œè®¡ç®— å¸‚åœºç»„åˆ(å¦‚ä¸­è¯å…¨æŒ‡æˆ–è€…è‡ªå»º)ä¸æŸå› å­ç»„åˆçš„æœˆæ”¶ç›Šç‡å·®å€¼
4ï¼Œè§‚å¯Ÿåˆ†è¡Œä¸šçš„è¶…é¢æ”¶ç›Šæƒ…å†µã€‚
ideaï¼šä¸å¯¹å› å­æœ‰æ•ˆæ€§åšå¼ºå‡è®¾ï¼Œä¸“æ³¨äºæœ€ä¼˜ç­–ç•¥çš„æµç¨‹å‘ç°ã€‚
'''
### sub-step 1 Load industry file 
# path: C:\zd_zxjtzq\RC_trashes\temp\sys_stra_24h\CISS_rc\db\db_assets
# logic: load ind. file from db_assets, match symbol list with ind. file 
from db.basics import industry
industry = industry()
ind_raw = industry.load_wind_ind('')
print("industry data from Wind-API: \n")
# Qs UnicodeEncodeError: 'charmap' codec can't encode characters in position
# Ans : cmdä¸èƒ½å¾ˆå¥½åœ°å…¼å®¹utf8,æ”¹ä¸€ä¸‹ç¼–ç ï¼Œæ¯”å¦‚æˆ‘æ¢æˆâ€œgb18030â€ï¼Œå°±èƒ½æ­£å¸¸æ˜¾ç¤º
print( ind_raw.head(5) )
### sub-step 2 get symbol lists for periods 
# for periods 13Q1 to 18Q2,
## ss2.1, get collection of symbol lists from CSI300+800+1000, 
# derived from Get_json_groupdata and Load_funda_csvJson | stocks_funda_wash
# object: temp_dataG.datagroup[wind_code+'_'+temp_date] = data_json_rc.file_csv
# C:\zd_zxjtzq\RC_trashes\temp\keti_sys_stra_24h\p1\wind_data
# path_ss2 = "C:\\zd_zxjtzq\\RC_trashes\\temp\\keti_sys_stra_24h\\p1\\wind_data"
# temp_file = "Wind_000300.SH_2013-05-31_20180923.csv"
# å¯¹äº temp_list['code'], æŠ“å–å¯¹åº”çš„windä¸‰çº§è¡Œä¸š,æœ€è¿‘å¹´åº¦å‡€åˆ©æ¶¦ï¼Œæ€»æ”¶å…¥ ã€‚
    # reference: ä¹‹å‰ç­›é€‰è¡Œä¸šé¾™å¤´çš„ç­–ç•¥ã€‚ å¦‚æœå¹´åŒ–è®¡ç®—çš„è´¢åŠ¡æŒ‡æ ‡=1å­£æŠ¥å€¼/å»å¹´(å­£æŠ¥/å¹´æŠ¥) 
    # load tb_finance_financeData.csv and tb_finance_capital.csv from D:\\db_dzh_dfw

### sub-step 3 fundamental financial and capital data
import pandas as pd 
path_db_dzh = "D:\\db_dzh_dfw\\"
file_tb_finance_finance = "tb_finance_financeData.csv"
file_tb_finance_capital = "tb_finance_capital.csv"
print("Loading financia data and capital data. ")
df_tb_fi_fi = pd.read_csv(path_db_dzh+file_tb_finance_finance, encoding="GBK",sep=",",low_memory=False)
# index 71004 | columns 245 | 
print('=========================================')
print("data head,sum of df_tb_fi_fi ")
print(df_tb_fi_fi.info() ) # 245 columns
print(df_tb_fi_fi.head() )

df_tb_fi_cap = pd.read_csv(path_db_dzh+file_tb_finance_capital, encoding="GBK",sep=",",low_memory=False )
# index 91935 | columns 20 | objects |phd 
# è¯åˆ¸ä»£ç ,æ—¶é—´,è‚¡ä»½æ€»æ•°,æ— é™å”®è‚¡ä»½åˆè®¡,Aè‚¡,Bè‚¡,å¢ƒå¤–ä¸Šå¸‚å¤–èµ„è‚¡,å…¶ä»–æµé€šè‚¡ä»½,é™å”®è‚¡
# ä»½åˆè®¡,å›½å®¶æŒè‚¡,å›½æœ‰æ³•äººæŒè‚¡,å¢ƒå†…æ³•äººæŒè‚¡,å¢ƒå†…è‡ªç„¶äººæŒè‚¡,å…¶ä»–å‘èµ·äººè‚¡ä»½,å‹Ÿé›†æ³•äººè‚¡ä»½,å¢ƒå¤–æ³•äººæŒè‚¡,
# å¢ƒå¤–è‡ªç„¶äººæŒè‚¡,å†…éƒ¨èŒå·¥è‚¡,ä¼˜å…ˆè‚¡æˆ–å…¶ä»–,å˜åŠ¨åŸå› ,å˜åŠ¨åŸå› 2    91935 non-null object
# Ana:last column "å˜åŠ¨åŸå› ",å­˜åœ¨34ä¸ªcellå†…æœ‰","åˆ†éš”ç¬¦ï¼Œpandasä¼šè®¤ä¸ºæ˜¯å¤šäº†ä¸€åˆ—(21th)ï¼Œä½†é¦–è¡Œcolumns
# åªæœ‰20ä¸ª;ç”¨ header=0 ä¹Ÿä¸è§£å†³é—®é¢˜
# pandas.errors.ParserError: Error tokenizing data. C error: Expected 20 fields in line 905, saw 21 
# Ana # ç”¨äº†sep="\s+"åï¼Œå‡ºé”™lineä»901å˜æˆäº†line 55553 ;åŠ äº†delimiter="\t"
# Ans: open csv file, add "å˜åŠ¨åŸå› 2" as 21th column at "U1"
print("data head,sum of df_tb_fi_cap ")
print(df_tb_fi_cap.info() )
print(df_tb_fi_cap.head() )
print('=========================================')
# Anaï¼šâ€œæ—¶é—´â€åœ¨æ—¥çš„çº§åˆ«ä¸Šå¯èƒ½æ˜¯{24,19,11,31ï¼Œ...}ï¼Œä½†å¹´å’Œæœˆä¼¼ä¹æ˜¯ç¨³å®šçš„
# format in loaded df:1990/9/24 0:00 || format in csv:1990-12-31 00:00:00
# pythonä¸­.split()åªèƒ½ç”¨æŒ‡å®šä¸€ä¸ªåˆ†éš”ç¬¦;å¤šä¸ªåˆ†éš”ç¬¦å¯ä»¥ç”¨reæ¨¡å—
import re
# re.split("[/,]",temp_date) || ['1990', '9', '24 0:00']
# re.split("[/ ]",temp_date) || ['1990', '9', '24', '0:00']
# ç”±äºè‚¡æœ¬å˜åŠ¨çš„æ—¶é—´å˜åŠ¨ä¸å®šï¼Œå› æ­¤éœ€è¦æŠ“å–å¯¹åº”çš„æ•°æ®
# todo ä¸ºäº†ç¼“è§£è¿‡å¤§dfå¸¦æ¥çš„ç®—æ³•æ•ˆç‡é—®é¢˜ï¼Œå¯ä»¥è€ƒè™‘åˆ†ä»£ç å°†å…¶æ‹†åˆ†æˆdf_code

### sub-step 3 match financial indicator into industry scale 
# ä»13å¹´å¼€å§‹ï¼Œè½½å…¥"2013-05-31"çš„è‚¡ç¥¨ä»£ç 300+500ï¼Œé€ä¸ªæŠ“å–13Q1-18Q2çš„è´¢åŠ¡æ•°æ®
''' Create new pd to save analytical indicators
inputï¼šwind_code = '000300.SH',temp_date = '2014-05-31' 
    temp_list = dataG.datagroup[wind_code+'_'+temp_date]
    df_tb_fi_fi
    df_tb_fi_cap
algo: 1, all 
    
'''
### ss3.1, get all sample space codes from CSI300,500,CSI1000
temp_date = '2016-05-31'
# çœ‹çœ‹æ ·æœ¬ç©ºé—´é‡ŒdataGroup æœ‰å•¥å¥½ä¸œè¥¿ã€‚
temp_list = pd.DataFrame()
for temp_i in dataG.index_list:
    # ['000300.SH', '000905.SH', '000852.SH'] 
    temp_list_sub = dataG.datagroup[temp_i+'_'+temp_date]
    temp_list = pd.concat([temp_list,temp_list_sub],ignore_index=False)
    #there are duplicate indexes, so we need to re-sort index here
    temp_list= temp_list.reset_index()
    print( temp_list.head() )
    temp_list= temp_list.drop(['index'] ,axis=1 ) 
    # print(temp_list.info() )
    temp_list.to_csv("D:\\temp_list_181025.csv")


# get code df in df_tb_fi_fi
# Notesï¼š"å‡€åˆ©æ¶¦"é¡¹ç›®ä¸‹ï¼Œåªæœ‰åŠå¹´å’Œå¹´æœ«æ•°æ®ï¼Œ1,3å­£åº¦å‡€åˆ©æ¶¦æ•°å€¼æ˜¯0ã€‚åº”è¯¥ä½¿ç”¨"å‡€åˆ©æ¶¦ï¼ˆä¸å«å°‘æ•°è‚¡ä¸œæŸç›Šï¼‰"
#   æ”¶å…¥åº”è¯¥ä½¿ç”¨ "ä¸€.è¥ä¸šæ”¶å…¥"
#   ç»è¥æ€§ç°é‡‘æµ "ç»è¥æ´»åŠ¨äº§ç”Ÿçš„ç°é‡‘æµé‡å‡€é¢"
# 5-31æ—¶å¯ä»¥è·å¾—å‰ä¸€å¹´Q4å’Œæœ¬å¹´Q1è´¢åŠ¡æ•°æ®ï¼Œ11-30å¯ä»¥è·å¾—æœ¬å¹´Q3,Q2çš„è´¢åŠ¡æ•°æ®
# match_date = [['05-31','12-31','03-31'],['11-30','09-30','06-30'] ]
# df_match_date = pd.DataFrame(match_date, columns=["date_raw","date_f1","date_f2"])
# date_f1 = df_match_date[df_match_date["date_raw"]== temp_date[-5:] ].loc[0,'date_f1']
# date_f2 = df_match_date[df_match_date["date_raw"]== temp_date[-5:] ].loc[0,'date_f2']

yymmdd = re.split('-',temp_date )
# From date for symbol list to date for fiscal quarter # "2013-03-31"  
# Notes:è¦ç”¨åˆ°å‰ä¸€å¹´æ•°æ®ï¼Œä½†æ˜¯è´¢åŠ¡æ•°æ®ä»2013å¹´å¼€å§‹çš„ï¼Œ2013å¹´æ— æ³•å–å¾—2012å¹´çš„æ•°æ®ï¼ï¼ 
if temp_date[-5:] == "05-31" :
    date_list = [str(int(yymmdd[0])-1)+'-12-31', yymmdd[0]+'-03-31',str(int(yymmdd[0])-1)+'-03-31']
elif temp_date[-5:] == "11-30" :
    date_list = [ yymmdd[0]+'-09-30', str(int(yymmdd[0])-1)+'-09-30',str(int(yymmdd[0])-1)+'-12-31' ]

## put these values to a big table 
# è®¡ç®—æ—¥æœŸå±äºå“ªä¸ªå­£åº¦ï¼ï¼ï¼ å¯¹è´¢åŠ¡æ•°æ®è¿›è¡Œå¹´åŒ–è½¬æ¢ | notes:ç°åœ¨éƒ½æ˜¯å‡å®šè´¢åŠ¡æ•°æ®åœ¨æœ€æ™šæ—¶é—´ç»Ÿä¸€
# è·å¾—ï¼Œä½†æ˜¯å®é™…ä¸Šè´¢åŠ¡æ•°æ®çš„æŠ«éœ²å¯ä»¥é€šè¿‡ ä¸šç»©é¢„å‘Šï¼ŒçœŸå®æŠ«éœ²æ—¥æœŸç­‰æ•°æ®æ›´é«˜æ•ˆåœ°è·å¾—ï¼Œæé«˜ä¿¡æ¯ä¼ é€’æ•ˆç‡ ã€‚
for temp_i in temp_list.index :
    temp_code = temp_list.loc[temp_i,'code']
    # code2 = "SH600036" # notes: different code types in df_tb_fi_fi["è¯åˆ¸ä»£ç "]
    # print('181025======temp_code :',type(temp_code),temp_code)
    # print(type(temp_code[-2:]),type(temp_code[:6]))
    # print('====================')
    # print('temp_code ',temp_code, '\n')
    code2 = temp_code[-2:] + temp_code[:6] 
    # print("code2  ",code2)
    if df_tb_fi_fi[df_tb_fi_fi["è¯åˆ¸ä»£ç "]== code2 ].any().any() :
        df_code = df_tb_fi_fi[ df_tb_fi_fi["è¯åˆ¸ä»£ç "]== code2 ] 
        # get latest dates before given date from df_code
        #   trasform from string to datetime 

        df_code.loc[:,"date"] = df_code.loc[:,"æ—¶é—´"] 
        # from string to DatetimeIndex(['2013-03-31',...
        df_code["date"] = df_code["date"].apply( pd.to_datetime ) 
        # print("=====df_code[æ—¶é—´]==181025")
         
        temp_index1 = df_code[ df_code["date"] == date_list[0] ].index 
        temp_index2 = df_code[ df_code["date"] == date_list[1] ].index
        temp_index3 = df_code[ df_code["date"] == date_list[2] ].index
        # æ ¹æ® Q1,2,3,4çš„ä¸åŒè®¡ç®— æ³¨æ„ï¼šæ­¤å¤„çš„q3æ•°æ®å¯¹åº”å½“å¹´å‰3å­£åº¦ä¹‹å’Œï¼Œè€Œä¸æ˜¯åˆ†å­£åº¦çš„ï¼Œ
        # q4å¯¹åº”å½“å¹´å…¨å¹´çš„è´¢åŠ¡æ•°æ®ä¹‹å’Œ
        # df_code.index might be empty for 000562.SZ
        ## Initialize var. and para å‚æ•°åˆå§‹åŒ–ï¼ç”±äºè‚¡ç¥¨ç¼ºå°‘Q1æˆ–Q3çš„è´¢åŠ¡æ•°æ®ï¼Œè¦åšå¥½åˆå§‹åŒ–çš„é»˜è®¤è®¾ç½®
        #   ä¾‹ï¼š603589.SH have no records for 2015-03! æ¬¡æ–°è‚¡ã€‚ 

        if temp_date[-5:] == "05-31" and len(df_code.index) >0  :
            # Q4_pre, Q1, Q1_pre
            # just one date match | TypeError: cannot convert the series to <class 'float'>
            # print( " df_code.loc[temp_index1 ,å‡€åˆ©æ¶¦ï¼ˆä¸å«å°‘æ•°è‚¡ä¸œæŸç›Šï¼‰:" )
            # print( df_code.loc[temp_index1 , "å‡€åˆ©æ¶¦ï¼ˆä¸å«å°‘æ•°è‚¡ä¸œæŸç›Šï¼‰"]  )
            profit_q4_pre =  float(df_code.loc[temp_index1 , "å‡€åˆ©æ¶¦ï¼ˆä¸å«å°‘æ•°è‚¡ä¸œæŸç›Šï¼‰"].values )
            revenue_q4_pre = float(df_code.loc[temp_index1, "ä¸€.è¥ä¸šæ”¶å…¥"].values )
            cf_oper_q4_pre = float(df_code.loc[temp_index1 , "ç»è¥æ´»åŠ¨äº§ç”Ÿçš„ç°é‡‘æµé‡å‡€é¢"].values )
            try :                
                profit_q1 =  float(df_code.loc[temp_index2 , "å‡€åˆ©æ¶¦ï¼ˆä¸å«å°‘æ•°è‚¡ä¸œæŸç›Šï¼‰"].values )
                revenue_q1 = float(df_code.loc[temp_index2, "ä¸€.è¥ä¸šæ”¶å…¥"].values )
                cf_oper_q1 = float(df_code.loc[temp_index2 , "ç»è¥æ´»åŠ¨äº§ç”Ÿçš„ç°é‡‘æµé‡å‡€é¢"].values )
                profit_q1_pre =  float(df_code.loc[temp_index3 , "å‡€åˆ©æ¶¦ï¼ˆä¸å«å°‘æ•°è‚¡ä¸œæŸç›Šï¼‰"].values )
                revenue_q1_pre = float(df_code.loc[temp_index3 , "ä¸€.è¥ä¸šæ”¶å…¥"].values )
                cf_oper_q1_pre = float(df_code.loc[temp_index3 , "ç»è¥æ´»åŠ¨äº§ç”Ÿçš„ç°é‡‘æµé‡å‡€é¢"].values )
                # synthesis profit,revenue and cash flow 
                # 1,è®¡ç®—å»å¹´1å­£åº¦çš„å…¨å¹´å æ¯”
                if profit_q1_pre != 0 :
                    profit_q1_yoy = profit_q1/profit_q1_pre # yoy
                else :
                    profit_q1_yoy = 1
                profit_q1_pre_pct = profit_q1_pre/profit_q4_pre
                para_fi_max = 0.35 # for q1 
                para_fi_1 = min(profit_q1_pre_pct,para_fi_max )
                profit_q4_es = profit_q1 + (profit_q4_pre-profit_q1_pre)*((1-para_fi_1)+para_fi_1*profit_q1_yoy)
                
                if revenue_q1_pre !=0 :
                    revenue_q1_yoy = revenue_q1/revenue_q1_pre
                else :
                    revenue_q1_yoy =1
                revenue_q1_pre_pct = revenue_q1_pre/revenue_q4_pre
                para_fi_2 = min(revenue_q1_pre_pct,para_fi_max )
                revenue_q4_es = revenue_q1 + (revenue_q4_pre-revenue_q1_pre)*((1-para_fi_2)+para_fi_2*revenue_q1_yoy)

                if cf_oper_q1_pre != 0 :
                    cf_oper_q1_yoy = cf_oper_q1/cf_oper_q1_pre
                else :
                    cf_oper_q1_yoy = 1
                cf_oper_q1_pre_pct = cf_oper_q1_pre/cf_oper_q4_pre
                para_fi_3 = min(cf_oper_q1_pre_pct,para_fi_max )
                cf_oper_q4_es = cf_oper_q1 + (cf_oper_q4_pre-cf_oper_q1_pre)*((1-para_fi_3)+para_fi_3*cf_oper_q1_yoy)
                     
            except:
                # 603589.SH have no records for 2015-03! æ¬¡æ–°è‚¡ã€‚
                # cautiously estimate current year/pre_year = 95% 
                print('There are missing quarterly finance records:')
                profit_q4_es = profit_q4_pre*0.95
                revenue_q4_es = revenue_q4_pre*0.95
                cf_oper_q4_es = cf_oper_q4_pre *0.95 
            
        elif temp_date[-5:] == "11-30" :
            # Q3, Q3_pre, Q4_pre,
            profit_q4_pre =  float(df_code.loc[temp_index3 , "å‡€åˆ©æ¶¦ï¼ˆä¸å«å°‘æ•°è‚¡ä¸œæŸç›Šï¼‰"].values )
            revenue_q4_pre = float(df_code.loc[temp_index3 , "ä¸€.è¥ä¸šæ”¶å…¥"].values )
            cf_oper_q4_pre = float(df_code.loc[temp_index3 , "ç»è¥æ´»åŠ¨äº§ç”Ÿçš„ç°é‡‘æµé‡å‡€é¢"].values )

            try :
                profit_q3 =  float(df_code.loc[temp_index1 , "å‡€åˆ©æ¶¦ï¼ˆä¸å«å°‘æ•°è‚¡ä¸œæŸç›Šï¼‰"].values )
                revenue_q3 = float(df_code.loc[temp_index1, "ä¸€.è¥ä¸šæ”¶å…¥"].values )
                cf_oper_q3 = float(df_code.loc[temp_index1 , "ç»è¥æ´»åŠ¨äº§ç”Ÿçš„ç°é‡‘æµé‡å‡€é¢"].values )
                profit_q3_pre =  float(df_code.loc[temp_index2 , "å‡€åˆ©æ¶¦ï¼ˆä¸å«å°‘æ•°è‚¡ä¸œæŸç›Šï¼‰"].values )
                revenue_q3_pre = float(df_code.loc[temp_index2, "ä¸€.è¥ä¸šæ”¶å…¥"].values )
                cf_oper_q3_pre = float(df_code.loc[temp_index2 , "ç»è¥æ´»åŠ¨äº§ç”Ÿçš„ç°é‡‘æµé‡å‡€é¢"].values )
                
                # synthesis profit,revenue and cash flow 
                # 1,è®¡ç®—ä»Šå¹´3å­£åº¦çš„å…¨å¹´å æ¯”
                profit_q3_yoy = profit_q3/profit_q3_pre # yoy
                profit_q3_pre_pct = profit_q3_pre/profit_q4_pre
                para_fi_max = 0.75 # for q3
                para_fi_1 = min(profit_q3_pre_pct,para_fi_max)
                profit_q4_es = profit_q3 + (profit_q4_pre-profit_q3_pre)*((1-para_fi_1)+para_fi_1*profit_q3_yoy)
                
                revenue_q3_yoy = revenue_q3/revenue_q3_pre
                revenue_q3_pre_pct = revenue_q3_pre/revenue_q4_pre
                para_fi_2 = min(revenue_q3_pre_pct,para_fi_max)
                revenue_q4_es = revenue_q3 + (revenue_q4_pre-revenue_q3_pre)*((1-para_fi_2)+para_fi_2*revenue_q3_yoy)

                cf_oper_q3_yoy = cf_oper_q3/cf_oper_q3_pre
                cf_oper_q3_pre_pct = cf_oper_q3_pre/cf_oper_q4_pre
                para_fi_3 = min(cf_oper_q3_pre_pct,para_fi_max)
                cf_oper_q4_es = cf_oper_q3 + (cf_oper_q4_pre-cf_oper_q3_pre)*((1-para_fi_3)+para_fi_3*cf_oper_q3_yoy)
            except :
                # cautiously estimate current year/pre_year = 95% 
                profit_q4_es = profit_q4_pre*0.95
                revenue_q4_es = revenue_q4_pre*0.95
                cf_oper_q4_es = cf_oper_q4_pre *0.95 
        # 
        temp_list.loc[temp_i, "profit_q4_es" ] = profit_q4_es
        temp_list.loc[temp_i, "revenue_q4_es" ] = revenue_q4_es
        temp_list.loc[temp_i, "cf_oper_q4_es" ] = cf_oper_q4_es

temp_list.to_csv("D:\\temp_list_1026.csv")
### sub-step 3 get anchor stocks for every sector,sub-sector,industry
# è´¢åŠ¡æŒ‡æ ‡ç¡®å®šè¡Œä¸šå†…ä»·å€¼æœ€å¤§å’Œæˆé•¿æœ€ä¼˜è´¨çš„è‚¡ç¥¨ä½œä¸ºé”š
## ss3.1, æå–ä¸ªè‚¡çš„ 1~3çº§è¡Œä¸šä»£ç 
## ss3.2, æ ¹æ® 1~3çº§è¡Œä¸šï¼Œgroupbyè·å–æ ·æœ¬å†…è¡Œä¸šçš„ã€åˆ©æ¶¦ï¼Œæ”¶å…¥ï¼Œç»è¥ç°é‡‘æµé‡‘é¢ã€‘ä¹‹å’Œ
    # notes:æ ·æœ¬å†…ä¸ªè‚¡ä¸ä»£è¡¨æœ¬ç»†åˆ†è¡Œä¸šçš„æ‰€æœ‰ä¸Šå¸‚ä¸ªè‚¡ï¼Œæ›´ä¸ä»£è¡¨ç»è¥ç¯å¢ƒä¸­çš„å…¬å¸

# calculate columns from ind1 to ind3 from temp_list['industry_gicscode']
# reference data: ind_raw = industry.load_wind_ind('') from line 165
# temp_df = ind_raw.drop_duplicates(subset=['ind3_code'], keep="first" )
for index01 in temp_list.index :
    # get industry code from 1 to 3 
    # notes: there might still be duplicate index 
    str1 = temp_list.loc[index01, "industry_gicscode"]
    temp_list.loc[index01,'ind1_code'] = str(str1)[:2]
    temp_list.loc[index01,'ind2_code'] = str(str1)[:4]
    temp_list.loc[index01,'ind3_code'] = str(str1)[:6]
# temp_INDS | [61 rows x 3 columns]
# notes: temp_INDS has no multiindex, RangeIndex(start=0, stop=61, step=1)
# columns= Index(['ind1_code', 'ind2_code', 'ind3_code', 'profit_q4_es', 'revenue_q4_es',
    #   'cf_oper_q4_es'], dtype='object')
# ===========================
# >>> temp_INDS_sum.index
# MultiIndex(levels=[['10', '15', '20', '25', '30', '35', '40', '45', '50', '55'
# '60'], ['1010', '1510', '2010', '2020', '2030', '2510', '2520', '2530', '2540'
#            labels=[[0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
# 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6,
#  names=['ind1_code', 'ind2_code', 'ind3_code'])

temp_INDS_sum=temp_list.groupby(["ind1_code","ind2_code","ind3_code"])["profit_q4_es","revenue_q4_es","cf_oper_q4_es"].sum()
temp_INDS_sum.to_csv("D:\\temp_INDS_sum_1026.csv")
## ss3.3, æŒ‰ç…§ç®—æ³•è®¡ç®—é”šå®šä»·æ ¼ã€‚
# ç›®æ ‡ï¼šè®¡ç®—æ¯ä¸ªind3çš„æ ·æœ¬å†…é”šanchorï¼Œä½œä¸ºæ–°å¢columnsæ”¾åœ¨temp_INDS_sumé‡Œ
#3 ss3.31, å®šä½ï¼Œè®¡ç®—é”šçš„åŸºå‡†æ•°å€¼
# todo compare ä¸ªè‚¡çš„pecentage with maximum one in temp_INDS_sum['','profit_pct_max']
# if current stock has larger percentage number, put it as the best value items.
df_ind3_sum = temp_INDS_sum.xs(["str_ind1","str_ind2"],level=["ind1_code","ind2_code"])
for temp_i3 in df_ind3_sum.index :
    str_ind3 = df_ind3_sum.loc[temp_i3,"ind3_code" ]
    print("Working on industry level3: ", str_ind3)
    

    
asd
# p582, pandas.pdf







## ss3.32 æ ¹æ®é”šçš„æ•°å€¼ï¼Œè®¡ç®—ä¸ªè‚¡çš„ç†è®ºä»·æ ¼ã€‚
for index01 in temp_list.index :
    # index01 = temp_list.index.values[0]
    # temp_code = "600036.SH" 
    temp_code = temp_list.loc[index01,'code']
    print("Calculating code: ",temp_code )
    # only one row for code in temp_list
    # get industry-3 code for given code 
    str_ind3 = temp_list.loc[index01, "ind3_code"]
    print('=============df_ind3')
    print( type(str_ind3),str_ind3 )
    print( temp_INDS_sum.index ) 
    print( temp_INDS_sum.columns ) # Index(['profit_q4_es', 'revenue_q4_es', 'cf_oper_q4_es']
    # get summary values of financial indicators from industry list
    # todo if error for int|string, then using str(str_ind3)
    # å¤šé‡ç´¢å¼•çš„dataframeå–å€¼ä¸€èˆ¬ä½¿ç”¨xs,å¯ä»¥ä¼ å…¥å¤šä¸ªä¸åŒçº§åˆ«çš„ç´¢å¼•è¿›è¡Œç­›é€‰,ä½†ä¸æ”¯æŒåŒä¸€çº§ç´¢å¼•å¤šé€‰å¹¶ä¸”xsè¿”å›çš„æ˜¯æ•°å€¼è€Œä¸æ˜¯å¼•ç”¨
    # temp_INDS_sum.xs(['10','1010'],level=["ind1_code","ind2_code"]).loc['101010','profit_q4_es']
    str_ind1 = str_ind3[:2]
    str_ind2 = str_ind3[:4]
    # temp_INDS_sum.xs(['10','1010'],level=["ind1_code","ind2_code"]).loc['101010','profit_q4_es']
    profit_total_ind3 = temp_INDS_sum.xs([str_ind1,str_ind2],level=["ind1_code","ind2_code"]).loc[str_ind3,'profit_q4_es']
    revenue_total_ind3 = temp_INDS_sum.xs([str_ind1,str_ind2],level=["ind1_code","ind2_code"]).loc[str_ind3,'revenue_q4_es']
    cf_oper_total_ind3 = temp_INDS_sum.xs([str_ind1,str_ind2],level=["ind1_code","ind2_code"]).loc[str_ind3,'cf_oper_q4_es']
    # df_ind3 =temp_INDS_sum[ temp_INDS_sum['ind3_code']== int(str_ind3) ]

    try:
        temp_list.loc[index01,'ind3_pct_profit_q4_es'] =temp_list.loc[index01,'profit_q4_es']/profit_total_ind3
        temp_list.loc[index01,'ind3_pct_revenue_q4_es'] =temp_list.loc[index01,'revenue_q4_es']/revenue_total_ind3
        temp_list.loc[index01,'ind3_pct_cf_oper_q4_es'] =temp_list.loc[index01,'cf_oper_q4_es']/cf_oper_total_ind3 

        
        





    except:
        print('=============df_ind3')
        print( df_ind3 )
        print( type(temp_list.loc[index01,"profit_q4_es"].values[0]) )
        print( type(temp_INDS_sum.loc[df_ind3.index,"profit_q4_es"].values[0]) )
        print("====================")
        print(profit_total_ind3,revenue_total_ind3,cf_oper_total_ind3  )
    



       
temp_list.to_csv("D:\\temp_list2_1026.csv")

## ss3.3, get anchor stocks for value and growth perspectives
# notes:1,è¡Œä¸šå†…weightsè¦æ ‡å‡†åŒ–å¤„ç†ï¼Œå‰”é™¤è´Ÿå€¼åå–95%æ€»æƒé‡åŠ æƒï¼Œå‰©ä½™5%åˆ†ç»™è´Ÿå€¼çš„ä¸ªè‚¡
# get list of ind3 from temp_INDS_sum or ind_raw
ind3_list = temp_list['ind3_code'].drop_duplicates()
ind3_list.to_csv("D:\\temp_list2_1027.csv")

# todo create class and modules to set such information. 


 
  









# sub-step 1
# sub-step 1
# sub-step 1
# sub-step 1




























'''
todo 
1,developing indicators
1.1, expected P/E in future 2 years | need (total_shares*price)/e_expected

2,å†å²æ¯æ—¥å¸‚åœºæ•°æ®åº”ç”¨ï¼Œç‰¹åˆ«æ˜¯å…³æ³¨windçš„å¤æƒå› å­æ•°æ®ã€‚
Wind_Input\Wind_all_A_Stocks_wind_170814_updated 


# Alphaå› å­å’Œé£é™©/ç³»ç»Ÿ/Betaå› å­è¯„å®šï¼š1ï¼Œæ•°å€¼ç¨³å®šä¸”ä¸å…¶ä»–å› å­ç›¸å…³æ€§ä½
#2ï¼Œå› å­ä»·æ ¼å˜åŠ¨éƒ¨åˆ†çš„æ”¶ç›Šæˆ–é£é™©è§’åº¦ä»·å€¼ï¼Œ
#3ï¼Œå› å­æ”¶ç›Šç‡æ˜¾è‘—æ€§ï¼Œæ¯æœŸä¸ªè‚¡æ”¶ç›Šç‡å’Œå› å­æš´éœ²å€¼å›å½’ï¼Œçœ‹å¹³å‡å€¼æ˜¯å¦æ˜¾è‘—ï¼Œæ˜¾è‘—æœˆä»½å æ¯”
#4ï¼Œçœ‹æ–°å¢å› å­æ˜¯å¦å¢åŠ äº†ä¿¡æ¯ä»·å€¼ã€‚(ä»çŸ­æœŸæ•ˆåº”çš„è§’åº¦ï¼Œä¹Ÿè®¸æŸä¸€å¹´æŸå› å­å®ç°äº†ä»·å€¼ï¼Œ
# åœ¨ä¸‹ä¸€å¹´åº¦æŠ•èµ„è€…ä»ç„¶ä¼šä½¿ç”¨è¯¥å› å­ï¼Œç›´åˆ°æŠ•èµ„ç»“æœæŒç»­ä¸ä½³æˆ–è€…ç²¾ç¡®è®¡é‡è¯¥å› å­æ•ˆåº”çš„æ•°æ®å‡ºç°ã€‚)
# æ•°æ®åŒºé—´ï¼šzxjt ç”¨çš„æ•°æ®æ—¶ 2008-2018
# éš¾ç‚¹1ï¼šè€Œéçº¿æ€§è§„æ¨¡å› å­åˆ™ä¸»è¦å¼ºè°ƒçš„æ˜¯å¸‚å€¼ä¸­ç­‰çš„è‚¡ç¥¨ï¼Œè®¡ç®—æ–¹æ³•ä¸ºè§„æ¨¡å› å­çš„ç«‹æ–¹,ç„¶åå’Œè§„æ¨¡å› å­è¿›è¡Œæ–½å¯†ç‰¹æ­£
#   äº¤åŒ–å¤„ç†å»æ‰å…¶å…±çº¿æ€§çš„éƒ¨åˆ†ï¼Œä½†éçº¿æ€§è§„æ¨¡å› å­ç”±äºæ„é€ å¤æ‚è¶…é¢æ”¶ç›Šä¸€èˆ¬è¾ƒéš¾è·å¾—ã€‚ 
# éš¾ç‚¹2ï¼šGrowth æˆé•¿å› å­ç¼ºå¤±å€¼è¾ƒå¤šï¼Œå¤šç©ºæ”¶ç›Šè®¡ç®—è¯¯å·®è¾ƒå¤§ï¼Œå› æ­¤åœ¨è¿™é‡Œæ²¡æœ‰åŠ å…¥å¯¹æ¯”
# å˜åŒ–ï¼šå€¼å¾—æ³¨æ„çš„æ˜¯è§„æ¨¡å› å­ï¼Œè¯¥å› å­åœ¨ 2017 å¹´ä¹‹å‰ä¸€ç›´è¢«æ™®éè®¤å®šä¸º Alpha å› å­ï¼ŒA è‚¡å¸‚åœºçš„å°ç›˜è‚¡æº¢ä»·æ•ˆåº”éå¸¸æ˜æ˜¾ï¼Œä½†æœ€è¿‘ä¸¤
# å¹´å¤§ç›˜è‚¡çš„é‡æ–°å´›èµ·å’Œé£æ ¼åˆ‡æ¢ä½¿å¾—è¯¥é£æ ¼å› å­çš„æ³¢åŠ¨ç‡æ€¥å‰§æå‡ï¼ˆå¹´åŒ–æ³¢åŠ¨ç‡å·²ç»ä¸Šå‡åˆ° 5%ï¼‰ï¼Œé£é™©å±æ€§é€
# æ­¥å¢å¼ºï¼Œå› æ­¤è§„æ¨¡å› å­ä½œä¸ºé£é™©å› å­å·²ç»è¢«å¤§å¤šæ•°æŠ•èµ„è€…æ‰€è®¤å¯ã€‚
# source 20180830_ä¸­ä¿¡å»ºæŠ•_é‡‘èå·¥ç¨‹ä¸“é¢˜_ä¸é²æ˜_Barraé£é™©æ¨¡å‹ä»‹ç»åŠä¸ä¸­ä¿¡å»ºæŠ•é€‰è‚¡ä½“ç³»çš„æ¯”è¾ƒ
# Anaï¼šä¼ ç»Ÿè¡Œä¸šå› å­æŒ‰ç…§å¸‚å€¼åŠ æƒä¸­æ€§åŒ–ï¼Œæˆ‘ä»¬è€ƒè™‘æŒ‰ç…§è¿‡å»40-100å¤©æ€»æˆäº¤é‡‘é¢ä¸­æ€§åŒ–
#   é€»è¾‘æ˜¯äº¤æ˜“çš„è§’åº¦ï¼Œå¸‚åœºæ·±åº¦å¯èƒ½æ¯”æµé€šå¸‚å€¼æ›´èƒ½åæ˜ ä¸€æ®µæ—¶é—´å†…å¸‚åœºäº¤æ˜“å¯¹æ‰‹çš„äº¤æ˜“æ„æ„¿ï¼Œ
#   å½“ç„¶ä»æ•°æ®å¤„ç†çš„è§’åº¦ï¼Œä¹Ÿæ›´å®¹æ˜“è·å¾—æ¯æ—¥æˆäº¤é‡‘é¢ï¼›æµåŠ¨å¸‚å€¼ä¸­å¾ˆå®¹æ˜“å­˜åœ¨æ˜¾è‘—æ¯”ä¾‹ä»“ä½ä¸ä¼šå‡ºç°äº¤æ˜“çš„æƒ…å†µã€‚



5ï¼ŒåŸºå‡†æ„å»ºç­–ç•¥ä¸­çš„æƒé‡ç­–ç•¥ï¼Œzxjtç”¨äº†è¡Œä¸šå†…å¸‚å€¼åŠ æƒæˆ–ç­‰æƒï¼ŒæŒ‡æ•°å†…è¡Œä¸šå¸‚å€¼åŠ æƒ/ç­‰æƒï¼Œè¡ç”Ÿæ–¹é¢è¿˜å¯¹5æŒ¡è‚¡ç¥¨çš„å20%åšç©º
 
# idea æ‰€æœ‰ç°æœ‰çš„æ¨¡å‹æ–¹æ³•éƒ½å¯ä»¥ä½œä¸ºä¸€ä¸ªæ¨¡å—ï¼Œåœ¨å…¶ä¹‹ä¸Šè¿›è¡ŒåŠ å¼ºã€‚
idea dbçš„è§’åº¦ï¼Œèƒ½ä¸èƒ½å»ºç«‹ä¸€ä¸ªå¼€æºçš„åŸºæœ¬é¢æ•°æ®åº“ï¼Œæœ‰ç»Ÿä¸€çš„æ•°æ®æ ‡å‡†ã€‚
'''