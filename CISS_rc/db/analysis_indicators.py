# -*- encoding:"utf-8"-*-
__author__=" ruoyu.Cheng"

'''
===============================================
TODOï¼šç®€åŒ–class indicator_ashares(),æŠŠæ•°æ®å¯¼å…¥å¯¼å‡ºçš„éƒ¨åˆ†è½¬åˆ° data_io_financial_indicator.py

åŠŸèƒ½ï¼š1ï¼Œå¯¼å…¥å¤–éƒ¨æ•°æ®ï¼Œè®¡ç®—åˆ†æè¿‡ç¨‹å¹¶ç”ŸæˆæŒ‡æ ‡å’Œå› å­ç­‰ã€‚
Function:serve as estimated input for strategy calculation 
last 200327 | since 181109

Classåˆ—è¡¨ï¼š
çˆ¶ç±»ï¼šclass indicators():
å­ç±»1ï¼šclass indicator_ashares():Aè‚¡æŒ‡æ ‡å’Œå› å­ 
    1ï¼Œå¸‚åœºã€è¡Œä¸šå’Œä¸»é¢˜æŒ‡æ•°ï¼šä»·æ ¼å’Œæˆäº¤é‡ï¼›ashares_index_price_vol
    2ï¼Œå¸‚åœºã€è¡Œä¸šå’Œä¸»é¢˜æŒ‡æ•°ï¼šè¡Œä¸šåˆ†ç±»ã€ä¸»é¢˜åˆ†ç±»ã€è¡Œä¸šåŸºæœ¬é¢æ•°æ®ç­‰ï¼›ashares_index_funda
    3ï¼Œä¸ªè‚¡ï¼šä»·æ ¼å’Œæˆäº¤é‡ï¼›ashares_stock_price_vol
    4ï¼Œä¸ªè‚¡ï¼šè´¢åŠ¡å’Œè´¢åŠ¡é¢„æµ‹æŒ‡æ ‡ï¼›ashares_stock_funda
    5ï¼Œä¸ªè‚¡ï¼šè‚¡ä¸œã€æœºæ„æŠ•èµ„è€…ã€æ”¶è´­å…¼å¹¶ç­‰äº‹ä»¶ï¼›ashares_stock_holder_events
    6ï¼ŒåŸºé‡‘ã€æœºæ„æŒ‡æ ‡å’Œå› å­ï¼›ashares_fund_nav_port 
å­ç±»2ï¼šclass analysis_factor():å› å­æ•°æ®åˆ†æ     
        print("æŒ‡æ ‡å’Œå› å­æ•°æ®å¤„ç†") 
        print("indicator_data_adjust_zscore  |æŒ‡æ ‡æ•°æ®æ¸…æ´—è°ƒæ•´ï¼šå»å¼‚å¸¸å€¼å’Œç¼ºå¤±å€¼ï¼›æ ‡å‡†åŒ–") 
        print("indicator_indicator_orthogonal  |å› å­æŒ‡æ ‡æ­£äº¤å¤„ç†") 
        print("indicator_indicator_icir  |å› å­æŒ‡æ ‡ICå’ŒICIRè®¡ç®— ") 
å­ç±»3ï¼š åŠ¨é‡æŒ‡æ ‡ class indicator_momentum():


Notes: 
refernce: rC_Stra_MAX.py 
===============================================
'''
import sys,os
import pandas as pd
import numpy as np
import json
import time
import datetime as dt

# å½“å‰ç›®å½• C:\rc_2023\rc_202X\ciss_web\CISS_rc\db
path_ciss_web = os.getcwd().split("CISS_rc")[0]
path_ciss_rc = path_ciss_web +"CISS_rc\\"
sys.path.append(path_ciss_rc + "config\\" )
sys.path.append(path_ciss_rc + "db\\" )
sys.path.append(path_ciss_rc + "db\\db_assets\\" )
sys.path.append(path_ciss_rc + "db\\data_io\\" )

# sys.path.append("..")
### Import config
from config_data import config_data
config_data_1 = config_data()
from config_indicator import config_indi_financial
config_indi_financial_1 = config_indi_financial()

from data_io_financial_indicator import data_io_financial_indicator
data_io_financial_indicator_1 = data_io_financial_indicator()
# äº¤æ˜“æ—¥listï¼š data_io_financial_indicator_1.obj_data_io["dict"]["tradingday"]
# äº¤æ˜“å‘¨listï¼š data_io_financial_indicator_1.obj_data_io["dict"]["date_list_tradingday"]

#########################################################
class indicators():
    def __init__(self ):
        #########################################################
        ### æ—©æœŸå¯¹è±¡åœ°å€
        self.config_data_1 = config_data_1
        ######################################################################
        ### level 1 ç›®å½•ï¼› ['C:\\zd_zxjtzq\\ciss_web', 
        #  è®¾ç½®æ•°æ®æ–‡ä»¶ä½ç½®
        self.path_ciss_web = config_data_1.obj_config["dict"]["path_ciss_web"]
        self.file_path_admin = self.path_ciss_web + "apps\\rc_data\\"

        ######################################################################
        ### level 1 ç›®å½•:è®¾ç½®db_wind æ•°æ®æ–‡ä»¶ä½ç½®ï¼Œåªè¯»å–æ•°æ®
        self.path0 = config_data_1.obj_config["dict"]["path_db_wind"]
        ### level 2 ç›®å½•
        self.path_wind_adj =  config_data_1.obj_config["dict"]["path_wind_adj"]
        self.path_wind_wds =  config_data_1.obj_config["dict"]["path_wind_wds"]

        ### level 3 ç›®å½•
        # å¯¼å…¥Windå…¨å†å²è¡Œä¸šåˆ†ç±»æ•°æ® || df_600151.SH
        self.path_wind_adj_ind =  config_data_1.obj_config["dict"]["path_rc_ind"] 

        ######################################################################


#########################################################
class indicator_ashares(): 
    # ç±»çš„åˆå§‹åŒ–æ“ä½œ
    def __init__(self):
        ### ç»§æ‰¿çˆ¶ç±»indicatorsçš„å®šä¹‰ï¼Œç­‰ä»·äº 
        indicators.__init__(self)
        #################################################################################
        ### Initialization 

        ### å¯¼å…¥date_list, 
        # äº¤æ˜“æ—¥listï¼š data_io_financial_indicator_1.obj_data_io["dict"]["tradingday"]
        # äº¤æ˜“å‘¨listï¼š data_io_financial_indicator_1.obj_data_io["dict"]["date_list_tradingday"]
        # åŒ¹é…date_startå‰æœ€è¿‘çš„äº¤æ˜“æ—¥æœŸ date_0ï¼ŒåŒ¹é…date_endå‰æœ€è¿‘çš„äº¤æ˜“æ—¥æœŸ date_1
        # notes: "data_check_anndates.csv"ä¸­çš„æ—¥æœŸåŒ…æ‹¬äº†èŠ‚å‡æ—¥ç­‰éAè‚¡äº¤æ˜“æ—¥ï¼Œæ¯”å¦‚0501äº”ä¸€èŠ‚
        # file_name = "date_list_tradingdate_ashares.csv"
        # df_dates = pd.read_csv(self.file_path_admin + file_name  )
        # type of date_list is numpy.int64
        self.date_list = data_io_financial_indicator_1.obj_data_io["dict"]["date_list_tradingday"]

        #################################################################################

    def print_info(self):
        ### print all modules for current script
        print("å¤šèµ„äº§-Aè‚¡ï¼Œclass indicator_ashares")
        print("1ï¼Œå¸‚åœºã€è¡Œä¸šå’Œä¸»é¢˜æŒ‡æ•°ï¼šå¯¼å…¥æŒ‡æ•°æˆåˆ†å’Œæƒé‡ï¼›ashares_index_constituents")
        print("1ï¼Œå¸‚åœºã€è¡Œä¸šå’Œä¸»é¢˜æŒ‡æ•°ï¼šä»·æ ¼å’Œæˆäº¤é‡ï¼›ashares_index_price_vol")
        print("2ï¼Œå¸‚åœºã€è¡Œä¸šå’Œä¸»é¢˜æŒ‡æ•°ï¼šè¡Œä¸šåˆ†ç±»ã€ä¸»é¢˜åˆ†ç±»ã€è¡Œä¸šåŸºæœ¬é¢æ•°æ®ç­‰ï¼›ashares_index_funda")
        print("3ï¼Œä¸ªè‚¡ï¼šä»·æ ¼å’Œæˆäº¤é‡ï¼›ashares_stock_price_vol")
        print("3.1ï¼Œä¸ªè‚¡ï¼šä»·æ ¼å’Œæˆäº¤é‡å­é›†ï¼šç´¯è®¡æ”¶ç›Šç‡,å¹³å‡æ”¶ç›Šç‡ï¼Œæœ€å¤§å›æ’¤ï¼Œæ³¢åŠ¨ç‡ï¼›ashares_stock_price_vol_sub " )
        print("3.2ï¼Œä¸ªè‚¡ï¼šåŒºé—´ä»·æ ¼å˜åŠ¨å’Œæ¶¨è·Œå¹…ï¼šashares_stock_price_vol_change " )  
        
        print("4ï¼Œä¸ªè‚¡ï¼šå¸‚å€¼ï¼Œè´¢åŠ¡å’Œè´¢åŠ¡é¢„æµ‹æŒ‡æ ‡ï¼›ashares_stock_funda")
        print("5ï¼Œä¸ªè‚¡ï¼šè‚¡ä¸œã€æœºæ„æŠ•èµ„è€…ã€æ”¶è´­å…¼å¹¶ç­‰äº‹ä»¶ï¼›ashares_stock_holder_events")
        print("6ï¼ŒåŸºé‡‘ã€æœºæ„æŒ‡æ ‡å’Œå› å­ï¼›ashares_fund_nav_port")

        return 1 

    #################################################################################
    ### 1ï¼Œå¸‚åœºã€è¡Œä¸šå’Œä¸»é¢˜æŒ‡æ•°ï¼šå¯¼å…¥æŒ‡æ•°æˆåˆ†å’Œæƒé‡ï¼›
    def ashares_index_constituents(self,obj_in) :
        ### æ ¹æ®æ—¥æœŸå’ŒæŒ‡æ•°ä»£ç ï¼Œè·å–æŒ‡æ•°æˆåˆ†è‚¡
        '''
        obj_in["date_start"] = "20050501"
        obj_in["code_index"] = "000300.SH"
        obj_in["table_name"] = "AIndexHS300FreeWeight"
        '''
        date_start = obj_in["date_start"]
        date_list_new = [date for date in self.date_list if date<= int(date_start) ]
        
        date_0 = date_list_new[-1]
        file_name = "WDS_TRADE_DT_"+ str(date_0) +"_ALL.csv"
        print("file_name ",file_name )
        df0 = pd.read_csv(self.path_wind_wds + obj_in["table_name"]+"\\"+ file_name  )
        # print("df0" ,df0.head().T )
        df1= df0[ df0["S_INFO_WINDCODE"] == obj_in["code_index"]  ]
        # print("df1" ,df1.head().T )

        obj1={}

        obj_in["df_ashares_index_consti"] = df1

        return obj_in

    #################################################################################
    ### 1ï¼Œå¸‚åœºã€è¡Œä¸šå’Œä¸»é¢˜æŒ‡æ•°ï¼šä»·æ ¼å’Œæˆäº¤é‡
    def ashares_index_price_vol(self) :
        # 1ï¼Œå¸‚åœºã€è¡Œä¸šå’Œä¸»é¢˜æŒ‡æ•°ï¼šä»·æ ¼å’Œæˆäº¤é‡
        


        return 1

    def ashares_index_price_vol_sub(self,obj_in ) :
        # 1.1ï¼Œå‡ ç§ç±»å‹ï¼šæ—¶ç‚¹æ•°æ®ï¼ŒåŒºé—´æ•°æ®
        ''' obj_in={}
        obj_in["type_date"] = 1 means 1date ;2 means period
        obj_in["date_start"] = "20050501"
        obj_in["date_end"] = "20050701"
        obj_in["type_indi"] = 1 means price ;2 means vol
        obj_in["code"] = "000300.SH"
        obj_in["table_name"] = "AIndexEODPrices"
        
        notes:
        1,æ²ªæ·±300æŒ‡æ•°çš„å…¨æ”¶ç›ŠæŒ‡æ•°H000300.SHæ¨å‡ºæ—¥æœŸæ˜¯ 20060405
        æŒ‡æ•°é»˜è®¤æ˜¯ä¸è€ƒè™‘åˆ†çº¢çš„é‚£éƒ¨åˆ†é’±çš„ã€‚æˆ‘ä»¬å¹³æ—¶çœ‹åˆ°çš„ä¸Šè¯50ã€æ²ªæ·±300ã€æ’ç”Ÿã€Hè‚¡æŒ‡æ•°ç­‰ç­‰ï¼Œéƒ½æ˜¯æŠŠæ¯å¹´çš„åˆ†çº¢æ’é™¤åœ¨å¤–çš„ç‚¹æ•°ã€‚
        ä¸è€ƒè™‘åˆ†çº¢å’ŒæŠŠåˆ†çº¢å†æŠ•å…¥ï¼Œè¿™ä¸¤è€…æ”¶ç›Šä¼šæœ‰å¾ˆå¤§å·®åˆ«ã€‚æŒ‡æ•°å…¬å¸ä¹Ÿè€ƒè™‘äº†è¿™ä¸€ç‚¹ï¼Œæ‰€ä»¥ä¹Ÿè®¾è®¡äº†å…¨æ”¶ç›ŠæŒ‡æ•°ã€‚å…¨æ”¶ç›ŠæŒ‡æ•°ä¼šé»˜è®¤æŠŠåˆ†çº¢å†æŠ•å…¥è€ƒè™‘è¿›æ¥ã€‚
        2,è‚¡ç¥¨é€šå¸¸æ˜¯æŒ‰åˆ—è¡¨è¯»å–æ•°æ®ï¼ŒæŒ‡æ•°é€šå¸¸åªè¯»å–1ä¸ª
        '''
        type_date = obj_in["type_date"]
        date_start = obj_in["date_start"] 
        date_end = obj_in["date_end"] 
        type_indi = obj_in["type_indi"] 
        wind_code = obj_in["code"] 
        table_name = obj_in["table_name"] 
        info = 'wind_code: {wind_code},date_start: {date_start} ,date_end: {date_end}'.format(wind_code=wind_code,date_start=date_start,date_end=date_end) 
        print(info)
        ### 1date æ—¶ç‚¹æƒ…å†µï¼š


        ### periodåŒºé—´æƒ…å†µï¼š
        ### 1ï¼Œå¯¼å…¥ç›¸å…³æ•°æ®ï¼Œç”Ÿæˆ[T,T+1]åŒºé—´æ¯ä¸ªäº¤æ˜“æ—¥æ•°æ®df 

        # date_list_new = [date for date in date_list if date<= int(date_start)  ]
        # date_0 = date_list_new[-1]
        date_list_new = [date for date in self.date_list if date>= int(date_start) and date<= int(date_end) ]
        
        
        ### è¯»å–date_0 ~ date_1 æœŸé—´æ¯ä¸ªäº¤æ˜“æ—¥çš„æŒ‡æ•°æ•°æ®
        count_date = 0 
        for temp_date in date_list_new :
            #type(temp_date ) = int
            
            # WDS_TRADE_DT_20050104_ALL.csv
            file_name = "WDS_TRADE_DT_"+ str( temp_date ) +"_ALL.csv"
            df0 = pd.read_csv( self.path_wind_wds +table_name+"\\"+ file_name  )
            df1= df0[ df0["S_INFO_WINDCODE"]== wind_code ]
            if count_date == 0 :
                df_index_price = df1 
                count_date = 1 
            else :
                df_index_price = df_index_price.append(df1,ignore_index=True  ) 

        df_index_price =df_index_price.sort_values(by="TRADE_DT")
        ### 2ï¼Œè®¡ç®—åŒºé—´æ—¥å‡æ¶¨è·Œå¹…ï¼Œç´¯è®¡æ¶¨è·Œå¹…ï¼Œæ—¥å‡æ³¢åŠ¨ç‡ï¼›å‘¨
        # notesï¼šç”¨S_DQ_CHANGE	S_DQ_PCTCHANGE ä¸¤ä¸ªè®¡ç®—çš„æ¯æ—¥æ”¶ç›Šç‡æ˜¯ä¸€æ ·çš„
        # è¿™é‡Œçš„ç™¾åˆ†æ¯”å˜åŠ¨éœ€è¦é™¤ä»¥100ï¼Œ "S_DQ_PCTCHANGE"
        preclose_0 = df_index_price.loc[df_index_price.index[0],"S_DQ_PRECLOSE"  ]
        # æ–¹æ³•ä¸€ï¼Œè®¡ç®—ç»å¯¹ç‚¹ä½ç´¯è®¡å˜åŠ¨åï¼ŒåŠ ä¸ŠæœŸåˆå€¼ï¼Œå†ç»Ÿä¸€é™¤ä»¥é¦–æ—¥å‰æ”¶ç›˜ä»·
        # df_index_price["S_DQ_CHANGE_cumsum"] = df_index_price["S_DQ_CHANGE"].cumsum()
        # df_index_price["pct_chg_accu"] = df_index_price["S_DQ_CHANGE_cumsum"]/preclose_0
        # æ–¹æ³•äºŒï¼šå¯¹æ¯æ—¥æ¶¨è·Œå¹… é™¤ä»¥100åŠ ä¸Š1åç´¯ä¹˜ï¼Œæœ€åå†å‡1
        df_index_price["S_DQ_PCTCHANGE_cumprod"] = df_index_price["S_DQ_PCTCHANGE"]/100 +1 
        df_index_price["ret_pct_accu"] =df_index_price["S_DQ_PCTCHANGE_cumprod"].cumprod() -1

        ### TODO å¦‚ä½•æ ¹æ®æ—¥æœŸé¢‘ç‡date_freqï¼Œè®¡ç®—å‘¨/æœˆ/å­£åº¦çš„å¹³å‡æ”¶ç›Šç‡å’Œæ³¢åŠ¨ç‡ï¼Ÿï¼Ÿï¼Ÿ
        ### ç´¯è®¡æ”¶ç›Šç‡,å¹³å‡æ”¶ç›Šç‡ï¼Œæœ€å¤§å›æ’¤ï¼Œæ³¢åŠ¨ç‡ || 
        ret_pct_accu = df_index_price.loc[ df_index_price.index[-1] ,"ret_pct_accu"]
        ret_pct_ave = df_index_price["S_DQ_PCTCHANGE"].mean() /100
        ret_pct_std = (df_index_price["S_DQ_PCTCHANGE"]/100).std() 
        ### æœ€å¤§å›æ’¤ mddè®¡ç®— url https://blog.csdn.net/weixin_38997425/article/details/82915386
        mdd= 0.0 
        for temp_i in df_index_price.index :
            temp_mdd = (1+df_index_price.loc[temp_i, "ret_pct_accu"]) / (1+ df_index_price.loc[:temp_i, "ret_pct_accu"].max())-1
            mdd = min( mdd,temp_mdd )
        print("mdd", mdd)
        print("ret_pct_accu ret_pct_ave ,ret_pct_std,mdd",ret_pct_accu,ret_pct_ave ,ret_pct_std,mdd)

        ### to csv
        # df_index_price.to_csv("D:\\df_index_price.csv")
        
        obj_out ={}
        obj_out["df_index_price"] = df_index_price
        obj_out["df_index_price"] = df_index_price
        obj_out["ret_pct_accu"] =ret_pct_accu
        obj_out["ret_pct_ave"] =ret_pct_ave
        obj_out["ret_pct_std"] =ret_pct_std
        obj_out["mdd"] =mdd

        return obj_out 

    #################################################################################
    def ashares_index_funda(self) :
        # 2ï¼Œå¸‚åœºã€è¡Œä¸šå’Œä¸»é¢˜æŒ‡æ•°ï¼šè¡Œä¸šåˆ†ç±»ã€ä¸»é¢˜åˆ†ç±»ã€è¡Œä¸šåŸºæœ¬é¢æ•°æ®ç­‰ï¼›



 









        return 1

    #################################################################################
    def ashares_stock_price_vol(self,obj_in) :
        ### 3ï¼Œä¸ªè‚¡ï¼šä»·æ ¼å’Œæˆäº¤é‡ç­‰æŒ‡æ ‡æ•°æ®
 








        obj_out = obj_in
        return obj_out

    def ashares_stock_price_vol_sub(self,obj_in ) :
        ### 3.1ï¼Œä¸ªè‚¡ï¼šä»·æ ¼å’Œæˆäº¤é‡å­é›†ï¼šç´¯è®¡æ”¶ç›Šç‡,å¹³å‡æ”¶ç›Šç‡ï¼Œæœ€å¤§å›æ’¤ï¼Œæ³¢åŠ¨ç‡
        # 1.1ï¼Œå‡ ç§ç±»å‹ï¼šæ—¶ç‚¹æ•°æ®ï¼ŒåŒºé—´æ•°æ®
        ''' obj_in={}
        obj_in["date_start"] = "20050501"
        obj_in["table_name"] = "AShareEODPrices" 
        obj_in["df_factor"] = df_factor  ;"wind_code"  in columns

        Input:
        Inidicators:
        è¿‘1ä¸ªæœˆæ—¥å‡æˆäº¤é¢æ¯”è¿‘6ä¸ªæœˆæ—¥å‡æˆäº¤é¢å‡å€¼ amt_ave_1m_6m = amt_ave_1m/amt_ave_6m
        è¿‘1ä¸ªæœˆæ—¥å‡æ¢æ‰‹ç‡æ¯”è¿‘6ä¸ªæœˆæ—¥å‡æ¢æ‰‹ç‡å‡å€¼ turnover_ave_1m_6m= turnover_ave_1m/turnover_ave_6m
        è¿‘1ä¸ªæœˆæ—¥å‡æ³¢åŠ¨ç‡æ¯”è¿‘6ä¸ªæœˆæ—¥å‡æ³¢åŠ¨ç‡æ ‡å‡†å·® volatility_std_1m_6m= volatility_std_1m/volatility_std_6m
        20å¤©ç§»åŠ¨å¹³å‡ä»·æ ¼æ¯”120å¤©ç§»åŠ¨å¹³å‡ä»·æ ¼ ma_20d_120d = ma_20d/ma_120d
        20å¤©å¹³å‡æ¶¨è·Œå¹…æ¯”120å¤©å¹³å‡æ¶¨è·Œå¹… ret_averet_ave_20d_120d = ret_averet_ave_20d/ret_averet_ave_120d
        20å¤©ç´¯è®¡æ¶¨è·Œå¹…æ¯”120å¤©ç´¯è®¡æ¶¨è·Œå¹… ret_accumu_20d_120d = ret_accumu_20d/ret_accumu_120d
        20å¤©å†…æœ€å¤§å›æ’¤æ¯”120å¤©å†…æœ€å¤§å›æ’¤ ret_mdd_20d_120d = (1+ret_mdd_20d)/((1+ret_mdd_120d)
        æ”¶ç›˜ä»·åœ¨è¿‡å»52å‘¨å†…ç™¾åˆ†æ¯” close_pct_52w = 52å‘¨æœ€é«˜ä»·(å¤æƒ)ï¼ŒS_PQ_ADJHIGH_52W/52å‘¨æœ€ä½ä»·(å¤æƒ)ï¼ŒS_PQ_ADJLOW_52W
        æ”¶ç›˜ä»·åœ¨è¿‡å»52å‘¨å†…ç™¾åˆ†æ¯” close_pct_52w = (close_52w_last -close_52w_low)/(close_52w_high -close_52w_low)
        Output:

        notes:
        1ï¼Œè‚¡ç¥¨é€šå¸¸æ˜¯æŒ‰åˆ—è¡¨è¯»å–æ•°æ®ï¼ŒæŒ‡æ•°é€šå¸¸åªè¯»å–1ä¸ª
        2ï¼Œ"AShareEODPrices" é‡è¦æŒ‡æ ‡ï¼š
            S_DQ_CLOSE å½“æ—¥æ”¶ç›˜ä»·
            S_DQ_ADJPRECLOSE åå¤æƒå‰ä¸€æ—¥æ”¶ç›˜ä»·
            S_DQ_ADJCLOSE åå¤æƒå½“æ—¥æ”¶ç›˜ä»·
            S_DQ_ADJFACTORï¼šå¤æƒå› å­= S_DQ_ADJCLOSE/ S_DQ_CLOSE
        ''' 
        date_start = obj_in["date_start"] 
        table_name = obj_in["table_name"] 
        df_factor = obj_in["df_factor"] 
        table_name_derivative = "AShareEODDerivativeIndicator" 
        table_name_index_price = "AIndexEODPrices"

        info = 'table_name: {table_name},date_start: {date_start}  '.format(table_name=table_name,date_start=date_start ) 
        print(info)
        '''TODO æ ¹æ®æ—¥è¡Œæƒ…æ•°æ®ï¼Œè®¡ç®—å‰æ¨Næ—¥çš„åŒºé—´æ”¶ç›Šç‡ã€æ³¢åŠ¨ç‡ã€æœ€å¤§å›æ’¤ç­‰æŒ‡æ ‡
        
        '''
        ###########################################################################
        ### 1ï¼Œå¯¼å…¥ç›¸å…³æ•°æ®ï¼Œç”Ÿæˆ[T-N,T]åŒºé—´Nä¸ªäº¤æ˜“æ—¥æ•°æ®df,
        # notes:å¯¹äºcode_list ç§çš„éƒ¨åˆ†æ–°ä¸Šå¸‚è‚¡ç¥¨ï¼Œä¸Šå¸‚æ—¥æœŸå¯èƒ½ä½äºNæ—¥
        N = 120
        date_list_pre = [date for date in self.date_list if date<= int(date_start)  ]
        # ä¾‹ï¼šç°æœ‰æ•°æ®èµ·å§‹æ—¥ä¸º20050104ï¼Œåœ¨20050501å‰æ¨5ä¸ªæœˆä»…æœ‰77ä¸ªäº¤æ˜“æ—¥
        N = min( N,  len(date_list_pre) )
        date_list_pre = date_list_pre[ -1*N:  ]
        date_last = date_list_pre[-1]

        print("Previous N days:", N, len(date_list_pre),date_list_pre )
        
        ###########################################################################
        ### å¯¹æ¯åªè‚¡ç¥¨æ–°å»ºdf_dates,æ‰€æœ‰df_datesä¿å­˜åœ¨obj_stock_dates[temp_code] ã€‚
        # dates as index and indicator as columns   
        # ä»¥ä¸‹æ˜¯è®¡ç®—è¿‡ç¨‹å’Œç»“æœæ‰€æœ‰æŒ‡æ ‡ï¼Œå› å­æŒ‡æ ‡åªæœ‰ä¸€éƒ¨åˆ†ã€‚    
        col_list = ["close_52w_last","close_52w_low", "close_52w_high" ,"close_pct_52w"]
        col_list = col_list +["amt_ave_1m","amt_ave_6m","amt_ave_1m_6m","turnover_ave_1m","turnover_ave_6m","turnover_ave_1m_6m" ]
        col_list = col_list +["volatility_std_1m","volatility_std_6m","volatility_std_1m_6m"]
        col_list = col_list +["ret_averet_ave_20d","ret_averet_ave_120d","ret_averet_ave_20d_120d"]
        col_list = col_list +["ma_20d","ma_120d","ma_20d_120d","ret_accumu_20d","ret_accumu_120d","ret_accumu_20d_120d" ]
        col_list = col_list +["ret_mdd_20d","ret_mdd_120d","ret_mdd_20d_120d"]
        col_list = col_list +["ret_alpha_ind_citic_1_20d","ret_alpha_ind_citic_1_120d"]
        col_list = col_list +["ret_alpha_stockpool_mv_20d","ret_alpha_stockpool_mv_120d"]
        col_list = col_list +["ret_alpha_index_bm_20d","ret_alpha_index_bm_120d"]
        
        # obj_stock_dates = {}
        df_dates_stocks = pd.DataFrame( index=date_list_pre, columns= ["0"] )
        df_dates_index = pd.DataFrame( index=date_list_pre, columns= ["0"] )

        for temp_i in df_factor.index :
            temp_code = df_factor.loc[temp_i, "wind_code"  ]
            for temp_col in col_list :
                df_dates_stocks [ temp_code+"_"+temp_col ] = 0.0

        ###########################################################################
        ### è¯»å–[T-N,T]åŒºé—´æœŸé—´æ¯ä¸ªäº¤æ˜“æ—¥çš„è‚¡ç¥¨æ—¥è¡Œæƒ…æ•°æ®
        # å¯¼å…¥wdsè¡¨æ ¼çš„columns.csv
        df_cols = pd.read_csv(self.path_wind_wds + obj_in["table_name"]+"\\"+ "columns.csv"  )
        col_list_1d = df_cols["0"].values
        code_index = df_factor["code_index"].values[0]
        for temp_date in date_list_pre :
            print("temp_date",temp_date )
            ### 1,è¯»å–ä¸ªè‚¡äº¤æ˜“æ—¥è¡Œæƒ…æ•°æ®   WDS_TRADE_DT_20050104_ALL.csv
            file_name = "WDS_TRADE_DT_"+ str( temp_date ) +"_ALL.csv"
            try :
                df0 = pd.read_csv( self.path_wind_wds +table_name+"\\"+ file_name  )
            except :
                df0 = pd.read_csv( self.path_wind_wds +table_name+"\\"+ file_name,encoding="gbk"  )

            for temp_i in df_factor.index :
                temp_code = df_factor.loc[temp_i, "wind_code"  ]
                df1= df0[ df0["S_INFO_WINDCODE"]== temp_code ]
                
                if len( df1.index ) > 0 :
                    temp_j = df1.index[0]
                    for temp_col in col_list_1d :
                        df_dates_stocks.loc[temp_date, temp_code+"_"+temp_col ]= df1.loc[ temp_j , temp_col ]
                else :
                    for temp_col in col_list_1d :
                        df_dates_stocks.loc[temp_date, temp_code+"_"+temp_col ]= np.nan
            
            ### 2,è¯»å–ä¸ªè‚¡æ—¥è¡ç”Ÿè¡Œæƒ…é‡Œçš„æ¢æ‰‹ç‡æŒ‡æ ‡            
            # æ¢æ‰‹ç‡ï¼ŒS_DQ_TURNï¼ŒNUMBER(20,4)ï¼Œ%ï¼Œæ¢æ‰‹ç‡(åŸºå‡†.è‡ªç”±æµé€šè‚¡æœ¬)ï¼ŒS_DQ_FREETURNOVER
            # notes:001872.SZåœ¨200501-200505ä¹‹é—´æ²¡æœ‰æ—¥è¡ç”Ÿè¡Œæƒ…ï¼Œä½†è‚¡ç¥¨1993å¹´å°±ä¸Šå¸‚äº†ã€‚ç”±äºå‘ç”Ÿäº†æ”¶è´­å…¼å¹¶ï¼Œæ—¥è¡ç”Ÿè¡Œæƒ…åœ¨20171225ä¹‹åæ‰æœ‰æ•°æ®ã€‚

            temp_col ="S_DQ_FREETURNOVER"
            file_name = "WDS_TRADE_DT_"+ str( temp_date ) +"_ALL.csv"
            df0 = pd.read_csv( self.path_wind_wds +table_name_derivative  +"\\"+ file_name  )
            for temp_i in df_factor.index :
                temp_code = df_factor.loc[temp_i, "wind_code"  ]
                df1= df0[ df0["S_INFO_WINDCODE"]== temp_code ]
                
                if len( df1.index ) > 0 :                    
                    temp_j = df1.index[0]
                    df_dates_stocks.loc[temp_date, temp_code+"_"+temp_col ]= df1.loc[ temp_j , temp_col ]
                else :
                    df_dates_stocks.loc[temp_date, temp_code+"_"+temp_col ]= np.nan
            
            ### 3 è¯»å–æŒ‡æ•°äº¤æ˜“æ—¥è¡Œæƒ…æ•°æ®   WDS_TRADE_DT_20050104_ALL.csv
            # table_name_index_price = "AIndexEODPrices"
            file_name = "WDS_TRADE_DT_"+ str( temp_date ) +"_ALL.csv"
            df0 = pd.read_csv( self.path_wind_wds +table_name_index_price +"\\"+ file_name  )
            
            # code_index = df_factor["code_index"].values[0] 
            df1= df0[ df0["S_INFO_WINDCODE"]== code_index ] 
            if len( df1.index ) > 0 :
                temp_j = df1.index[0]
                ## å¯¹äºæŒ‡æ•°ï¼Œåªéœ€è¦ä¸‰ä¸ªï¼šæ”¶ç›˜ä»·(ç‚¹)ï¼ŒS_DQ_CLOSEï¼›æ¶¨è·Œå¹…(%)ï¼ŒS_DQ_PCTCHANGEï¼›æˆäº¤é‡‘é¢(åƒå…ƒ)ï¼ŒS_DQ_AMOUNT
                for temp_col in ["S_DQ_CLOSE","S_DQ_PCTCHANGE","S_DQ_AMOUNT"  ] :
                    df_dates_stocks.loc[temp_date, code_index+"_"+temp_col ]= df1.loc[ temp_j , temp_col ]
            else :
                for temp_col in col_list_1d :
                    df_dates_stocks.loc[temp_date, code_index+"_"+temp_col ]= np.nan
        
        ###########################################################################

        ### æŒ‡æ ‡è®¡ç®—ï¼Œå¯¹æ¯åªä¸ªè‚¡çš„å†å²æ—¥è¡Œæƒ…åºåˆ—               
        for temp_i in df_factor.index :
            temp_code = df_factor.loc[temp_i, "wind_code"  ] 
            print("temp_code",temp_code )
            #################################################################################
            ### æ”¶ç›˜ä»·åœ¨è¿‡å»52å‘¨å†…ç™¾åˆ†æ¯” close_pct_52w = (close_52w_last -close_52w_low)/(close_52w_high -close_52w_low)
            # è¿™æ˜¯æœ€ç®€å•çš„ï¼Œä¸éœ€è¦å†å²æ—¶é—´åºåˆ— | "S_PQ_ADJHIGH_52W"== "close_52w_high";"S_PQ_ADJLOW_52W"=="close_52w_low";
            # notes:"S_PQ_ADJHIGH_52W"sæ˜¯åœ¨df_factorä¹‹å‰å·²ç»å¯¼å…¥äº†çš„æŒ‡æ ‡
            temp_col_high = "S_PQ_ADJHIGH_52W"
            temp_col_low = "S_PQ_ADJLOW_52W"
            temp_col = "S_DQ_CLOSE_TODAY"
            df_factor.loc[temp_i, "close_52w_high"] = df_factor.loc[temp_i, "S_PQ_ADJHIGH_52W"]
            df_factor.loc[temp_i, "close_52w_low"] = df_factor.loc[temp_i, "S_PQ_ADJLOW_52W"]
            df_factor.loc[temp_i, "close_52w_last"] =  df_factor.loc[temp_i, "S_DQ_CLOSE_TODAY"]
            df_factor.loc[temp_i, "close_pct_52w"] = (df_factor.loc[temp_i, "close_52w_last"]- df_factor.loc[temp_i, "close_52w_low"] )/(df_factor.loc[temp_i, "close_52w_high"]  -df_factor.loc[temp_i, "close_52w_low"] )
            
            # notes:è‹¥ä¸€åˆ—ä¸­æœ‰np.nan,è®¡ç®—å¹³å‡å€¼æ—¶ä¼šè‡ªåŠ¨å¿½ç•¥ã€‚
            #################################################################################
            ### è¿‘1ä¸ªæœˆæ—¥å‡æˆäº¤é¢æ¯”è¿‘6ä¸ªæœˆæ—¥å‡æˆäº¤é¢å‡å€¼ amt_ave_1m_6m = amt_ave_1m/amt_ave_6m
            # æˆäº¤é‡‘é¢(åƒå…ƒ)ï¼ŒS_DQ_AMOUNT
            temp_col = "S_DQ_AMOUNT"
            # if "amt_ave_1m" in df_factor.columns and "amt_ave_6m" in df_factor.columns :
            df_factor.loc[temp_i, "amt_ave_1m"] = df_dates_stocks.loc[ date_list_pre[-20:]  ,temp_code+"_"+temp_col].mean()
            df_factor.loc[temp_i, "amt_ave_6m"] = df_dates_stocks.loc[date_list_pre[-1*N:] ,temp_code+"_"+temp_col].mean()
            df_factor.loc[temp_i, "amt_ave_1m_6m"] = df_factor.loc[temp_i, "amt_ave_1m"]/df_factor.loc[temp_i, "amt_ave_6m"]
            #################################################################################
            ### è¿‘1ä¸ªæœˆæ—¥å‡æ¢æ‰‹ç‡æ¯”è¿‘6ä¸ªæœˆæ—¥å‡æ¢æ‰‹ç‡å‡å€¼ turnover_ave_1m_6m= turnover_ave_1m/turnover_ave_6m
            # æ¢æ‰‹ç‡(åŸºå‡†.è‡ªç”±æµé€šè‚¡æœ¬)ï¼ŒS_DQ_FREETURNOVER from ä¸­å›½Aè‚¡æ—¥è¡Œæƒ…ä¼°å€¼æŒ‡æ ‡[AShareEODDerivativeIndicator]
            temp_col = "S_DQ_FREETURNOVER"
            df_factor.loc[temp_i, "turnover_ave_1m"] = df_dates_stocks.loc[ date_list_pre[-20:]  ,temp_code+"_"+temp_col].mean()
            df_factor.loc[temp_i, "turnover_ave_6m"] = df_dates_stocks.loc[date_list_pre[-1*N:] ,temp_code+"_"+temp_col].mean()
            df_factor.loc[temp_i, "turnover_ave_1m_6m"] = df_factor.loc[temp_i, "turnover_ave_1m"]/df_factor.loc[temp_i, "turnover_ave_6m"]
            #################################################################################
            ### è¿‘1ä¸ªæœˆæ—¥å‡æ³¢åŠ¨ç‡æ¯”è¿‘6ä¸ªæœˆæ—¥å‡æ³¢åŠ¨ç‡æ ‡å‡†å·® volatility_std_1m_6m= volatility_std_1m/volatility_std_6m
            # æ³¢åŠ¨ç‡ ï¼šæ¶¨è·Œå¹…(%)ï¼ŒS_DQ_PCTCHANGE
            temp_col = "S_DQ_PCTCHANGE"
            df_factor.loc[temp_i, "volatility_std_1m"] = df_dates_stocks.loc[date_list_pre[-20:] ,temp_code+"_"+temp_col].std()
            df_factor.loc[temp_i, "volatility_std_6m"] = df_dates_stocks.loc[date_list_pre[-1*N:] ,temp_code+"_"+temp_col].std()
            df_factor.loc[temp_i, "volatility_std_1m_6m"] =df_factor.loc[temp_i, "volatility_std_1m"] /df_factor.loc[temp_i, "volatility_std_6m"] 

            ### 20å¤©å¹³å‡æ¶¨è·Œå¹…æ¯”120å¤©å¹³å‡æ¶¨è·Œå¹… ret_averet_ave_20d_120d = ret_averet_ave_20d/ret_averet_ave_120d
            df_factor.loc[temp_i, "ret_averet_ave_20d"] = df_dates_stocks.loc[date_list_pre[-20:] ,temp_code+"_"+temp_col].mean()
            df_factor.loc[temp_i, "ret_averet_ave_120d"] = df_dates_stocks.loc[date_list_pre[-1*N:] ,temp_code+"_"+temp_col].mean()
            df_factor.loc[temp_i, "ret_averet_ave_20d_120d"] =df_factor.loc[temp_i, "ret_averet_ave_20d"] /df_factor.loc[temp_i, "ret_averet_ave_120d"] 
            #################################################################################
            ### 20å¤©ç§»åŠ¨å¹³å‡ä»·æ ¼æ¯”120å¤©ç§»åŠ¨å¹³å‡ä»·æ ¼ ma_20d_120d = ma_20d/ma_120d
            # å¤æƒæ”¶ç›˜ä»·(å…ƒ),S_DQ_ADJCLOSE
            temp_col = "S_DQ_ADJCLOSE"
            df_factor.loc[temp_i, "ma_20d"] = df_dates_stocks.loc[date_list_pre[-20:] ,temp_code+"_"+temp_col].mean()
            df_factor.loc[temp_i, "ma_120d"] = df_dates_stocks.loc[date_list_pre[-1*N:] ,temp_code+"_"+temp_col].mean()
            df_factor.loc[temp_i, "ma_20d_120d"] =df_factor.loc[temp_i, "ma_20d"] /df_factor.loc[temp_i, "ma_120d"] 
            #################################################################################
            ### 20å¤©ç´¯è®¡æ¶¨è·Œå¹…æ¯”120å¤©ç´¯è®¡æ¶¨è·Œå¹… ret_accumu_20d/ret_accumu_120d
            # å¦‚æœæœŸåˆæ—¥æ— æ•°å€¼ï¼Œåˆ™æ—¥æ¶¨è·Œå¹…æˆ–æ—¥æ”¶ç›˜ä»·éƒ½ç®—ä¸å‡ºæ¥ç´¯è®¡æ”¶ç›Š |  "S_DQ_PCTCHANGE",S_DQ_ADJCLOSE
            temp_col = "S_DQ_ADJCLOSE"
            
            # temp_nä¸ªäº¤æ˜“æ—¥ï¼Œæ›¿ä»£Nï¼Œåˆ é™¤NaNæ‰€åœ¨è¡Œ
            temp_df_close_adj = df_dates_stocks.loc[ : , temp_code+"_"+temp_col]
            temp_df_close_adj = temp_df_close_adj.dropna( axis=0, how="all" ).to_frame()
            date_list_sub = temp_df_close_adj.index

            # è‹¥æ€»è®°å½•æ•°é‡å°äºN=120,å¦‚77ï¼Œåˆ™æå–å‰77ä¸ªè®°å½•
            temp_n = min(N,len(temp_df_close_adj.index ))
            # è‹¥æ€»è®°å½•æ•°é‡å°äºN=20,å¦‚19ï¼Œåˆ™æå–å‰19ä¸ªè®°å½•
            temp_n_20 = min(20 ,len(temp_df_close_adj.index ))

            temp_close_pre_1  =  temp_df_close_adj.loc[date_list_sub[-1] ,temp_code+"_"+temp_col]
            temp_close_pre_20 =  temp_df_close_adj.loc[date_list_sub[-1*temp_n_20 ] ,temp_code+"_"+temp_col] 
            temp_close_pre_N  =  temp_df_close_adj.loc[date_list_sub[0] ,temp_code+"_"+temp_col]  

            print("type temp_df_close_adj", temp_close_pre_1/ temp_close_pre_20 ,temp_close_pre_1/ temp_close_pre_N  )

            df_factor.loc[temp_i, "ret_accumu_20d"] = temp_close_pre_1/ temp_close_pre_20 -1
            df_factor.loc[temp_i, "ret_accumu_120d"] = temp_close_pre_1/ temp_close_pre_N -1 
            # (temp_close_pre_1/ temp_close_pre_20 )/( temp_close_pre_1/ temp_close_pre_N ) = temp_close_pre_N / temp_close_pre_20
            df_factor.loc[temp_i, "ret_accumu_20d_120d"] = temp_close_pre_N / temp_close_pre_20 -1 
            #################################################################################
            ### 20å¤©å†…æœ€å¤§å›æ’¤æ¯”120å¤©å†…æœ€å¤§å›æ’¤ ret_mdd_20d_120d = ret_mdd_20d/ret_mdd_120d
            df_factor.loc[temp_i, "ret_mdd_20d"] = 0.0
            df_factor.loc[temp_i, "ret_mdd_120d"] = 0.0
            # for past 20 days ,å°‘æ•°æƒ…å†µä¸‹120å¤©å†…æœ‰äº¤æ˜“æ—¥å°äº20å¤©
            temp_close_max= 0.0
            temp_mdd= 0.0 
            for j in range( min(temp_n_20,temp_n ) ) :
                # temp_j= 0,1,...19; -20+temp_j=-20,-19,...-1
                temp_j = date_list_sub[-1*temp_n_20+j]
                temp_close = temp_df_close_adj.loc[ temp_j, temp_code+"_"+temp_col ]
                temp_close_max = max(temp_close_max,temp_close )
                temp_mdd = min(temp_mdd, temp_close/temp_close_max-1 )
            df_factor.loc[temp_i, "ret_mdd_20d"] = temp_mdd
            # for past 120 days | temp_n =min(N,len(temp_df_close_adj.index )
            temp_close_max= 0.0
            temp_mdd= 0.0 
            for j in range( temp_n )  :
                # temp_j= 0,1,...N-1; -N+temp_j=-N,-N+1,...-1
                temp_j = date_list_sub[-1*temp_n+j]
                temp_close = temp_df_close_adj.loc[ temp_j, temp_code+"_"+temp_col ]
                temp_close_max = max(temp_close_max,temp_close )
                temp_mdd = min(temp_mdd, temp_close/temp_close_max-1 )   

            df_factor.loc[temp_i, "ret_mdd_120d"] = temp_mdd
            # notes:20å¤©å†…çš„æœ€å¤§å›æ’¤mddè‚¯å®šæ¯”120å¤©å†…å°‘ï¼Œç›¸å¯¹å›æ’¤çœ‹çš„æ˜¯20å¤©å†…çš„ä¸‹è·Œå¹…åº¦è¾¾åˆ°äº†è¿‡å»120å¤©æœ€å¤§è·Œå¹…çš„ç™¾åˆ†æ¯”
            # ä¾‹å¦‚: (1-0.1)/(1-0.2)=0.9/0.8=1.125,å€¼è¶Šå¤§è¯´æ˜çŸ­æœŸè·Œçš„è¶Šå°‘ï¼Œ1.0æ„å‘³ç€çŸ­æœŸè·Œå¹…è¦†ç›–äº†120å¤©å†…çš„å…¨éƒ¨è·Œå¹…
            df_factor.loc[temp_i, "ret_mdd_20d_120d"] = (1+ df_factor.loc[temp_i, "ret_mdd_20d"]) /(1+ df_factor.loc[temp_i, "ret_mdd_120d"] )

            #################################################################################
            ### 20å¤©å’Œ120å¤©ä¸ªè‚¡ç›¸å¯¹äºä¸­ä¿¡ä¸€çº§çš„è¡Œä¸šå¸‚å€¼åŠ æƒè¶…é¢æ”¶ç›Šç‡ ret_alpha_ind_citic_1_20d,ret_alpha_ind_citic_1_120d
            # ä¸­ä¿¡ä¸€çº§è¡Œä¸šä»£ç  "citics_ind_code_s_1"çš„list = df_ret_accumu.index
            ind_list = list( df_factor["citics_ind_code_s_1"].drop_duplicates() ) 
            # 1,åˆ†è¡Œä¸šè®¡ç®—å¸‚å€¼åŠ æƒæ”¶ç›Šï¼Œ20å¤©å’Œ120å¤©
            # df_ret_accumu çš„indexå°±æ˜¯ä¸­ä¿¡ä¸€çº§è¡Œä¸šåˆ†ç±»æ•°å€¼ 10.0ï¼Œ11.0ï¼Œ...,70.0
            for temp_citic_1 in ind_list :
                print("temp_citic_1",temp_citic_1 )
                # åˆ†åˆ«è®¡ç®—ä¸ªè‚¡20å¤©å’Œ120å¤©çš„ç›¸å¯¹æ”¶ç›Šç‡
                df_factor_sub = df_factor[ df_factor["citics_ind_code_s_1"]== temp_citic_1 ]
                # è®¡ç®—è¡Œä¸šå†…çš„å¸‚å€¼åŠ æƒæ”¶ç›Šç‡
                ret_citic_1_20d = (df_factor_sub["ret_accumu_20d"]*df_factor_sub["S_DQ_MV"]).sum()/df_factor_sub["S_DQ_MV"].sum()
                ret_citic_1_120d = (df_factor_sub["ret_accumu_120d"]*df_factor_sub["S_DQ_MV"]).sum()/df_factor_sub["S_DQ_MV"].sum()
                print("temp_citic_1",temp_citic_1, round(ret_citic_1_20d,2),round(ret_citic_1_120d,2) )
                # è®¡ç®—ä¸ªè‚¡ç›¸å¯¹è¡Œä¸šçš„æ”¶ç›Šç‡
                df_factor.loc[df_factor_sub.index, "ret_alpha_ind_citic_1_20d" ] = df_factor.loc[df_factor_sub.index,"ret_accumu_20d"] -ret_citic_1_20d 
                df_factor.loc[df_factor_sub.index, "ret_alpha_ind_citic_1_120d" ] = df_factor.loc[df_factor_sub.index,"ret_accumu_120d"] -ret_citic_1_120d 
            
            #################################################################################
            ### 20å¤©å’Œ120å¤©ä¸ªè‚¡ç›¸å¯¹äºå…¨æ ·æœ¬ç©ºé—´å¸‚å€¼åŠ æƒçš„è¶…é¢æ”¶ç›Šç‡ ret_alpha_stockpool_mv_20d,ret_alpha_stockpool_mv_120d
            # è®¡ç®—å…¨æ ·æœ¬ç©ºé—´å¸‚å€¼åŠ æƒçš„æ”¶ç›Šç‡
            ret_stockpool_mv_20d = (df_factor["ret_accumu_20d"]*df_factor["S_DQ_MV"]).sum()/df_factor["S_DQ_MV"].sum()
            ret_stockpool_mv_120d = (df_factor["ret_accumu_120d"]*df_factor["S_DQ_MV"]).sum()/df_factor["S_DQ_MV"].sum()
            print("temp_citic_1",temp_citic_1, round(ret_stockpool_mv_20d ,2),round(ret_stockpool_mv_120d ,2) )
            # è®¡ç®—ä¸ªè‚¡ç›¸å¯¹å…¨æ ·æœ¬ç©ºé—´å¸‚å€¼åŠ æƒçš„æ”¶ç›Šç‡
            df_factor.loc[df_factor_sub.index, "ret_alpha_stockpool_mv_20d" ] = df_factor.loc[df_factor_sub.index,"ret_accumu_20d"] -ret_stockpool_mv_20d 
            df_factor.loc[df_factor_sub.index, "ret_alpha_stockpool_mv_120d" ] = df_factor.loc[df_factor_sub.index,"ret_accumu_120d"] -ret_stockpool_mv_120d

            #################################################################################
            ### 20å¤©å’Œ120å¤©ä¸ªè‚¡ç›¸å¯¹äºåŸºå‡†æŒ‡æ•°çš„è¶…é¢æ”¶ç›Šç‡ ret_alpha_index_bm_20d,ret_alpha_index_bm_120d
            # è®¡ç®—æŒ‡æ•°20ï¼Œ120å¤©ç´¯è®¡æ”¶ç›Šç‡ ï¼›å¯¹äºæŒ‡æ•°æ—¥è¡Œæƒ…ï¼šæ”¶ç›˜ä»·(ç‚¹)ï¼ŒS_DQ_CLOSEï¼›æ¶¨è·Œå¹…(%)ï¼ŒS_DQ_PCTCHANGE
            # temp_nä¸ªäº¤æ˜“æ—¥ï¼Œæ›¿ä»£Nï¼Œåˆ é™¤NaNæ‰€åœ¨è¡Œ
            temp_col = "S_DQ_CLOSE" 
            temp_df_close_adj = df_dates_stocks.loc[ :, code_index+"_"+temp_col]
            temp_df_close_adj = temp_df_close_adj.dropna( axis=0, how="all" ).to_frame()
            date_list_sub = temp_df_close_adj.index
            
            temp_close_pre_1  =  temp_df_close_adj.loc[date_list_sub[-1] ,code_index+"_"+temp_col]
            temp_close_pre_20 =  temp_df_close_adj.loc[date_list_sub[-20] ,code_index+"_"+temp_col] 
            temp_close_pre_N  =  temp_df_close_adj.loc[date_list_sub[0] ,code_index+"_"+temp_col]  
            
            index_ret_accumu_20d = temp_close_pre_1/ temp_close_pre_20 -1
            index_ret_accumu_120d = temp_close_pre_1/ temp_close_pre_N -1 
            print("Index retrun for 20days and 120days", index_ret_accumu_20d ,index_ret_accumu_120d  )

            df_factor[ "ret_alpha_index_bm_20d" ] =  df_factor["ret_accumu_20d"]  -index_ret_accumu_20d
            df_factor[ "ret_alpha_index_bm_120d" ] = df_factor["ret_accumu_120d"] -index_ret_accumu_120d

        obj_out ={}
        # è¾“å‡ºcol_list 
        obj_out["col_list_price_vol"] = col_list 
        obj_out["df_factor"] = df_factor

        return obj_out 

    def ashares_stock_price_vol_change(self,obj_in ):
        ### 3.2ï¼Œä¸ªè‚¡ï¼šåŒºé—´ä»·æ ¼å˜åŠ¨å’Œæ¶¨è·Œå¹…ï¼š
        '''
        Functionï¼š
        1ï¼Œè®¡ç®—è‚¡ç¥¨åŒºé—´æ¶¨è·Œå¹…
        2ï¼Œè®¡ç®—è‚¡ç¥¨åŒºé—´æˆäº¤é¢ã€æˆäº¤é‡
        3ï¼Œè®¡ç®—è‚¡ç¥¨åŒºé—´æƒæ¯å˜åŠ¨

        Input:obj_inè‡³å°‘åŒ…æ‹¬çš„å˜é‡ï¼š
        1,obj_index_consti["df_change"]ï¼šdataframe,colsè‡³å°‘åŒ…æ‹¬["wind_code"]
        2,obj_index_consti["date_pre"]:åŒºé—´å˜åŠ¨çš„èµ·å§‹æ—¥
        3,obj_index_consti["date"]ï¼šåŒºé—´å˜åŠ¨çš„ç»“æŸæ—¥
        
        outputï¼š
        df_index_consti["df_change"] 

        notes:
        1ï¼Œ"AShareEODPrices" é‡è¦æŒ‡æ ‡ï¼š
        S_DQ_CLOSE å½“æ—¥æ”¶ç›˜ä»·
        S_DQ_ADJPRECLOSE åå¤æƒå‰ä¸€æ—¥æ”¶ç›˜ä»·
        S_DQ_ADJCLOSE åå¤æƒå½“æ—¥æ”¶ç›˜ä»·
        S_DQ_ADJFACTORï¼šå¤æƒå› å­= S_DQ_ADJCLOSE/ S_DQ_CLOSE
        '''
        #
        temp_date_pre = obj_in["date_pre"]
        temp_date = obj_in["date"] 
        df_change = obj_in["df_change"]
        
        table_name = "AShareEODPrices" 
        
        col_list = ["CRNCY_CODE","S_DQ_CLOSE" ,"S_DQ_ADJCLOSE" ,"S_DQ_PCTCHANGE","S_DQ_AMOUNT","S_DQ_ADJFACTOR" ]
        obj_in["col_list"] = col_list

        for temp_col in col_list :
            df_change[temp_col ] = np.nan
        
        ### è·å–åˆå§‹æ—¥è¡Œæƒ…æ•°æ®ï¼š
        # æ³¨æ„ï¼šéƒ¨åˆ†è‚¡ç¥¨å¯èƒ½åœ¨æœˆåˆæœªä¸Šå¸‚ï¼
        file_name = "WDS_TRADE_DT_"+ str( temp_date_pre ) +"_ALL.csv"
        try :
            df0 = pd.read_csv( self.path_wind_wds +table_name+"\\"+ file_name  )
        except :
            df0 = pd.read_csv( self.path_wind_wds +table_name+"\\"+ file_name,encoding="gbk"  )
        # print(df0.columns )
        
        for temp_i in df_change.index :
            temp_code = df_change.loc[temp_i,  "wind_code" ]
            # find wind_code in df0
            df1 = df0[df0["S_INFO_WINDCODE"]==temp_code  ]
            if len( df1.index ) > 0 :
                temp_j = df1.index[0]
                for temp_col in col_list :
                    ###         
                    df_change.loc[temp_i,"pre_"+ temp_col ] = df0.loc[ temp_j,temp_col  ]
            else :
                print("No record for code ",temp_code  ) 
        
        ### è·å–æœ€è¿‘æ—¥è¡Œæƒ…æ•°æ®ï¼š
        # æ³¨æ„ï¼šéƒ¨åˆ†è‚¡ç¥¨å¯èƒ½åœ¨æœˆåˆæœªä¸Šå¸‚ï¼
        file_name = "WDS_TRADE_DT_"+ str( temp_date ) +"_ALL.csv"
        try :
            df0 = pd.read_csv( self.path_wind_wds +table_name+"\\"+ file_name  )
        except :
            df0 = pd.read_csv( self.path_wind_wds +table_name+"\\"+ file_name,encoding="gbk"  )
        # print(df0.head().T )        
        # notes:æœ‰å¯èƒ½å‡ºç°è‚¡ç¥¨é€€å¸‚çš„æƒ…å†µï¼Œä¾‹å¦‚20060831è¦å–æ—¥è¡Œæƒ…ï¼Œé‡åˆ°000406.SZäº20060406é€€å¸‚äº†ã€‚
        for temp_i in df_change.index :
            temp_code = df_change.loc[temp_i,  "wind_code" ]
            # find wind_code in df0 
            df1 = df0[df0["S_INFO_WINDCODE"]==temp_code  ]
            
            if len( df1.index ) > 0 :
                temp_j = df1.index[0]
                for temp_col in col_list :
                    df_change.loc[temp_i,"last_"+ temp_col ] = df0.loc[ temp_j,temp_col  ]
            else :
                #é€šå¸¸æ˜¯ç”±äºä¸­é€”ä¸Šå¸‚æˆ–è€…é€€å¸‚å¯¼è‡´çš„ï¼Œéœ€è¦ç‰¹å®šæ¨¡å—å¼•å…¥ä¸Šå¸‚æˆ–é€€å¸‚æ—¥æœŸï¼›é€€å¸‚æ—¥æœŸå½“æ—¥æ— äº¤æ˜“ï¼Œä½†å‰3å‘¨å°±çŸ¥é“ã€‚
                from data_io import data_io
                data_io_1 = data_io()
                obj_date = {}
                obj_date["wind_code"] = temp_code
                obj_date = data_io_1.get_list_delist_day(obj_date)
                # notes:é€€å¸‚æ—¥æœ‰å¯èƒ½æ˜¯nanï¼Œ floatç±»å‹ï¼›obj_date["delist_date"];obj_date["list_date"]
                # ä¾‹å­ï¼š20060421.0,å¯¹äº000406.SZ:é€€å¸‚æ—¥æœŸå½“æ—¥060421æ— äº¤æ˜“{060406æ˜¯æœ€åä¸€ä¸ªäº¤æ˜“æ—¥}ï¼Œä½†å‰3å‘¨å°±çŸ¥é“ã€‚
                
                # é€‰æ‹©æå‰15ä¸ªäº¤æ˜“æ—¥
                ### notes:å¯¹äº601988.SHåœ¨20050531ï¼Œobj_date["delist_date"] == np.nan æ²¡ç”¨
                if not np.isnan(obj_date["delist_date"] ) :
                    obj_date["date"] = obj_date["delist_date"]
                    obj_date = data_io_1.get_trading_days(obj_date)
                    delist_date =  str(int( obj_date["date_list_pre"][-15] ))
                    print("delist_date ",delist_date )
                    file_name_1 = "WDS_TRADE_DT_"+ str( delist_date) +"_ALL.csv"
                    try :
                        df_1 = pd.read_csv( self.path_wind_wds +table_name+"\\"+ file_name_1  )
                    except :
                        df_1 = pd.read_csv( self.path_wind_wds +table_name+"\\"+ file_name_1,encoding="gbk"  )

                    df_2 = df_1[df_1["S_INFO_WINDCODE"]==temp_code  ]

                    temp_j = df_2.index[0]
                    for temp_col in col_list :
                        df_change.loc[temp_i,"last_"+ temp_col ] = df_1.loc[ temp_j,temp_col  ] 

        ##########################################################################
        ### è®¡ç®—åŒºé—´å˜åŠ¨ï¼š
        # åŒºé—´æ¶¨è·Œå¹… s_change_adjclose 
        df_change["s_change_adjclose"] = df_change["last_"+"S_DQ_ADJCLOSE"]/df_change["pre_"+"S_DQ_ADJCLOSE"]-1
        # åˆ¤æ–­åŒºé—´å†…æ˜¯å¦æœ‰æƒæ¯å˜åŠ¨ï¼Œçœ‹å¤æƒå› å­æ˜¯å¦å˜åŠ¨ S_DQ_ADJFACTOR, close to 1.0 means nearly no change or quite small
        df_change["s_change_adjfacor"] = df_change["last_"+"S_DQ_ADJFACTOR"]/df_change["pre_"+"S_DQ_ADJFACTOR"] 
        
        obj_in["df_change"] = df_change
        

        return obj_in

    #################################################################################
    def ashares_stock_funda(self,obj_in) :
        # 4ï¼Œä¸ªè‚¡ï¼šå¸‚å€¼ï¼Œè´¢åŠ¡å’Œè´¢åŠ¡é¢„æµ‹æŒ‡æ ‡ï¼›
        '''
        obj_in["date_start"] = "20050501" 
        obj_in["table_name"] = "AShareEODDerivativeIndicator" 
        obj_in_stock["df_factor"] : dfç±»å‹,åŒ…æ‹¬äº†"wind_code","code_index","date",  

        ###
        notes:1,è‹¥"code_list"å­˜åœ¨ï¼Œåˆ™å¯¹è‚¡ç¥¨åˆ—è¡¨å–å€¼ï¼Œè‹¥ä¸å­˜åœ¨ï¼Œå¯¹å•ä¸ªä»£ç "code_stock"å–å€¼
            "code_list" in obj_in.keys()
        df_factoræ˜¯dfç±»å‹ï¼Œè‡³å°‘åŒ…æ‹¬"wind_code"è¿™ä¸€åˆ—
        '''
        date_start = obj_in["date_start"]
        date_list_new = [date for date in self.date_list if date<= int(date_start) ]        
        date_0 = date_list_new[-1]
        ### è·å–å¸‚å€¼å’Œå¸‚ç›ˆç‡ï¼ŒPEï¼ŒPBç­‰åŸºæœ¬æŒ‡æ ‡
        file_name = "WDS_TRADE_DT_"+ str(date_0) +"_ALL.csv"
        print("file_name ",file_name )
        df0 = pd.read_csv(self.path_wind_wds + obj_in["table_name"]+"\\"+ file_name  )
        df_cols = pd.read_csv(self.path_wind_wds + obj_in["table_name"]+"\\"+ "columns.csv"  )
        col_list = df_cols["0"].values
        # print("df0" ,df0.head().T )

        ### æŠŠæ—¥è¡ç”Ÿè¡Œæƒ…æ‰€æœ‰æŒ‡æ ‡éƒ½æ”¾å…¥df_factor 
        for temp_i in obj_in["df_factor"].index :
            temp_code = obj_in["df_factor"].loc[temp_i, "wind_code"] 

            df1= df0[ df0["S_INFO_WINDCODE"] == temp_code  ]
            
            if len( df1.index ) > 0 :
                temp_j = df1.index[0]
                for temp_col in col_list : 
                    obj_in["df_factor"].loc[temp_i, temp_col ] = df0.loc[temp_j, temp_col ]
        
        # obj_out = obj_in

        return  obj_in

    #################################################################################
    def ashares_stock_holder_events(self) :
        # 5ï¼Œä¸ªè‚¡ï¼šè‚¡ä¸œã€æœºæ„æŠ•èµ„è€…ã€æ”¶è´­å…¼å¹¶ç­‰äº‹ä»¶ï¼›
        
 









        return 1

    #################################################################################
    def ashares_fund_nav_port(self) :
        #6ï¼ŒåŸºé‡‘ã€æœºæ„æŒ‡æ ‡å’Œå› å­ï¼›



 









        return 1


#########################################################
### å› å­æ•°æ®åˆ†æ
class analysis_factor():
    # ç±»çš„åˆå§‹åŒ–æ“ä½œ
    def __init__(self):
        ### ç»§æ‰¿çˆ¶ç±»indicatorsçš„å®šä¹‰ï¼Œç­‰ä»·äº
        indicators.__init__(self)
        #################################################################################
        ### Initialization 

        sys.path.append( self.file_path_admin + "config\\")
        from config_data import config_data
        config_data_1 = config_data()
        self.obj_config = config_data_1.obj_config
        ### factor_model ç›®å½•ä½ç½®ï¼š
        # self.obj_config["dict"]["path_factor_model"] = dict_config["path_ciss_db"] +"factor_model\\"
        
        ### å¯¼å…¥date_list, å¯¼å…¥Aè‚¡å†å²äº¤æ˜“æ—¥æœŸ 
        df_dates = pd.read_csv(self.path_wind_adj + self.obj_config["dict"]["file_date_tradingday"]  )
        # type of date_list is numpy.int64
        self.date_list = list( df_dates["date"].values )
        self.date_list.sort()
        # month
        # df_dates = pd.read_csv(self.path_wind_adj + self.obj_config["dict"]["file_date_month"] )
        # # type of date_list is numpy.int64
        # self.date_list_m = list( df_dates["date"].values )
        # self.date_list_m.sort()
        # # quarter
        # df_dates = pd.read_csv(self.path_wind_adj + self.obj_config["dict"]["file_date_quarter"]   )
        # # type of date_list is numpy.int64
        # self.date_list_q = list( df_dates["date"].values )
        # self.date_list_q.sort()

        ### 
        #################################################################################

    def print_info(self):
        ### print all modules for current script
        print("æŒ‡æ ‡å’Œå› å­æ•°æ®å¤„ç†")
        print("cal_replace_extreme_value_mad |å¯¹å•ä¸ªæŒ‡æ ‡è®¡ç®—å‡å€¼å’ŒMADï¼Œå¹¶ä»£æ›¿æç«¯å€¼  ")
        print("indicator_data_adjust_zscore  |æŒ‡æ ‡æ•°æ®æ¸…æ´—è°ƒæ•´ï¼šå»å¼‚å¸¸å€¼å’Œç¼ºå¤±å€¼ï¼›æ ‡å‡†åŒ–") 
        print("indicator_indicator_orthogonal  |å› å­æŒ‡æ ‡æ­£äº¤å¤„ç†") 
        print("indicator_indicator_icir  |å› å­æŒ‡æ ‡ICå’ŒICIRè®¡ç®— ") 
        print("indicator_factor_weight |æ ¹æ®IC_IRçš„å€¼ï¼Œè®¡ç®—è‚¡ç¥¨iåœ¨å› å­k{1ï¼Œ2,...,K}ä¸Šçš„å› å­æƒé‡ ") 
        print("  ")
        print("group_mean_abcd3d_ana |### ä¸ªè‚¡abcd3dæŒ‡æ ‡å’Œå…¶ä»–æŒ‡æ ‡çš„æ ‡å‡†åŒ–åˆ†æ  ")
        print("market_status_abcd3d_ana |### å…¨å¸‚åœºã€è¡Œä¸šå†…ä¸ªè‚¡çš„åŠ¨é‡çŠ¶æ€åˆ†æï¼ŒåŸºäºå·²æœ‰çš„abcd3dæŒ‡æ ‡  ")
        
        return 1 

    def cal_replace_extreme_value_mad(self,df_factor,col_name,level=3 ):
        ### fanction:å¯¹å•ä¸ªæŒ‡æ ‡è®¡ç®—å‡å€¼å’ŒMADï¼Œå¹¶ä»£æ›¿æç«¯å€¼
        #å¯¹ df_factor[col_name] ç”¨MADæ–¹æ³•æ›¿ä»£å¼‚å¸¸å€¼
        # temp_median= np.median( code_list )
        # df_factor.to_csv("D:\\temp_df_factor.csv")
        
        temp_median = df_factor[col_name].median()
        temp_mad = np.median(  np.abs( df_factor[col_name] -temp_median  ) )

        #########################################################
        ### è®¡ç®—ä¸Šé™å’Œä¸‹é™å¹¶æ›¿ä»£æç«¯å€¼ï¼šupper_limit,lower_limit
        # æ„Ÿè§‰å¤§æ¦‚ç‡ä¸ä¼šè¶…è¿‡æç«¯å€¼
        upper_limit = temp_median+ level *1.4826*temp_mad
        lower_limit = temp_median- level *1.4826*temp_mad 

        ### å…ˆä¸ºæ‰€æœ‰å€¼å–ä¸‹é™å€¼ 
        df_factor[col_name+"_mad"] = 0.0

        # è‹¥æœ€å¤§æœ€å°å€¼æ²¡æœ‰è¶…è¿‡å°±ä¸éœ€è¦è°ƒæ•´
        list_adj = []

        for temp_i in df_factor.index : 
            temp_value = df_factor.loc[temp_i, col_name]
            if temp_value > upper_limit :
                df_factor.loc[temp_i, col_name+"_mad"] = upper_limit
            elif temp_value < lower_limit :
                df_factor.loc[temp_i, col_name+"_mad"] = lower_limit
            else :
                df_factor.loc[temp_i, col_name+"_mad"] =df_factor.loc[temp_i, col_name]  

        return df_factor

    def indicator_data_adjust_zscore(self,df_factor,col_list_to_zscore):
        ### æŒ‡æ ‡æ•°æ®æ¸…æ´—è°ƒæ•´ï¼šå»å¼‚å¸¸å€¼å’Œç¼ºå¤±å€¼ï¼›æ ‡å‡†åŒ–
        '''
        1,MADï¼ˆMedian Absolute Deviationç»å¯¹ä¸­ä½æ•°æ³•ï¼‰:
        æˆ‘ä»¬å°†å¤§äºğ‘€ğ‘’ğ‘‘ğ‘–ğ‘ğ‘›ğ‘“+3âˆ—1.4826âˆ—ğ‘€ğ´ğ·çš„å€¼æˆ–å°äºğ‘€ğ‘’ğ‘‘ğ‘–ğ‘ğ‘›ğ‘“âˆ’3âˆ—1.4826âˆ—ğ‘€ğ´ğ·çš„å€¼å®šä¹‰ä¸ºå¼‚å¸¸å€¼ã€‚
        åœ¨å¯¹å¼‚å¸¸å€¼åšå¤„ç†æ—¶ï¼Œéœ€è¦æ ¹æ®å› å­çš„å…·ä½“æƒ…å†µæ¥å†³å®š.ç¼ºå¤±ç‡å°äº20%çš„å› å­æ•°æ®
        ç”¨ä¸­ä¿¡ä¸€çº§è¡Œä¸šçš„ä¸­ä½æ•°ä»£æ›¿ï¼Œå½“ç¼ºå¤±ç‡å¤§äº20%æ—¶åˆ™åšå‰”é™¤å¤„ç†ã€‚
        notes:æ•°å€¼åˆ†å¸ƒåœ¨ï¼ˆÎ¼-2Ïƒ,Î¼+2Ïƒ)ä¸­çš„æ¦‚ç‡ä¸º0.9544ï¼›æ•°å€¼åˆ†å¸ƒåœ¨ï¼ˆÎ¼-3Ïƒ,Î¼+3Ïƒ)ä¸­çš„æ¦‚ç‡ä¸º0.9974ï¼›

        2,å› å­æ ‡å‡†åŒ–
        for factor k: miu_k = sum_1_n[ w_mv * X_ik_rawdata ];X_ik = (X_ik_rawdata-miu_k )/std_k
        å®šä¹‰ï¼šå›å½’ä¸­éœ€è¦å¯¹å•ä¸ªå› å­åœ¨æ¨ªæˆªé¢ä¸Šè¿›è¡Œæ ‡å‡†åŒ–ï¼Œä»è€Œå¾—åˆ°å‡å€¼ä¸º0ã€æ ‡å‡†å·®ä¸º1çš„æ ‡å‡†åŒ–å› å­ã€‚
        ä¸ºä¿è¯å…¨å¸‚åœºåŸºå‡†æŒ‡æ•°å¯¹æ¯ä¸ªé£æ ¼å› å­çš„æš´éœ²ç¨‹åº¦å‡ä¸º0ï¼Œæˆ‘ä»¬éœ€è¦å¯¹æ¯ä¸ªå› å­å‡å»å…¶å¸‚å€¼åŠ æƒå‡å€¼ï¼Œå†é™¤ä»¥å…¶æ ‡å‡†å·®ã€‚
        æ–¹æ³•æ¯”è¾ƒï¼šRankæ ‡å‡†åŒ–åçš„æ•°æ®ä¼šä¸¢å¤±åŸå§‹æ ·æœ¬çš„ä¸€äº›é‡è¦ä¿¡æ¯ï¼Œè¿™é‡Œæˆ‘ä»¬ä»ç„¶é€‰æ‹©Zå€¼æ ‡å‡†åŒ–ã€‚
        2.1ï¼Œå¼•å…¥æ¯ä¸ªå› å­å¯¹åº”è‚¡ç¥¨çš„å¸‚å€¼ï¼Œè®¡ç®—åŠ æƒå‡å€¼miu_k
        2.2ï¼Œè®¡ç®—(x_ik -miu_k)/ std_k
        ç”±äºä¸åŒå› å­åœ¨æ•°é‡çº§ä¸Šå­˜åœ¨å·®åˆ«ï¼Œä¾‹å¦‚è§„æ¨¡å› å­åœ¨å–å¯¹æ•°ä¹‹åä»ç„¶æ˜¯BPå› å­çš„æ•°åå€ç”šè‡³ç™¾å€ï¼Œå› æ­¤åœ¨å®é™…å›å½’ä¸­éœ€è¦å¯¹å•ä¸ªå› å­åœ¨æ¨ªæˆªé¢ä¸Šè¿›è¡Œæ ‡å‡†åŒ–ï¼Œä»è€Œå¾—åˆ°å‡å€¼ä¸º0ã€æ ‡å‡†å·®ä¸º1çš„æ ‡å‡†åŒ–å› å­ã€‚ä¸ºä¿è¯å…¨å¸‚åœºåŸºå‡†æŒ‡æ•°å¯¹æ¯ä¸ªé£æ ¼å› å­çš„æš´éœ²ç¨‹åº¦å‡ä¸º0ï¼Œæˆ‘ä»¬éœ€è¦å¯¹æ¯ä¸ªå› å­å‡å»å…¶å¸‚å€¼åŠ æƒå‡å€¼ï¼Œå†é™¤ä»¥å…¶æ ‡å‡†å·®ï¼Œè®¡ç®—æ–¹æ³•å¦‚ä¸‹ï¼š
        
        INPUT:
            1,df_factorï¼šdf,åŒ…æ‹¬è‚¡ç¥¨ä»£ç ã€è¡Œä¸šåˆ†ç±»ã€å¸‚å€¼ï¼›
            2,col_list_to_zscore:list,åŒ…æ‹¬äº†éœ€è¦è®¡ç®—æ ‡å‡†åˆ†å€¼zscoreçš„æŒ‡æ ‡ï¼Œ
        
        notes:
        1ï¼Œdf_factoré‡Œé»˜è®¤åŒ…å«è¡Œä¸šåˆ†ç±»å’Œå¸‚å€¼æŒ‡æ ‡ï¼›ä¾‹å¦‚ä¸­ä¿¡ä¸€çº§è¡Œä¸šå’Œæµé€šå¸‚å€¼æ•°æ®ï¼›
        ä¾‹å¦‚"citics_ind_code_s_1"ï¼ŒS_DQ_MV
        2ï¼Œå¸‚å€¼åŠ æƒè§„åˆ™ï¼šä»·é‡ç±»å› å­é€‰æ‹©æµé€šå¸‚å€¼åŠ æƒã€åŸºæœ¬é¢ç±»å› å­é€‰æ‹©æ€»å¸‚å€¼åŠ æƒ

        å‚è€ƒ å…‰å¤§è¯åˆ¸-20170410-å¤šå› å­ç³»åˆ—æŠ¥å‘Šä¹‹ä¸€ï¼šå› å­æµ‹è¯•æ¡†æ¶.pdf
        '''
        #########################################################
        ### 1ï¼Œå˜é‡è®¾ç½®
        code_list = df_factor["wind_code"]

        #########################################################
        ### fanction:å¯¹å•ä¸ªæŒ‡æ ‡è®¡ç®—å‡å€¼å’ŒMADï¼Œå¹¶ä»£æ›¿æç«¯å€¼
        def cal_replace_extreme_value_mad(df_factor,col_name ):
            #å¯¹ df_factor[col_name] ç”¨MADæ–¹æ³•æ›¿ä»£å¼‚å¸¸å€¼
            # temp_median= np.median( code_list )
            df_factor.to_csv("D:\\temp_df_factor.csv")
            temp_median = df_factor[col_name].median()
            temp_mad = np.median(  np.abs( df_factor[col_name] -temp_median  ) )

            #########################################################
            ### è®¡ç®—ä¸Šé™å’Œä¸‹é™å¹¶æ›¿ä»£æç«¯å€¼ï¼šupper_limit,lower_limit
            # æ„Ÿè§‰å¤§æ¦‚ç‡ä¸ä¼šè¶…è¿‡æç«¯å€¼
            upper_limit = temp_median+3*1.4826*temp_mad
            lower_limit = temp_median-3*1.4826*temp_mad 

            ### å…ˆä¸ºæ‰€æœ‰å€¼å–ä¸‹é™å€¼ 
            df_factor[col_name+"_mad"] = 0.0

            # è‹¥æœ€å¤§æœ€å°å€¼æ²¡æœ‰è¶…è¿‡å°±ä¸éœ€è¦è°ƒæ•´
            list_adj = []

            for temp_i in df_factor.index : 
                temp_value = df_factor.loc[temp_i, col_name]
                if temp_value > upper_limit :
                    df_factor.loc[temp_i, col_name+"_mad"] = upper_limit
                elif temp_value < lower_limit :
                    df_factor.loc[temp_i, col_name+"_mad"] = lower_limit
                else :
                    df_factor.loc[temp_i, col_name+"_mad"] =df_factor.loc[temp_i, col_name]  

            return df_factor
        
        #########################################################
        ### fanction:å¯¹å•ä¸ªæŒ‡æ ‡ï¼ˆå¸‚å€¼ä»¥å¤–ï¼‰è®¡ç®—å¸‚å€¼åŠ æƒåçš„å› å­æ ‡å‡†å·®
        def cal_zscore_mv_weighted(df_factor,col_name ,col_name_mv ):
            '''ä¸åŒå› å­åœ¨æ•°é‡çº§ä¸Šå­˜åœ¨å·®åˆ«ï¼Œä¾‹å¦‚è§„æ¨¡å› å­åœ¨å–å¯¹æ•°ä¹‹åä»ç„¶æ˜¯BPå› å­çš„æ•°åå€ç”šè‡³ç™¾å€ï¼Œå› æ­¤åœ¨
            å®é™…å›å½’ä¸­éœ€è¦å¯¹å•ä¸ªå› å­åœ¨æ¨ªæˆªé¢ä¸Šè¿›è¡Œæ ‡å‡†åŒ–ï¼Œä»è€Œå¾—åˆ°å‡å€¼ä¸º0ã€æ ‡å‡†å·®ä¸º1çš„æ ‡å‡†åŒ–å› å­ã€‚
            ä¸ºä¿è¯å…¨å¸‚åœºåŸºå‡†æŒ‡æ•°å¯¹æ¯ä¸ªé£æ ¼å› å­çš„æš´éœ²ç¨‹åº¦å‡ä¸º0ï¼Œæˆ‘ä»¬éœ€è¦å¯¹æ¯ä¸ªå› å­å‡å»å…¶å¸‚å€¼åŠ æƒå‡å€¼ï¼Œå†é™¤ä»¥å…¶æ ‡å‡†å·®ã€‚
            for factor k: miu_k = sum_1_n[ w_mv * X_ik_rawdata ];X_ik = (X_ik_rawdata-miu_k )/std_k
            
            notes:
            1,col_nameæ˜¯è¦è®¡ç®—æ ‡å‡†åˆ†çš„å› å­æŒ‡æ ‡ï¼Œcol_name_mvæ˜¯å¸‚å€¼åŠ æƒæŒ‡æ ‡
            2,zscoreæœ‰çš„æŒ‡æ ‡æ˜¯è¶Šå¤§è¶Šå¥½ï¼Œæ¯”å¦‚å‡€åˆ©æ¶¦ï¼›æœ‰çš„æŒ‡æ ‡è¶Šå°è¶Šå¥½ï¼Œæ¯”å¦‚PE
            3,ç”¨äºè®¡ç®—å¸‚å€¼åŠ æƒå‡å€¼å’Œmiu,stdçš„éƒ½åº”è¯¥æ˜¯ col_name +"_mad" çš„å€¼
            '''
            ### 1ï¼Œmiu_k = sum_1_n[ w_mv * X_ik_rawdata ]
            temp_miu = (df_factor[col_name +"_mad"]* df_factor[ "weight_"+col_name_mv ]).sum()

            ### 2,std_k,å¦‚æœç®€å•è®¡ç®—æ³¢åŠ¨ç‡æ˜¯å‡è®¾æ¯ä¸ªå…¬å¸éƒ½ä¸€æ ·ï¼Œç”¨å¸‚å€¼åŠ æƒå¯èƒ½æ›´èƒ½åæ˜ æ³¢åŠ¨ç‡å¯¹åº”çš„
            # æµåŠ¨æ€§æ€»ä½“ï¼ˆèµ„é‡‘èµ„é‡‘è§„æ¨¡ï¼‰å’ŒåŸºæœ¬é¢æ€»ä½“æƒ…å†µã€‚
            # é€šå¸¸åšæ³•æ˜¯ç›´æ¥ç”¨æ¯ä¸ªè‚¡ç¥¨çš„æŒ‡æ ‡å€¼è®¡ç®—stdï¼Œæˆ‘ä»¬è¿™é‡Œç›¸å½“äºç»Ÿä¸€ç”¨å¸‚å€¼åŠ æƒåçš„å€¼è®¡ç®—std
            # temp_std= df_factor[col_name +"_mad" ].std()
            temp_std= df_factor[ col_name +"_mad" ].std()

            ### 2,X_ik = (X_ik_rawdata-miu_k )/std_k
            df_factor["zscore_"+col_name ] =(df_factor[ col_name +"_mad" ] -temp_miu )/temp_std


            return df_factor

        #########################################################
        ### è®¡ç®—å¸‚å€¼æ ‡å‡†åˆ†ï¼ˆ=å› å­ï¼‰å’Œå¸‚å€¼åŠ æƒæƒé‡ | ä¾‹å¦‚æµé€šå¸‚å€¼æ ‡å‡†åˆ†"zscore_S_DQ_MV" å’Œ"weight_S_DQ_MV"
        # å¸‚å€¼åŠ æƒè§„åˆ™ï¼šä»·é‡ç±»å› å­é€‰æ‹©æµé€šå¸‚å€¼åŠ æƒã€åŸºæœ¬é¢ç±»å› å­é€‰æ‹©æ€»å¸‚å€¼åŠ æƒ
        col_name_mv = "S_DQ_MV"
        df_factor = self.cal_replace_extreme_value_mad(df_factor,col_name_mv )
        
        list_zscore = ["zscore_"+col_name_mv  ]
        temp_miu = df_factor[col_name_mv+"_mad"].mean()
        temp_std = df_factor[col_name_mv+"_mad"].std()
        df_factor["zscore_"+col_name_mv ] = ( df_factor[col_name_mv+"_mad"] - temp_miu )/temp_std
        # æ‰€æœ‰ä¸ªè‚¡çš„å¸‚å€¼åŠ æƒæƒé‡
        df_factor["weight_"+col_name_mv ] = df_factor[col_name_mv+"_mad"]/df_factor[col_name_mv+"_mad"].sum()

        #########################################################
        ### è®¡ç®—å„ä¸ªæŒ‡æ ‡çš„æ ‡å‡†åˆ†å€¼zscoreï¼Œ ä¾‹å¦‚å¸‚ç›ˆç‡(PE,TTM) "S_VAL_PE_TTM"
        # col_name = "S_VAL_PE_TTM"
        col_list_zscore = []
        for col_name in col_list_to_zscore :
            col_list_zscore = col_list_zscore + [ "zscore_"+col_name  ]
            list_zscore = list_zscore = ["zscore_"+col_name  ]
            # calculate mad value
            print("col_name ",col_name)
            df_factor = self.cal_replace_extreme_value_mad(df_factor,col_name )
            # calculate zscore value
            df_factor = cal_zscore_mv_weighted(df_factor,col_name ,col_name_mv)
            # notesï¼šzscoreæœ‰çš„æŒ‡æ ‡æ˜¯è¶Šå¤§è¶Šå¥½ï¼Œæ¯”å¦‚å‡€åˆ©æ¶¦ï¼›æœ‰çš„æŒ‡æ ‡è¶Šå°è¶Šå¥½ï¼Œæ¯”å¦‚PE

        obj_out = {}
        obj_out["df_factor"] =df_factor
        # åŒ…æ‹¬æ‰€æœ‰zscoreåˆ—åçš„column list
        obj_out["col_list_zscore"] = col_list_zscore

        return obj_out

    def indicator_indicator_orthogonal(self,obj_in ) :
        ### 2.4,å› å­åšå¯¹ç§°æ­£äº¤å¤„ç†
        '''
        INPUT:obj_in åŒ…æ‹¬ï¼š
        1,df_factorï¼šdf,åŒ…æ‹¬è‚¡ç¥¨ä»£ç ã€è¡Œä¸šåˆ†ç±»ã€å¸‚å€¼ï¼›
        2,col_list_zscore:list,åŒ…æ‹¬æ‰€æœ‰zscoreåˆ—åçš„column list  

        notes:
        1ï¼Œdf_factorçš„åˆ—æœ‰å¾ˆå¤šéå› å­é¡¹ï¼Œéœ€è¦å¯¹å…¶å–å› å­æŒ‡æ ‡çš„éƒ¨åˆ† col_list_to_zscore

        å› å­æ­£äº¤ factor SymmetricOrthogonalizationçš„æ­¥éª¤ï¼š
        file=å¤©é£è¯åˆ¸-ä¸“é¢˜æŠ¥å‘Šï¼šå› å­æ­£äº¤å…¨æ”»ç•¥â€”â€”ç†è®ºã€æ¡†æ¶ä¸å®è·µ.pdf;
        path=.\TOUYAN\å¤©é£è¯åˆ¸é‡‘å·¥åˆé›†\å¤šå› å­é€‰è‚¡ç³»åˆ—æŠ¥å‘Š\
        step1ï¼Œæ±‚tæ—¶é—´çŸ©é˜µdf1[è‚¡ç¥¨æ•°é‡Nï¼Œå› å­æ•°é‡K]çš„åæ–¹å·®çŸ©é˜µSigma= df1.cov(),é‡å çŸ©é˜µM=np.matrix( (N-1)*Sigma );
        step2,M_inv: æ±‚è§£S*S_t= inv(M) :çŸ©é˜µé€†çš„2ç§æ–¹æ³•ï¼š1ï¼ŒM_inv=np.matrix(M).I ;2,np.linalg.inv(M) 3,ä¼ªé€†-ä¸å¯é€†çš„æƒ…å†µï¼Œnp.linalg.pinv(M) ;
        step3ï¼šM_inv=U*D_inv*U', (A,B)=np.linalg.eig(M_inv), M_inv*A=B*Aï¼ŒBæ˜¯ç‰¹å¾å‘é‡çŸ©é˜µï¼ŒAæ˜¯ç‰¹å¾å€¼vectorï¼›
        D = np.dot( np.dot(np.linalg.inv(B),M_inv ),B ) ;çŸ©é˜µä¸­çš„æ¯ä¸ªæ•°å­—éƒ½ä¿ç•™ä¸¤ä½æœ‰æ•ˆæ•°å­— D2 = np.round( D,decimals=2,out=None )
        D_inv = np.linalg.inv( D )
        æ±‚ D_inv_sqrt,å¯¹å¯¹è§’çº¿ä¸Šçš„æ¯ä¸ªå€¼æ±‚å¹³æ–¹æ ¹çš„å€’æ•°ï¼Œå³ 1/sqrt( rambda1 )
        è¿‡åº¦çŸ©é˜µ S = U* D_inv_sqrt* U' *C , éœ€è¦æ±‚å¾—U å’Œ Cï¼›
        Uæ˜¯Mçš„ç‰¹å¾å‘é‡çŸ©é˜µï¼Œå³(V,U) =np.linalg.eig(M) å¯ä»¥æ±‚å¾— Uï¼›
        M_inv_sqrt = U * D_inv_sqrt * U'
        è§„èŒƒæ­£äº¤æ–¹æ³•ï¼šS=U* D_inv_sqrt* U' *C, { C=U} = U* D_inv_sqrt
        è§„èŒƒæ­£äº¤åçš„å› å­æ²¡æœ‰ç¨³å®šçš„å¯¹åº”å…³ç³»ã€‚è§„èŒƒæ­£äº¤å’ŒPCAä¸€æ ·ï¼Œåœ¨æ¯ä¸ªæˆªé¢ä¸Šä»¥æ–¹å·®æœ€å¤§çš„æ–¹å‘æ¥ç¡®å®šç¬¬ä¸€ä¸»æˆåˆ†ï¼Œä½†æ˜¯ä¸åŒæˆªé¢ä¸Šç¬¬ä¸€ä¸»æˆåˆ†çš„æ–¹å‘å¯èƒ½ä¼šå·®åˆ«å¾ˆå¤§ï¼Œè¿™æ ·å°±å¯¼è‡´ä¸åŒæˆªé¢ä¸Šä¸»æˆåˆ†åºåˆ—ä¸Šçš„å› å­æ²¡æœ‰ç¨³å®šçš„å¯¹åº”å…³ç³»[Qian 2007]ã€‚
        æ¯”è¾ƒåˆ†æï¼šæ–½å¯†ç‰¹æ­£äº¤ç”±äºåœ¨è¿‡å»è‹¥å¹²ä¸ªæˆªé¢ä¸Šéƒ½å–åŒæ ·çš„å› å­æ­£äº¤é¡ºåºï¼Œå› æ­¤æ­£äº¤åçš„å› å­å’ŒåŸå§‹å› å­æœ‰æ˜¾å¼çš„å¯¹åº”å…³ç³»ï¼Œè€Œè§„èŒƒæ­£äº¤åœ¨æ¯ä¸ªæˆªé¢ä¸Šé€‰å–çš„ä¸»æˆåˆ†æ–¹å‘å¯èƒ½ä¸ä¸€è‡´ï¼Œå¯¼è‡´æ­£äº¤å‰åçš„å› å­æ²¡æœ‰ç¨³å®šçš„å¯¹åº”å…³ç³»ã€‚ç”±æ­¤å¯è§ï¼Œæ­£äº¤åç»„åˆçš„æ•ˆæœï¼Œå¾ˆå¤§ä¸€éƒ¨åˆ†å–å†³äºæ­£äº¤å‰åå› å­æ˜¯å¦æœ‰ç¨³å®šçš„å¯¹åº”å…³ç³»ã€‚ br
        å¯¹ç§°æ­£äº¤ï¼ˆSymmetricOrthogonalizationï¼Œ[LÃ¶wdin1970, Schweinler1970]ï¼‰æ˜¯ä¸€ç§ç‰¹æ®Šçš„æ­£äº¤æ–¹æ³•ï¼Œå®ƒçš„è¿‡æ¸¡çŸ©é˜µæ˜¯å–CKÃ—K=ğ¼ğ¾Ã—ğ¾ï¼Œå³
        å¯¹ç§°æ­£äº¤ S = U* D_inv_sqrt* U'
        å¯¹ç§°æ­£äº¤æœ‰å‡ ä¸ªé‡è¦çš„æ€§è´¨[Klein 2013]ï¼š1.ç›¸å¯¹äºæ–½å¯†ç‰¹æ­£äº¤æ³•ï¼Œå¯¹ç§°æ­£äº¤ä¸éœ€è¦æä¾›æ­£äº¤æ¬¡åºï¼Œå¯¹æ¯ä¸ªå› å­æ˜¯å¹³ç­‰çœ‹å¾…çš„ï¼›
        2.åœ¨æ‰€æœ‰æ­£äº¤è¿‡æ¸¡çŸ©é˜µä¸­ï¼Œå¯¹ç§°æ­£äº¤åçš„çŸ©é˜µå’ŒåŸå§‹çŸ©é˜µçš„ç›¸ä¼¼æ€§æœ€å¤§ï¼Œå³æ­£äº¤å‰åçŸ©é˜µçš„è·ç¦»æœ€å°ã€‚æˆ‘ä»¬ç”¨å˜åŒ–å‰åçš„çŸ©é˜µçš„è·ç¦»ï¼ˆFrobenius èŒƒæ•°ï¼‰ğœ™æ¥è¡¡é‡å› å­æ­£äº¤å‰åå˜åŒ–çš„å¤§å°
        '''
        ### get specific df with N rows and K columns
        df_factor_ortho = obj_in["df_factor"].loc[:, obj_in["col_list_zscore"] ]
        df_factor_ortho.to_csv("D:\\df_factor_ortho_1.csv")
        index_list = df_factor_ortho.index
        col_list = columns=df_factor_ortho.columns

        N = len( df_factor_ortho.index  )
        K= len( obj_in["col_list_zscore"] )
        print("N,K ",N ,K )
        ### step1ï¼Œæ±‚tæ—¶é—´çŸ©é˜µdf1[è‚¡ç¥¨æ•°é‡Nï¼Œå› å­æ•°é‡K]çš„åæ–¹å·®çŸ©é˜µSigma= df1.cov(),é‡å çŸ©é˜µM=np.matrix( (N-1)*Sigma );
        df_factor_ortho_sigma = df_factor_ortho.cov()
        print( "df_factor_ortho_sigma ",df_factor_ortho_sigma  )

        matrix_m = np.matrix( (N-1)*df_factor_ortho_sigma )
        print("matrix_m",matrix_m )
        
        ### step2,M_inv
        # 20200404,34*34çš„æƒ…å†µä¸‹ï¼Œå‡ºç°matrix_m_invå…¨æ˜¯nançš„æƒ…å†µ
        # notes:å³ä¾¿æ±‚ä¼ªé€†çŸ©é˜µpinvä¹Ÿä¼šå‡ºç°numpy.linalg.LinAlgError: SVD did not converge æŠ¥é”™çš„æƒ…å†µ
        # åªèƒ½è€ƒè™‘å‡å°‘å› å­æ¢³ç†ï¼Œ34ä¸ªç¡®å®æ²¡å¿…è¦ã€‚
        # matrix_m_inv = np.linalg.inv( matrix_m )
        matrix_m_inv = np.linalg.pinv( matrix_m )
        print("matrix_m_inv",matrix_m_inv )

        ### step3ï¼š(A,B)=np.linalg.eig(M_inv)
        (A,B)=np.linalg.eig( matrix_m_inv )
        D = np.dot( np.dot(np.linalg.inv(B),matrix_m_inv ),B )
        print("Matrix D \n", D)
        D_inv = np.linalg.inv( D )
        # æ±‚ D_inv_sqrt,å¯¹å¯¹è§’çº¿ä¸Šçš„æ¯ä¸ªå€¼æ±‚å¹³æ–¹æ ¹çš„å€’æ•°ï¼Œå³ 1/sqrt( rambda1 )
        D_inv_sqrt = D_inv
        len_D = len( D_inv[0] ) # D_inv is n*n matrix 
        for i in range( len_D ) :
            D_inv_sqrt[i][i] = np.sqrt( D_inv_sqrt[i][i]  )

        # ä¸ºäº†é¿å…åç»­å‡ºç°nanå€¼ï¼Œå¯¹D_inv_sqrtæ±‚å¯¹è§’çŸ©é˜µï¼Œdiag(M)ä¼šè¿”å›vectorå½¢å¼çš„å¯¹è§’çº¿å€¼ï¼Œdiag(diag(M))ä¼šè¿”å›å¯¹è§’çº¿çŸ©é˜µ
        D_inv_sqrt = np.diag(np.diag(D_inv_sqrt))
        print("D_inv_sqrt diag \n", D_inv_sqrt )

        # Uæ˜¯Mçš„ç‰¹å¾å‘é‡çŸ©é˜µ
        (V,U) =np.linalg.eig( matrix_m )       

        # matrix to array
        # pd.DataFrame(U.A).to_csv("D:\\matrix_U.csv")
        # pd.DataFrame(D_inv_sqrt).to_csv("D:\\matrix_D_inv_sqrt.csv")
        U_trans = U.T
        # pd.DataFrame(U_trans.A).to_csv("D:\\matrix_U_trans.csv")
        # print("Debug== 1\n",  U * D_inv_sqrt )
        # print("Debug== 2\n",  D_inv_sqrt* U.T )
        # å¯¹ç§°æ­£äº¤ S = U* D_inv_sqrt* U'
        S = U * D_inv_sqrt  * U.T

        print("S \n",S  )
        # matrix S to array = S.A
        ### Calculate orthogonal factor array from df_factor * matrix S
        array_factor_ortho = np.dot( np.array(df_factor_ortho),S.A )

        ### Calculate new factor matrix    
        # notes:æ³¨æ„ï¼dataframe*dataframeæ˜¯åŸºäºå„è‡ªä½ç½®df2(x,y)ä¹˜df2(x,y)ä¸€ä¸€å¯¹åº”ï¼Œå’ŒçŸ©é˜µç›¸ä¹˜ä¸ä¸€æ ·
        # è¦å…ˆæŠŠdfè½¬æˆmatrixï¼Œå†è½¬å›df
        matrix_factor_ortho = np.matrix(array_factor_ortho) * S 
        df_factor_ortho=pd.DataFrame( matrix_factor_ortho.A , index =index_list,columns= col_list )

        df_factor_ortho.to_csv("D:\\df_factor_ortho_2.csv")  

        # Save to object      
        obj_in["df_factor_ortho"] = df_factor_ortho
        obj_in["matrix_S"] = S 

        return obj_in

    def indicator_indicator_icir(self,obj_factor):
        ###  2.6,è®¡ç®—å„å› å­6~12ä¸ªæœˆICIRï¼Œä½œä¸ºå„å› å­æƒé‡  
        # notes:åªæœ‰å½“ç´¯è®¡æœˆä»½count_monthå¤§äº3æ—¶æ‰è®¡ç®—å½“æœˆçš„IC_adjå€¼ï¼ŒIC_adjå€¼å¤§äº3ï¼Œä¹Ÿå°±æ˜¯ç´¯è®¡æœˆä»½å¤§äº6æ—¶æ‰è®¡ç®—ICIR;count_month >=6
        '''
        å¦‚ä½•ï¼Œ6è®¡ç®—å› å­ICIRï¼Ÿå‚è€ƒP7/23ï¼Œä¸œæ–¹é‡‘å·¥â€”â€”åŠ¨æ€æƒ…æ™¯å¤šå› å­Alphaæ¨¡å‹â€”â€”ã€Šå› å­é€‰è‚¡ç³»åˆ—ç ”ç©¶ä¹‹å…«ã€‹.pdf
        å¯¹äºè¿‡å»T(=12)æœŸè®¡ç®—å¾—åˆ°çš„ä¸ªè‚¡å› å­æš´éœ²X_i_kå’Œä¸ªè‚¡æœŸé—´è¶…é¢æ”¶ç›Šç‡rï¼Œè®¡ç®—é£é™©è°ƒæ•´IC:IC_adj=corr(X_i_k,r_alpha )
        Qs:IC_IRå¦‚ä½•è®¡ç®—ï¼ŸIR=ret_mean/ret_stdï¼ŒIC_IR=IC_miu/IC_std
        TODO:1,è®¡ç®—è¿‡å»12ä¸ªæœŸï¼ˆæœˆï¼‰æœ«çš„X_i_kã€ä¸ªè‚¡æ”¶ç›Šç‡ã€ä¸€çº§è¡Œä¸šå†…åŠ æƒæ”¶ç›Šç‡,å¯¹æ¯ä¸€æœŸè®¡ç®—ä¸ªè‚¡çš„IC_adj_s_tå’Œè¡Œä¸šçš„IC_adj_ind_tï¼›
        2ï¼Œå¯¹12æœŸçš„ä¸ªè‚¡çš„IC_adj_s_tå’Œè¡Œä¸šçš„IC_adj_ind_tå€¼,åˆ†åˆ«è®¡ç®—IC_miuï¼ŒIC_stdï¼Œè·å¾—IC_IRå€¼
        åˆ†æï¼šå¯¹äºæ»šåŠ¨æ—¶æœŸçš„è®¡ç®—ï¼Œè¿™ä¸ªå€¼åº”è¯¥åˆ†åˆ«å­˜å‚¨ï¼Œé¿å…é‡å¤è®¡ç®—ï¼›æœªæ¥åº”è¯¥å¯ä»¥é€‰æ‹©å‘¨æˆ–ä»»æ„æ—¶é—´åŒºé—´ï¼Œåªéœ€è¦ç»™å‡ºdate_list
        æ­¥éª¤æ¢³ç†ï¼š
        inputï¼š
        df_date_factor_returnåŒ…æ‹¬äº†æ‰€æœ‰ä¸ªè‚¡çš„20å¤©å’Œ120å¤©æ”¶ç›Šç‡ã€ä»¥åŠå„ä¸ªå› å­æŒ‡æ ‡å€¼
        
        notes:ç›¸å¯¹è¡Œä¸šçš„è¶…é¢æ”¶ç›Šç‡æœ‰ "ret_alpha_ind_citic_1_20d" ,"ret_alpha_ind_citic_1_120d" 
        ç›¸å¯¹äºåŸºå‡†æŒ‡æ•°çš„è¶…é¢æ”¶ç›Šç‡ ret_alpha_index_bm_20d,ret_alpha_index_bm_120d ;
        20å¤©å’Œ120å¤©ä¸ªè‚¡ç›¸å¯¹äºå…¨æ ·æœ¬ç©ºé—´å¸‚å€¼åŠ æƒçš„è¶…é¢æ”¶ç›Šç‡ ret_alpha_stockpool_mv_20d,ret_alpha_stockpool_mv_120d
        '''
        df_factor_ortho = obj_factor["df_factor_ortho"] 
        df_factor = obj_factor["df_factor"]
        
        count_month = obj_factor["count_month"] 
        # 20191129å‡ºç°è¿‡æŠ¥é”™ï¼Œ300142.SZ çš„æœ€åä¸€æœŸå€¼ä¸æ˜¯intï¼Œè€Œæ˜¯str || df3.astype('int64')
        temp_date = int( obj_factor["temp_date"] )
        df_date_factor_return = obj_factor["df_date_factor_return"] 
        
        # åˆ¤æ–­df_ic_ir æ˜¯å¦å­˜åœ¨
        if "df_ic_ir" in obj_factor.keys() :
            df_ic_ir  = obj_factor["df_ic_ir"]
        # else :
        #     df_ic_ir = pd.DataFrame( index= df_factor.index ,columns=["wind_code","date","ic_adj"] )

        #################################################
        ### 2.6.1,å¯¹æ¯åªä¸ªè‚¡ï¼Œè®¡ç®—ICå•æœŸçš„ICå€¼ï¼›ä¿¡æ¯ç³»æ•°ï¼ˆInformation Coefficientï¼Œç®€ç§° IC
        # Normal ICï¼Œå³æŸæ—¶ç‚¹æŸå› å­åœ¨å…¨éƒ¨è‚¡ç¥¨çš„æš´éœ²å€¼ä¸å…¶ä¸‹æœŸå›æŠ¥çš„æˆªé¢ç›¸å…³ç³»æ•°ï¼›RankICï¼Œå³æŸæ—¶ç‚¹æŸå› å­åœ¨å…¨éƒ¨è‚¡ç¥¨æš´éœ²å€¼æ’åä¸å…¶ä¸‹æœŸå›æŠ¥æ’åçš„æˆªé¢ç›¸å…³ç³»æ•°ã€‚
        # å› å­ IC è¡°é€€ï¼Œæ˜¯é€šè¿‡è§‚å¯Ÿéšç€æ»åæ—¶é—´çš„å»¶é•¿ï¼Œå› å­æœ‰æ•ˆæ€§é™ä½çš„é€Ÿåº¦ï¼›é€šè¿‡è§‚å¯ŸåŠè¡°æœŸçš„é•¿çŸ­åˆ¤æ–­è¯¥å› å­çš„ç¨³å®šæƒ…å†µã€‚
        if count_month >= 3 :
            df_ic_ir_temp = pd.DataFrame( index= df_factor.index ,columns=["wind_code","date","ic_adj"] )
            df_ic_ir_temp["date"] = temp_date
            for temp_f in obj_factor["col_list_zscore"] : 
                df_ic_ir_temp["ic_adj_"+ temp_f ] = np.nan

            for temp_i in df_factor.index :
                temp_code = df_factor.loc[temp_i,"wind_code"]
                df_ic_ir_temp.loc[temp_i,"wind_code"] = temp_code 
                # for every factor ,calculate
                for temp_f in obj_factor["col_list_zscore"] :
                    print("temp_f" ,temp_f ,temp_code+"_"+temp_f, temp_code+"_ret_alpha_ind_citic_1_120d" )
                    # notes:df_date_factor_returnçš„indexæ˜¯æ—¥æœŸåºåˆ—ï¼Œcolumnsæ˜¯æ¯ä¸ªè‚¡ç¥¨çš„å› å­æŒ‡æ ‡å€¼å’Œç›¸å¯¹è¡Œä¸šè¶…é¢æ”¶ç›Šå€¼
                    # å–æœ€è¿‘çš„count_monthä¸ªæœˆå’Œ12ä¸ªæœˆçš„è¾ƒå°å€¼æ±‚ç›¸å…³ç³»æ•°
                    temp_n = min( count_month, 12 )
                    index_list_sub =  df_date_factor_return.index[ -1*temp_n: ]
                    df_ic_ir_temp.loc[temp_i,"ic_adj_"+ temp_f ] = df_date_factor_return.loc[ index_list_sub ,[ temp_code+"_"+temp_f, temp_code+"_ret_alpha_ind_citic_1_120d"  ] ].corr().loc[ temp_code+"_"+temp_f, temp_code+"_ret_alpha_ind_citic_1_120d" ]
            
            if count_month == 3 :
                df_ic_ir = df_ic_ir_temp
                # é¢„å…ˆå¢åŠ ic_mean,ic_std,ic_irç›¸å…³çš„åˆ—
                for temp_f in obj_factor["col_list_zscore"] :
                    # temp_col = "ic_adj_mean_"+ temp_f
                    df_ic_ir[ "ic_adj_mean_"+ temp_f ] =np.nan
                    df_ic_ir[ "ic_adj_std_"+ temp_f ] =np.nan
                    df_ic_ir[ "ic_ir_"+ temp_f ] =np.nan

            else :
                df_ic_ir = df_ic_ir.append(df_ic_ir_temp,ignore_index=True)

        if  count_month >= 6 :
            temp_n = min( count_month, 12 )
            ### 2.6.2, å¯¹æ¯åªä¸ªè‚¡ï¼Œè®¡ç®—å¤šæœŸICè®¡ç®—ICIRå€¼ï¼Œic_ir= ic_miu/ic_std; Grinoldçš„ç®—æ³•æ˜¯IR=ic*sqrt(N)
            for temp_i in df_factor.index :
                temp_code = df_factor.loc[temp_i,"wind_code"]
                df_ic_ir_code = df_ic_ir[ df_ic_ir["wind_code"] == temp_code  ]
                # é»˜è®¤å‡åºascendingæ’åˆ—
                
                df_ic_ir_code =df_ic_ir_code.sort_values(by="date")
                # å–æœ€æ–°ä¸€æœŸçš„indexä½ç½®ï¼Œä¸ºå…¶èµ‹å€¼
                temp_index = df_ic_ir_code.index[-1]

                ### å¯¹äºä¸ªè‚¡çš„å†å²æ•°æ®ï¼Œåªå–æœ€è¿‘12æœŸçš„å€¼
                for temp_f in obj_factor["col_list_zscore"] :
                    print("temp_f" ,temp_f ,"ic_adj_"+ temp_f  )
                    df_ic_ir.loc[temp_index,  "ic_adj_mean_"+ temp_f ] = df_ic_ir_code.loc[-1*temp_n:, "ic_adj_"+ temp_f ].mean()
                    df_ic_ir.loc[temp_index,  "ic_adj_std_"+ temp_f ] = df_ic_ir_code.loc[-1*temp_n:, "ic_adj_"+ temp_f ].std()
                    df_ic_ir.loc[temp_index,  "ic_ir_"+ temp_f ] =df_ic_ir.loc[temp_index,  "ic_adj_mean_"+ temp_f ]/df_ic_ir.loc[temp_index,  "ic_adj_std_"+ temp_f ] 

        
        ### save df_ic_ir,count_month
        obj_factor["df_ic_ir"] = df_ic_ir
        
        return obj_factor 

    def indicator_factor_weight(self,obj_factor):
        ### æ ¹æ®IC_IRçš„å€¼ï¼Œè®¡ç®—è‚¡ç¥¨iåœ¨å› å­k{1ï¼Œ2,...,K}ä¸Šçš„å› å­æƒé‡
        ''' 
        æ•°æ®ä¿å­˜åœ¨ df_factor_weight,åˆ—åŒ…æ‹¬wind_codeå’Œdateï¼Œ

        å› å­æ”¶ç›Šå’Œä¸ªè‚¡æ”¶ç›Šçš„æŠ•å½±ï¼š sum{i,1,N}(W_i_k*r_i)=f_k, k=1,2,...,K
        1,å¯¹IC_irçš„æç«¯å€¼è¿›è¡Œå¤„ç†ï¼Œæ±‚zscoreï¼š
        1.1,æœ‰å¤§æœ‰å°ï¼Œå½“å‰å¯¼å‡ºçš„ic_iræ•°å€¼ï¼Œæœ‰"inf","-inf"ä¸¤ç§æ˜¯excelæ— æ³•è¯†åˆ«çš„ï¼Œä¹Ÿæœ‰æå¤§å€¼å’Œæå°å€¼éœ€è¦å‰”é™¤
        ç”±äºæœ‰æå¤§å€¼å’Œæå°å€¼ï¼Œå› å­æŒ‡æ ‡çš„ä¸­ä½æ•°åŸºæœ¬æ˜¯0.0ï¼Œä½†å‡å€¼ã€æœ€å¤§å€¼ã€æœ€å°å€¼ã€æ ‡å‡†å·®çš„æ•°å€¼éƒ½éå¸¸å¤§æ— æ³•ä½¿ç”¨ã€‚
        1.2,å…³äºæ•°å€¼ï¼šç»å¤§éƒ¨åˆ†è¿˜æ˜¯å¤„äº+1/-1ï¼Œå°¾éƒ¨è¶…è¿‡+5/-5çš„åŸºæœ¬åœ¨20ä¸ªä»¥å†…/100ä¸ªå€¼
        1.3ï¼ŒIC_IRå€¼è¶Šæ¥è¿‘1ï¼Œè¡¨ç¤ºå› å­å€¼å’Œç›¸å¯¹è¡Œä¸šçš„è¶…é¢æ”¶ç›Šè¶Šæ­£ç›¸å…³ï¼Œæˆ–è€…å’Œè¶…é¢æ”¶ç›Šçš„æ³¢åŠ¨ç‡è¶Šè´Ÿç›¸å…³ã€‚

        2,å¯¹äºä¸ªè‚¡iï¼Œåœ¨å› å­1~Kä¸Šçš„æš´éœ²ä¹‹å’Œä¸º1ï¼Œå› æ­¤å¯ä»¥ç”¨å†å²ICå‡å€¼æˆ–IC_IRå‡å€¼ç®—å‡ºä¸ªè‚¡åœ¨æ¯ä¸ªå› å­ä¸Šçš„æƒé‡w_s_i_k;
            w_s_i_k = IC_IR_i_k_miu / sum(k,1,K)( IC_IR_i_k_miu ) ,for i=1,2,...,N
        3ï¼Œå¯¹äºå¸‚åœºç»„åˆï¼Œåœ¨å› å­kä¸Šçš„æš´éœ²ä¸º IC_IR_k_miu / sum(k,1,K)( abs(IC_IR_k_miu ) )

        Input:df_ic_ir,code_index,temp_date
        Output:df_factor_weight
        '''
        # generate df =df_factor_weight
        index_i = 0 
        df_factor_weight= pd.DataFrame(index=[index_i], columns=["wind_code","date"] )
        
        # Import df_ic_ir 
        df_ic_ir = obj_factor["df_ic_ir"]
        temp_date = int( obj_factor["temp_date"] )

        date_list = list( df_ic_ir["date"].drop_duplicates() )
        date_list.sort() 

        # notes:éš¾ç‚¹ï¼šæ¯ä¸€æœŸçš„è‚¡ç¥¨ä»£ç listéƒ½ä¸ä¸€æ ·
        ### date_list_subæ˜¯è¦åŒ¹é…ä¹‹å‰æœ‰6~12ä¸ªæœˆè®°å½•çš„æœˆä»½ï¼Œä¹Ÿå°±æ˜¯count_month>=6
        
        ### å–æœ€è¿‘çš„6~12æœŸä½œä¸ºdate_pre_temp_date
        date_pre_temp_date = [ date for date in date_list if date<=temp_date]
        date_pre_temp_date.sort()
        date_pre_temp_date= date_pre_temp_date[-12:]

        df_ic_ir_date = df_ic_ir[ df_ic_ir["date"] ==temp_date  ]
        code_list = list( df_ic_ir["wind_code"].drop_duplicates() )

        for temp_code in code_list : 
            ### åªå–æœ€è¿‘çš„12æœŸ
            df_ic_ir_sub_s = df_ic_ir [ df_ic_ir["wind_code"] == temp_code  ]
            #
            df_ic_ir_sub_s= df_ic_ir_sub_s[ df_ic_ir_sub_s["date"].isin(date_pre_temp_date) ]
            
            ### 2ï¼Œå¯¹äºå•åªä¸ªè‚¡iï¼Œè®¡ç®—ä¸ªè‚¡iå•ä¸ªæŒ‡æ ‡ic_irå‡å€¼/ä¸ªè‚¡iæ‰€æœ‰æŒ‡æ ‡ic_irå‡å€¼ä¹‹å’Œ
            # temp_ic_ir = "ic_ir_ret_mdd_20d_120d"
            # æ±‚æ‰€æœ‰è‚¡ç¥¨åœ¨è¿‡å»T(6~12)æœŸçš„å¹³å‡å€¼çš„ç»å¯¹å€¼ä¹‹å’Œ
            
            df_factor_weight.loc[index_i,"wind_code"] = temp_code
            df_factor_weight.loc[index_i,"date"] = temp_date
            
            ic_ir_list= []
            sum_ic_ir_median = 0 
            # df_factor_weight
            for temp_ic_ir in df_ic_ir_sub_s.columns:
                if temp_ic_ir[:5] =="ic_ir" :
                    ic_ir_list= ic_ir_list + [ temp_ic_ir ]
                    df_ic_ir_sub_s = self.cal_replace_extreme_value_mad(df_ic_ir_sub_s,temp_ic_ir )
                    # ç”¨np.nanæ— æ³•è¯†åˆ«ï¼Œç”¨fillnaçš„æ–¹å¼
                    temp_median = df_ic_ir_sub_s[temp_ic_ir+"_mad"].fillna(0.0).median()
                    print("temp_median:" ,temp_median,type(temp_median) )
                    if not temp_median == np.nan :
                        df_factor_weight.loc[index_i, "f_w_"+temp_ic_ir ] = temp_median
                        sum_ic_ir_median = sum_ic_ir_median + abs(temp_median)
                    else :
                        df_factor_weight.loc[index_i, "f_w_"+temp_ic_ir ] = 0.0

            # æœ€åç»Ÿä¸€é™¤ä»¥å‡å€¼çš„ç»å¯¹å€¼ä¹‹å’Œ
            for temp_ic_ir in ic_ir_list:
                df_factor_weight.loc[index_i,"f_w_"+temp_ic_ir]= df_factor_weight.loc[index_i,"f_w_"+temp_ic_ir]/sum_ic_ir_median

            index_i = index_i + 1  

        ### save to ouput object 
        obj_factor["df_factor_weight"] = df_factor_weight

        return obj_factor

    def group_mean_abcd3d_ana(self,temp_i,df_abcd3d_ana, temp_df_ana) :
        ### ä¸ªè‚¡abcd3dæŒ‡æ ‡å’Œå…¶ä»–æŒ‡æ ‡çš„æ ‡å‡†åŒ–åˆ†æ 
        '''åˆ†åˆ«å¯¹åˆ†ç»„æœ¬èº«ã€åˆ†ç»„å†…ç»†åˆ†æˆé•¿ã€ä»·å€¼ç»„è®¡ç®—å„ä¸ªæŒ‡æ ‡        
        '''
        ##############################################################################
        ### å®šä¹‰æ ‡å‡†åŒ–çš„åˆ†ç»„æŒ‡æ ‡è®¡ç®—function  
        def group_mean_indicators(temp_i, temp_df_ana,df_abcd3d_ana ):
            ''' temp_i æ˜¯df_abcd3d_anaå¯¹åº”çš„è¡Œ,temp_df_anaæ˜¯ç‰¹å®šåˆ†ç»„
            '''
            ### è®¡ç®—æµé€šå¸‚å€¼åŠ æƒæŒ‡æ ‡
            print("temp_df_ana[ abcd3d ]",temp_df_ana  )
            df_abcd3d_ana.loc[temp_i,"abcd3d_ave_num" ] = temp_df_ana["abcd3d"].mean()
            temp_value = (temp_df_ana["abcd3d"]*temp_df_ana["S_DQ_MV"] ).sum()
            temp_value = temp_value / temp_df_ana["S_DQ_MV"].sum()
            # æµé€šå¸‚å€¼ï¼štemp_df_ana["abcd3d"]*temp_df_ana["S_DQ_MV"]
            df_abcd3d_ana.loc[temp_i,"abcd3d_ave_mvfloat" ] = temp_value
            temp_df_ana_sub = temp_df_ana[ temp_df_ana["abcd3d"]<=-4 ]
            df_abcd3d_ana.loc[temp_i,"abcd3d_pct_down" ] = temp_df_ana_sub["abcd3d"].count()/temp_df_ana["abcd3d"].count() 
            temp_df_ana_sub = temp_df_ana[ temp_df_ana["abcd3d"]>= 4 ]
            df_abcd3d_ana.loc[temp_i,"abcd3d_pct_up" ] = temp_df_ana_sub["abcd3d"].count()/temp_df_ana["abcd3d"].count() 
            # ä¿å­˜å½“æ—¥æ¶¨å¹…æœ€å¤§å’Œæˆäº¤é‡‘é¢æœ€å¤§çš„è‚¡ç¥¨
            if len( temp_df_ana.index ) > 1 :
                df_abcd3d_ana.loc[temp_i,"stock_max_pct" ] = temp_df_ana.loc[ temp_df_ana["S_DQ_CHANGE"].idxmax(),"S_INFO_WINDCODE" ]
                df_abcd3d_ana.loc[temp_i,"stock_max_amt" ] = temp_df_ana.loc[ temp_df_ana["S_DQ_AMOUNT"].idxmax(),"S_INFO_WINDCODE" ]

            ### è®¡ç®—æµé€šå¸‚å€¼åŠ æƒçš„ï¼Œè¿‡å»40å¤©æ”¶ç›˜ä»·æ‰€å¤„æœ€é«˜æœ€ä½ä»·çš„ç™¾åˆ†æ¯” | "close_pct_s_16"ï¼Œ"close_pct_s_40"ï¼Œ"close_pct_s_100"
            # temp_df_ana["temp"] = (temp_df_ana["close_pct_s_40"]*temp_df_ana["S_DQ_MV"] ).sum()
            # temp_df_ana["temp"] = temp_df_ana["temp"] / temp_df_ana["temp"].sum()
            # df_abcd3d_ana.loc[temp_i,"close_pct" ] = temp_df_ana["temp"].mean()
            # ç®€å•å¹³å‡
            df_abcd3d_ana.loc[temp_i,"close_pct" ] = temp_df_ana["close_pct_s_40"].mean()

            ### è®¡ç®—æ¶¨åœ+è·Œåœæ•°é‡ã€å†å²æ–°é«˜æ–°ä½| UP_DOWN_LIMIT_STATUS={-1,0,1};LOWEST_HIGHEST_STATUS={-1,0,1}
                        
            temp_df_ana[ "temp"] = temp_df_ana["UP_DOWN_LIMIT_STATUS"].apply(lambda x : x if x >0 else 0 )
            df_abcd3d_ana.loc[temp_i,"num_up_limit" ] = temp_df_ana[ "temp"].sum()
            temp_df_ana[ "temp"] = temp_df_ana["UP_DOWN_LIMIT_STATUS"].apply(lambda x : x if x <0 else 0 )
            df_abcd3d_ana.loc[temp_i,"num_down_limit" ] = temp_df_ana[ "temp"].sum()
            temp_df_ana[ "temp"] = temp_df_ana["LOWEST_HIGHEST_STATUS"].apply(lambda x : x if x >0 else 0 )
            df_abcd3d_ana.loc[temp_i,"num_new_high" ] = temp_df_ana[ "temp"].sum()
            temp_df_ana[ "temp"] = temp_df_ana["LOWEST_HIGHEST_STATUS"].apply(lambda x : x if x <0 else 0 )
            df_abcd3d_ana.loc[temp_i,"num_new_low" ] = temp_df_ana[ "temp"].sum()

            ### è®¡ç®—æµé€šå¸‚å€¼åŠ æƒçš„å¸‚ç›ˆç‡ S_VAL_PE_TTMï¼Œæœªæ¥1å¹´é¢„æµ‹å¸‚ç›ˆç‡ EST_PE_FY1ï¼›EST_PEG_FY1
            # notes:1,éƒ¨åˆ†æŒ‡æ ‡åªè¦†ç›–éƒ¨åˆ†è‚¡ç¥¨ ;2,æ€»å¸‚å€¼æ–¹æ³•ä¼šå¯¼è‡´é“¶è¡Œé‡Œçš„å·¥å•†é“¶è¡Œéæµé€šéƒ¨åˆ†è¢«è®¡å…¥å¯æŠ•èµ„ç©ºé—´ã€‚
            temp_df = temp_df_ana[ temp_df_ana["S_VAL_PE_TTM"]>0 ]
            temp_df[ "temp"] = temp_df["S_VAL_PE_TTM"]*temp_df["S_DQ_MV"]
            temp_value = temp_df["S_DQ_MV"].sum()
            df_abcd3d_ana.loc[temp_i ,"PE_ttm"] = temp_df[ "temp"].sum()/temp_value
            
            temp_df = temp_df_ana[ temp_df_ana["EST_PE_FY1"]>0 ]
            temp_df[ "temp"] = temp_df["EST_PE_FY1"]*temp_df["S_DQ_MV"]
            temp_value = temp_df["S_DQ_MV"].sum()
            df_abcd3d_ana.loc[temp_i ,"PE_fy1"] = temp_df[ "temp"].sum()/temp_value

            temp_df = temp_df_ana[ temp_df_ana["EST_PEG_FY1"]>0 ]
            temp_df[ "temp"] = temp_df["EST_PEG_FY1"]*temp_df["S_DQ_MV"]
            temp_value = temp_df["S_DQ_MV"].sum()
            df_abcd3d_ana.loc[temp_i ,"PEG_FY1"] = temp_df[ "temp"].sum()/temp_value

            return df_abcd3d_ana
        
        ##############################################################################
        ### åˆ†ç»„æœ¬èº« 
        df_abcd3d_ana = group_mean_indicators(temp_i, temp_df_ana,df_abcd3d_ana )

        ############################################################################## 
        ### è®¡ç®—æˆé•¿å’Œä»·å€¼åˆ†ç»„ï¼šä»·å€¼==PE==EST_PE_FY1;æˆé•¿==ROE==NET_PROFIT_YOY;EST_PE_FY1	EST_PEG_FY1
        # notes:å› ä¸ºæ²¡æœ‰roeæŒ‡æ ‡ï¼Œå…ˆç”¨PE/PEGä»£æ›¿ï¼Œå¯¹åº”çš„æ˜¯Gï¼Œå³å‡€åˆ©æ¶¦å¢é•¿ç‡ï¼›æ•°æ®æ–¹é¢200513å½“æ—¥3800åªè‚¡ç¥¨ä¸­æœ‰1710åªæœ‰æ•°æ®
        # 1710åªè‚¡ç¥¨PE/PEGå¹³å‡Gå€¼42%ï¼Œä¸­ä½æ•°25.8%ï¼›NET_PROFIT_YOYæŒ‡æ ‡æœ‰1890ä¸ªå€¼ï¼Œä½†1690ä¸ºæ­£ï¼Œä¸”å¹³å‡å€¼90.0ï¼Œä¸­ä½æ•°29.66%
        num_stock = len( temp_df_ana.index )
        ##############################################################################
        ### è®¡ç®—ä»·å€¼ç»„
        temp_i_value = str(temp_i) + "_value"
        df_abcd3d_ana.loc[temp_i_value,"group_type" ] = "value" # "value_growth"
        df_abcd3d_ana.loc[temp_i_value,"group_name" ] = "ä»·å€¼_" +str( df_abcd3d_ana.loc[temp_i,"group_name" ] )
        # temp_df_ana["EST_PE_FY1"] å–æœ‰æ­£å€¼çš„ã€æœ€å°çš„å‰50%,ä½†è¦æ³¨æ„ç¬¦åˆè¦æ±‚è‚¡ç¥¨æ•°é‡æ˜¯å¦å¤ªå°‘
        temp_df_ana_value = temp_df_ana[ temp_df_ana["EST_PE_FY1"] >=0.0 ]
        temp_df_ana_value = temp_df_ana_value.sort_values(by="EST_PE_FY1",ascending=True )
        
        if len( temp_df_ana_value.index) >= 2  :
            # è¶…è¿‡2åªæ‰å¯ä»¥å–å‰50%
            temp_len = round( float(len( temp_df_ana_value.index)) /2 )
            temp_df_ana_value= temp_df_ana_value.iloc[ :temp_len , : ]
            df_abcd3d_ana = group_mean_indicators(temp_i_value, temp_df_ana_value, df_abcd3d_ana )

        ##############################################################################
        ### è®¡ç®—æˆé•¿ç»„
        temp_i_growth = str(temp_i) + "_growth"
        df_abcd3d_ana.loc[temp_i_growth,"group_type" ] = "growth" # "value_growth"
        df_abcd3d_ana.loc[temp_i_growth,"group_name" ] = "æˆé•¿_" + str(df_abcd3d_ana.loc[temp_i,"group_name" ])
        # temp_df_ana["EST_PE_FY1"] å–æœ‰æ­£å€¼çš„ã€æœ€å°çš„å‰50%
        temp_df_ana_growth  = temp_df_ana[ temp_df_ana["EST_PE_FY1"] >=0.0 ]
        temp_df_ana_growth  = temp_df_ana_growth[ temp_df_ana_growth["EST_PEG_FY1"] >=0.0 ]
        temp_df_ana_growth["growth_fy1"] = temp_df_ana_growth["EST_PE_FY1"]/temp_df_ana_growth["EST_PEG_FY1"]
        
        # é™åºæ’åˆ—å–å‰50%
        temp_df_ana_growth= temp_df_ana_growth.sort_values(by="growth_fy1",ascending=False )
        if len(  temp_df_ana_growth.index)  >= 2  :
            # è¶…è¿‡2åªæ‰å¯ä»¥å–å‰50%
            temp_len = round( float(len( temp_df_ana_growth.index)) /2 )
            temp_df_ana_growth= temp_df_ana_growth.iloc[ :temp_len , : ]
            
            df_abcd3d_ana = group_mean_indicators(temp_i_growth, temp_df_ana_growth, df_abcd3d_ana ) 
        return df_abcd3d_ana 

    def market_status_abcd3d_ana(self,obj_ana) :
        ### å…¨å¸‚åœºã€è¡Œä¸šå†…ä¸ªè‚¡çš„åŠ¨é‡çŠ¶æ€åˆ†æï¼ŒåŸºäºå·²æœ‰çš„abcd3dæŒ‡æ ‡
        '''
        todo
        1,å¯¹å‡ ä¸ªæµé€šå¸‚å€¼ç»„å†…è¿›ä¸€æ­¥ç»†åˆ†ï¼šæˆé•¿ã€ä»·å€¼ï¼›
        2,åˆ›ä¸šæ¿å’Œç§‘åˆ›æ¿å†…åˆ’åˆ†æˆé•¿ã€ä»·å€¼ï¼›
        notes:æˆé•¿å’Œä»·å€¼è‹¥åˆ†åˆ«ç”¨roeå’Œpeï¼Œå®¹æ˜“é€ æˆè‚¡ç¥¨çš„é‡åˆï¼›
        3ï¼Œå¯¹æ¯ä¸ªè¡Œä¸šå†…åˆ†å¤§å°å¸‚å€¼-50%ã€æˆé•¿\ä»·å€¼-50%
        200602ï¼š å¢åŠ åŒºé—´æ”¶ç›˜ä»·æ‰€å¤„ä»·æ ¼ç™¾åˆ†æ¯”ç»Ÿè®¡ï¼š "close_pct_s_"+str(x) 
        tree:
        1,æ–°å»ºdf_abcd3d_ana,indexæ˜¯ä¸åŒçš„åˆ†ç»„ä¾‹å¦‚æ²ªæ·±300ã€åŒ»ç–—è¡Œä¸šç­‰ï¼Œcolumnsæ˜¯åˆ†ææŒ‡æ ‡
        1.1ï¼Œæˆäº¤é‡‘é¢ï¼šamt_1_300 :301_800,801_1800,1801_end
        1.2ï¼Œæµé€šå¸‚å€¼ï¼šmvfloat_1_300:æµé€šå¸‚å€¼å‰300ã€500ã€1000ï¼›
            AShareEODDerivativeIndicator{å½“æ—¥æµé€šå¸‚å€¼,S_DQ_MV;å½“æ—¥æ€»å¸‚å€¼,S_VAL_MV};
        1.2.1ï¼Œmvfloat_1_300ç­‰å†…åˆ†è¡Œä¸šé€‰è‚¡
        1.2.2ï¼Œmvfloat_1_300ç­‰å†…æˆé•¿æŒ‡æ ‡é€‰è‚¡
        1.3ï¼Œè¡Œä¸šï¼šind_citics_1_20 :ä¸­ä¿¡ä¸€çº§è¡Œä¸š
        1.4, å¸¸ç”¨æŒ‡æ ‡ï¼špe,pbï¼Œpcf, dps;
            AShareEODDerivativeIndicator{S_VAL_PE_TTM,å¸‚ç›ˆç‡(PE,TTM){è‹¥å‡€åˆ©æ¶¦<=0,åˆ™è¿”å›ç©º},
            å¸‚å‡€ç‡(PB),S_VAL_PB_NEW;
            å¸‚ç°ç‡(PCF,ç»è¥ç°é‡‘æµTTM)S_VAL_PCF_OCFTTM;è‚¡ä»·/æ¯è‚¡æ´¾æ¯,S_PRICE_DIV_DPS }
        1.5,æ»šåŠ¨é¢„æœŸç±»æŒ‡æ ‡ï¼š
            Windä¸€è‡´é¢„æµ‹ä¸ªè‚¡æ»šåŠ¨æŒ‡æ ‡ï¼ŒAShareConsensusRollingData{
            1ï¼ŒNET_PROFIT
            2ï¼Œå¸‚ç›ˆç‡,EST_PEï¼ŒFY0,FY1,FTTM,YOY,YOY2
            3ï¼ŒPEG,EST_PEG
            4,å¸‚å‡€ç‡,EST_PB
            5,æ¯è‚¡ç°é‡‘æµ,EST_CFPS
            6,åˆ©æ¶¦æ€»é¢,EST_TOTAL_PROFIT;è¥ä¸šåˆ©æ¶¦,EST_OPER_PROFIT;åŸºå‡†å¹´åº¦,BENCHMARK_YR   }
            ä¸­å›½Aè‚¡æŠ•èµ„è¯„çº§æ±‡æ€»,AShareStockRatingConsus{
            1,
            2ï¼Œ
            }
        1.6,å…¶ä»–æŒ‡æ ‡ï¼šæ¶¨åœå®¶æ•°ã€åˆ›æ–°é«˜ç­‰
            AShareEODDerivativeIndicator{
            æ¶¨è·ŒåœçŠ¶æ€,UP_DOWN_LIMIT_STATUS,1è¡¨ç¤ºæ¶¨åœ;0è¡¨ç¤ºéæ¶¨åœæˆ–è·Œåœ;-1è¡¨ç¤ºè·Œåœã€‚
            æœ€é«˜æœ€ä½ä»·çŠ¶æ€,LOWEST_HIGHEST_STATUS,1è¡¨ç¤ºæ˜¯å†å²æœ€é«˜æ”¶ç›˜ä»·;0è¡¨ç¤ºéå†å²æœ€é«˜ä»·æˆ–æœ€ä½ä»·;-1è¡¨ç¤ºæ˜¯å†å²æœ€ä½æ”¶ç›˜ä»·ã€‚    }
        notes: 
        '''
        ########################################################################
        ### Initialization 
        date_list = obj_ana["date_list"] 

        # from data_io import data_timing_abcd3d
        # data_timing_abcd3d_1 = data_timing_abcd3d()
        from data_io_pricevol_financial import data_pricevol_financial
        data_pricevol_financial_1 = data_pricevol_financial()

        ### å®šä¹‰æ ‡å‡†åŒ–çš„æ±‡æ€»åˆ†æ | def group_mean_abcd3d_ana(self,temp_i,df_abcd3d_ana, temp_df_ana) :
            
        ########################################################################
        ### abcd3då…¨å¸‚åœºä¸ªè‚¡åˆ†ç»„å’Œåˆ†è¡Œä¸šç»Ÿè®¡
        ### å¯¼å…¥è¡Œä¸šåˆ†ç±»åŠå¯¹åº”çš„ä¸­æ–‡
        path_ind_names = self.obj_config["dict"]["path_wind_adj"]
        df_ind_names = pd.read_csv(path_ind_names+ "ind_code_name.csv"  ,encoding="gbk" )
        path_output = self.obj_config["dict"]["path_ciss_db"]+"timing_abcd3d\\market_status_group\\"

        obj_data={}
        obj_data["dict"] ={}
        # for temp_date in date_list_post :
        for temp_date in date_list :
            # print("temp_date")

            obj_data["dict"]["date_start"] =  temp_date
            # obj_data["dict"]["date_start"] = input("Type in year start :from 20060104:") 
            
            ### å¯¼å…¥å†å²è¡Œæƒ…å’Œabcd3dæ•°æ®
            obj_data = data_pricevol_financial_1.import_data_ashare_change_amt( obj_data)
            df_mom_eod_prices = obj_data["df_mom_eod_prices"]
            num_stocks = len( df_mom_eod_prices.index )
            
            ########################################################################
            ### è·å–ä¸­ä¿¡ä¸€çº§è¡Œä¸šåˆ—è¡¨
            # [0.0, 10.0, 11.0, 12.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 30.0, 
            # 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 40.0, 41.0, 42.0, 50.0, 60.0, 61.0, 62.0, 63.0, 70.0]
            list_ind_code = obj_data["df_mom_eod_prices"]["ind_code"].drop_duplicates().to_list()
            list_ind_code.sort()
            list_ind_code_str = [ str(int(x)) for x in list_ind_code  ]

            # ########################################################################
            # ### å¯¼å…¥å¸‚å€¼ã€è´¢åŠ¡æŒ‡æ ‡ttm ã€é¢„æœŸæ•°æ®
            # obj_data = data_pricevol_financial_1.import_data_ashare_mv_fi_esti( obj_data)

            ########################################################################
            ### 1,åˆ†æç»Ÿè®¡åˆ†ç»„ï¼šdf_abcd3d_ana,indexæ˜¯ä¸åŒçš„åˆ†ç»„ä¾‹å¦‚æ²ªæ·±300ã€åŒ»ç–—è¡Œä¸šç­‰ï¼Œcolumnsæ˜¯åˆ†ææŒ‡æ ‡
            '''
            æ ¸å¿ƒåˆ†ç»„ï¼šæµé€šå¸‚å€¼å¤§ä¸­å°ï¼›
            å¤§ç±»æ¿å—ï¼šé‡‘èåœ°äº§40+41+42+43ã€å¿…é¡»æ¶ˆè´¹30+31+32+33+34ã€é£Ÿå“é¥®æ–™å†œæ—ç‰§æ¸”36+37ã€
                åŒ»ç–—35ã€ç”µå­60ã€é€šè®¯61ã€è®¡ç®—æœº62ã€ä¼ åª’63ã€ç”µåŠ›è®¾å¤‡æ–°èƒ½æº27
            '''
            list_rank=[ [1,300],[301,800],[801,1800],[1801,10000] ]
            ### 1.1ï¼Œæˆäº¤é‡‘é¢å…¨å¸‚åœºåˆ†ç»„ï¼šamt_1_300 :301_800,801_1800,1801_end
            list_index0 = ["all"]
            for word in ["amt","mvfloat","mvtotal"   ] :
                for temp_rank in list_rank :
                    word_para = word + "_1day_"+ str(temp_rank[0]) +"_"+ str(temp_rank[1])
                    list_index0 = list_index0 + [ word_para ]
            print( list_index0 )

            '''1,df_abcd3d_ana.columns:
            ç»„å†…ç®—æœ¯å¹³å‡å€¼:abcd3d_ave_num
            æµé€šå¸‚å€¼åŠ æƒå¹³å‡å€¼ã€abcd3d_ave_mvfloat
            æ•°å€¼ä¸º-6~-4,-3~3,4~6çš„åŠ æƒå æ¯” abcd3d_pct_down,abcd3d_pct_up
            "close_pct"ï¼šæ”¶ç›˜ä»·æ‰€å¤„è¿‡å»40å¤©ç™¾åˆ†æ¯”
            '''
            col_list=["abcd3d_ave_num","abcd3d_ave_mvfloat","abcd3d_pct_down","abcd3d_pct_up","group_type","close_pct"  ]
            ### å¢åŠ  æ¶¨è·Œåœã€æ–°é«˜æ–°ä½æ•°é‡ã€åŸºæœ¬è´¢åŠ¡
            col_list= col_list +["num_up_limit","num_down_limit","num_new_high","num_new_low" ]
            col_list= col_list +["PE_ttm","PE_fy1","PEG_FY1" ]

            df_abcd3d_ana=pd.DataFrame(index= list_index0, columns=col_list )
            
            ########################################################################
            ### 1.2ï¼Œç»Ÿè®¡å…¨å¸‚åœºæŒ‡æ ‡ï¼š"abcd3d",ä»¥åŠä¾æ®çš„çŸ­æœŸå’Œä¸­æœŸæŒ‡æ ‡ï¼šindi_short	indi_mid

            temp_i = "all"
            # "group_type"åˆ†ç»„ç±»å‹ï¼Œå¸‚åœº marketã€è¡Œä¸š industry;"group_name"åˆ†ç»„åç§°
            df_abcd3d_ana.loc[temp_i,"group_type" ] = "market"
            df_abcd3d_ana.loc[temp_i,"group_name" ] = "å…¨éƒ¨Aè‚¡"
            temp_df_ana = df_mom_eod_prices
            
            df_abcd3d_ana = self.group_mean_abcd3d_ana(temp_i,df_abcd3d_ana, temp_df_ana )
 
            ### åˆ›ä¸šæ¿è‚¡ç¥¨ "300" å¼€å¤´
            str_filter = "300"
            temp_df_ana = df_mom_eod_prices
            temp_df_ana["temp"] = temp_df_ana[ "S_INFO_WINDCODE"].apply(lambda code: 1 if code[:3]==str_filter else 0 )
            temp_df_ana = temp_df_ana[ temp_df_ana["temp"]==1 ]

            temp_i = "chinext"
            # "group_type"åˆ†ç»„ç±»å‹ï¼Œå¸‚åœº marketã€è¡Œä¸š industry;"group_name"åˆ†ç»„åç§°
            df_abcd3d_ana.loc[temp_i,"group_type" ] = "market"
            df_abcd3d_ana.loc[temp_i,"group_name" ] = "åˆ›ä¸šæ¿"

            df_abcd3d_ana = self.group_mean_abcd3d_ana(temp_i,df_abcd3d_ana, temp_df_ana )
            
            ### ç§‘åˆ›æ¿è‚¡ç¥¨ "688" å¼€å¤´
            str_filter = "688"
            temp_df_ana = df_mom_eod_prices
            temp_df_ana["temp"] = temp_df_ana[ "S_INFO_WINDCODE"].apply(lambda code: 1 if code[:3]==str_filter else 0 )
            temp_df_ana = temp_df_ana[ temp_df_ana["temp"]==1 ]

            temp_i = "star"
            # "group_type"åˆ†ç»„ç±»å‹ï¼Œå¸‚åœº marketã€è¡Œä¸š industry;"group_name"åˆ†ç»„åç§°
            df_abcd3d_ana.loc[temp_i,"group_type" ] = "market"
            df_abcd3d_ana.loc[temp_i,"group_name" ] = "ç§‘åˆ›æ¿"

            df_abcd3d_ana = self.group_mean_abcd3d_ana(temp_i,df_abcd3d_ana, temp_df_ana )

            ########################################################################
            ### 1.3ï¼Œç»Ÿè®¡åˆ†ç»„æŒ‡æ ‡ï¼š"abcd3d" 
            # notes:2006å¹´æ—¶Aè‚¡æ•°é‡çº¦1300ä¸ªï¼Œ2020çº¦3900ä¸ªã€‚é»˜è®¤1~300,301~800ä¸¤ç»„è‚¯å®šæœ‰
            list_rank=[ [1,300],[301,800],[801,1800],[1801,10000] ]

            ### å½“æ—¥æˆäº¤é‡‘é¢ï¼Œ"amt","S_DQ_AMOUNT"
            word ="amt" 

            df_mom_eod_prices = df_mom_eod_prices.sort_values(by="S_DQ_AMOUNT",ascending=False)
            for temp_rank in list_rank :
                # åˆ¤æ–­è‚¡ç¥¨æ•°é‡æ˜¯å¦è¶³å¤Ÿå¤§
                if num_stocks > temp_rank[0] :
                    # print( temp_rank[0],temp_rank[1] )
                    # for para in ["_1day_1_300","_1day_301_800","_1day_801_1800","_1day_1801_end"] :
                    temp_i = word + "_1day_"+ str(temp_rank[0]) +"_"+ str(temp_rank[1])
                    # "group_type"åˆ†ç»„ç±»å‹ï¼Œå¸‚åœº marketã€è¡Œä¸š industry;"group_name"åˆ†ç»„åç§°
                    df_abcd3d_ana.loc[temp_i,"group_type" ] = "market"
                    df_abcd3d_ana.loc[temp_i,"group_name" ] = "æˆäº¤é‡‘é¢_"+str(temp_rank[0]) +"_"+ str(temp_rank[1])
                    # notes:ç¬¬N~Mä¸ªå€¼åœ¨indexé‡Œå¯¹åº”çš„æ˜¯ N-1~M-1ä¸ªã€‚
                    temp_df_ana = df_mom_eod_prices.iloc[ temp_rank[0]-1:temp_rank[1] ,:]
                    df_abcd3d_ana = self.group_mean_abcd3d_ana(temp_i,df_abcd3d_ana, temp_df_ana )

            ### å½“æ—¥æµé€šå¸‚å€¼ï¼Œmvfloatï¼Œ'S_DQ_MV'
            word ="mvfloat"  
            df_mom_eod_prices = df_mom_eod_prices.sort_values(by="S_DQ_MV",ascending=False) 
            for temp_rank in list_rank :
                # åˆ¤æ–­è‚¡ç¥¨æ•°é‡æ˜¯å¦è¶³å¤Ÿå¤§
                if num_stocks > temp_rank[0] :
                    # print( temp_rank[0],temp_rank[1] )
                    # for para in ["_1day_1_300","_1day_301_800","_1day_801_1800","_1day_1801_end"] :
                    temp_i = word + "_1day_"+ str(temp_rank[0]) +"_"+ str(temp_rank[1])
                    # "group_type"åˆ†ç»„ç±»å‹ï¼Œå¸‚åœº marketã€è¡Œä¸š industry;"group_name"åˆ†ç»„åç§°
                    df_abcd3d_ana.loc[temp_i,"group_type" ] = "market"
                    df_abcd3d_ana.loc[temp_i,"group_name" ] = "æµé€šå¸‚å€¼_"+str(temp_rank[0]) +"_"+ str(temp_rank[1])

                    temp_df_ana = df_mom_eod_prices.iloc[ temp_rank[0]-1:temp_rank[1] ,:]

                    df_abcd3d_ana = self.group_mean_abcd3d_ana(temp_i,df_abcd3d_ana, temp_df_ana )

            ### å½“æ—¥æ€»å¸‚å€¼ï¼Œmvtotal,"S_VAL_MV"
            word ="mvtotal"  
            df_mom_eod_prices = df_mom_eod_prices.sort_values(by="S_VAL_MV",ascending=False) 
            for temp_rank in list_rank :
                # åˆ¤æ–­è‚¡ç¥¨æ•°é‡æ˜¯å¦è¶³å¤Ÿå¤§
                if num_stocks > temp_rank[0] :
                    # print( temp_rank[0],temp_rank[1] )
                    # for para in ["_1day_1_300","_1day_301_800","_1day_801_1800","_1day_1801_end"] :
                    temp_i = word + "_1day_"+ str(temp_rank[0]) +"_"+ str(temp_rank[1])
                    # "group_type"åˆ†ç»„ç±»å‹ï¼Œå¸‚åœº marketã€è¡Œä¸š industry;"group_name"åˆ†ç»„åç§°
                    df_abcd3d_ana.loc[temp_i,"group_type" ] = "market"
                    df_abcd3d_ana.loc[temp_i,"group_name" ] = "æ€»å¸‚å€¼_"+str(temp_rank[0]) +"_"+ str(temp_rank[1])

                    # notes:ç¬¬N~Mä¸ªå€¼åœ¨indexé‡Œå¯¹åº”çš„æ˜¯ N-1~M-1ä¸ªã€‚
                    temp_df_ana = df_mom_eod_prices.iloc[ temp_rank[0]-1:temp_rank[1] ,:]
                    df_abcd3d_ana = self.group_mean_abcd3d_ana(temp_i,df_abcd3d_ana, temp_df_ana )

            ### è®¡ç®—è¡Œä¸šåˆ†ç»„ï¼šlist_ind_codeä»¥åŠæ’åºè¿‡
            '''
            è¡Œä¸šåˆ†ç»„ï¼šæµé€šå¸‚å€¼å¤§ä¸­å°ï¼›å¤§ç±»æ¿å—ï¼šé‡‘èåœ°äº§40+41+42+43ã€å¿…é¡»æ¶ˆè´¹30+31+32+33+34ã€é£Ÿå“é¥®æ–™å†œæ—ç‰§æ¸”36+37ã€
                åŒ»ç–—35ã€ç”µå­60ã€é€šè®¯61ã€è®¡ç®—æœº62ã€ä¼ åª’63ã€ç”µåŠ›è®¾å¤‡æ–°èƒ½æº27
            list_ind_code_str = [ str(int(x)) for x in list_ind_code  ]
            '''
            for ind_code in list_ind_code :
                # code_str = list_ind_code_str( list_ind_code.index(ind_code) )
                code_str = str(int( ind_code ))
                # find code name in df_ind_names
                print( ind_code )
                # print(  df_ind_names["ind_code"].values )
                df_ind_names_sub = df_ind_names[ df_ind_names["ind_code"]== int(ind_code) ]
                if len(df_ind_names_sub.index ) > 0 :
                    ind_name = df_ind_names_sub["ind_name"].values[0]
                    df_mom_eod_prices_ind = df_mom_eod_prices[ df_mom_eod_prices["ind_code"]==ind_code ]

                    temp_i = ind_code
                    # "group_type"åˆ†ç»„ç±»å‹ï¼Œå¸‚åœº marketã€è¡Œä¸š industry;"group_name"åˆ†ç»„åç§°
                    df_abcd3d_ana.loc[temp_i,"group_type" ] = "industry"
                    df_abcd3d_ana.loc[temp_i,"group_name" ] = ind_name
                    
                    df_abcd3d_ana = self.group_mean_abcd3d_ana(temp_i,df_abcd3d_ana, df_mom_eod_prices_ind )
            
            ### Sort for exhibition ä¸ºå±•ç¤ºé˜…è¯»è¿›è¡Œæ’åº
            # group_list = ["market","industry","value_growth"] 
            group_list = ["market","industry","value","growth"]
            count_group = 0 
            for temp_group in group_list : 
                df_abcd3d_ana_sub = df_abcd3d_ana [df_abcd3d_ana["group_type"]==temp_group ]
                df_abcd3d_ana_sub=df_abcd3d_ana_sub.sort_values(by="abcd3d_ave_mvfloat",ascending=False)
                if count_group == 0 :
                    df_out = df_abcd3d_ana_sub
                    count_group = 1 
                else :
                    df_out = df_out.append(df_abcd3d_ana_sub)
            df_abcd3d_ana = df_out

            ### save to csv file 
            # D:\CISS_db\timing_abcd3d\market_status_group
            file_name = "abcd3d_market_ana_trade_dt_" + str(temp_date) + ".csv"
            print( df_abcd3d_ana)
            df_abcd3d_ana.to_csv(path_output + file_name ,encoding="gbk")

        ### 
        obj_ana["path_output"] = path_output
        obj_ana["file_name"] = file_name
        obj_ana["list_group_type"] = df_abcd3d_ana["group_type" ].to_list()
        obj_ana["list_group_name"] = df_abcd3d_ana["group_name" ].to_list()

        return obj_ana

#########################################################
### åŠ¨é‡æŒ‡æ ‡
class indicator_momentum():
    def __init__(self, indicator_name ):
        self.indicator_name = indicator_name


    # def load_quotes(self,quote_type='CN_day',sp_df,  config_IO,symbol_list,date_start,date_end) :


    def indi_mom_ma_all(self,code_head,code_df ):
        # Calculate for whole time series 

        # todo éœ€è¦è‡³å°‘ä¹‹å‰100å¤©çš„quotation æ•°æ®ã€‚
        # æ³¨æ„indexnumber =400çš„æ—¶é—´å¤„ï¼Œç”¨windows=40å»è®¡ç®—ï¼Œå¹³å‡å€¼å¯¹åº”çš„æ˜¯ï½›400-40+1~400ï½
        # è¯¥æ—¶é—´åº”è¯¥ä½¿ç”¨ index_num=399å¤„çš„å¹³å‡å€¼ã€‚
        # index_num={1:39},æ•°å€¼æ˜¯ NaN

        # å‡åº Ascendingï¼Œin case we do not have sorted data from csv file
        code_df= code_df.sort_values(['date'],ascending=True ) 

        # reference rC_Stra_MAX.py\AnalyticaData
        from config.config_indicator import config_indi_mom
        technical_ma = config_indi_mom('').technical_ma()
        # period of moving averagee
        ma_x = technical_ma['ma_x'] # [3,8,16,40,100]
        # relative value of price over moving average price 
        p_ma = technical_ma['p_ma'] # [0,0,0,0,0]
        # status of moving average 
        ma_up = technical_ma['ma_up'] # =[1,1,1,1,1] 
        # generate analitical parameters
        code_df_ana=code_df 
        code_df_ana['close_pre']  = code_df_ana['close' ].shift(1)
        code_df_ana['high_pre']  = code_df_ana['high' ].shift(1)
        code_df_ana['low_pre']  = code_df_ana['low' ].shift(1)
        code_df_ana['amt_pre']  = code_df_ana['amt' ].shift(1)
        code_df_ana['turn_pre']  = code_df_ana['turn' ].shift(1)
        columns_mom_ma = []
        for ma_x_i in ma_x :
            # Moving Average  , close_ma(x)
            temp_str= 'ma' + str( ma_x_i )
            
            code_df_ana[temp_str ] = pd.rolling_mean(code_df_ana['close' ],window= ma_x_i )
            # è¦é¿å…çœ‹ç©¿æœªæ¥ï¼Œå¯¹Tæ—¥çš„é¢„æµ‹åªèƒ½ç”¨T-1æ—¥ä½œä¸ºæœ€æ–°æ•°æ®
            # df..shift(1) means shift downward å‘ä¸‹å¹³ç§»1ä½ï¼Œç¬¬ä¸€ä½æ•°å€¼ä¼šå˜æˆNaN
            # df..shift(-1) means shift upnward å‘ä¸Šå¹³ç§»
            code_df_ana[temp_str+'_pre' ] = code_df_ana[temp_str ].shift(1)
            # å› ä¸ºè¦åšåˆ†æ¯ï¼Œreplace 0 or negative value to be large number or local maxã€‚
            def avoid_zero(x):
                if x <= 0 :
                    x= NaN
                return x
            code_df_ana[temp_str+'_pre' ] =code_df_ana[temp_str+'_pre'].map(lambda x: avoid_zero(x),na_action=None)
            # replace NaN with nearest values 
            code_df_ana[temp_str+'_pre' ] =code_df_ana[temp_str+'_pre'].fillna(method='ffill')
            columns_mom_ma = columns_mom_ma +[temp_str+'_pre']

            # 'P/MA8', pre close over close_ma(x)
            temp_str2= 'dif_P_MA' + str( ma_x_i )
            columns_mom_ma = columns_mom_ma +[temp_str2]
            # code_df_ana[temp_str2] = code_df_ana['close']/code_df_ana[temp_str+'_pre' ] 
            code_df_ana[temp_str2] = code_df_ana.apply(lambda x: x['close_pre']/x[temp_str+'_pre'],axis=1) 
            
            # 'MA3_up' close_ma(x)_T over close_ma(x)_T-1
            temp_str3= 'ma' + str( ma_x_i ) + '_up'
            columns_mom_ma = columns_mom_ma +[temp_str3]
            code_df_ana[temp_str3] =  code_df_ana[temp_str+'_pre' ].diff(1) 

            # 'P/H100' pre close over pre high value of past 100 days
            temp_str4= 'dif_P_H' + str( ma_x_i ) 
            code_df_ana[ temp_str4 ] = pd.rolling_mean(code_df_ana['high' ],window= ma_x_i )
            code_df_ana[temp_str4+'_pre' ] = code_df_ana[temp_str4 ].shift(1)
            columns_mom_ma = columns_mom_ma +[temp_str4+'_pre']

            # 'P/L100'
            temp_str5= 'dif_P_L' + str( ma_x_i ) 
            code_df_ana[ temp_str5 ] = pd.rolling_mean(code_df_ana['low' ],window= ma_x_i )
            code_df_ana[temp_str5 +'_pre' ] = code_df_ana[temp_str5 ].shift(1)
            columns_mom_ma = columns_mom_ma +[temp_str5+'_pre']
            
            # amt_ma(x)
            temp_str6= 'amt_ma_pre' + str( ma_x_i ) 
            columns_mom_ma = columns_mom_ma +[temp_str6 ]
            code_df_ana[temp_str6 ] = pd.rolling_mean(code_df_ana['amt_pre' ],window= ma_x_i )
            # amt/amt_ma(x)
            # temp_str7= 'amt_amt_ma_pre' + str( ma_x_i ) 
            # columns_mom_ma = columns_mom_ma +[temp_str7 ]
            # code_df_ana[temp_str7 ] = code_df_ana.apply(lambda x: x['amt_pre']/x[temp_str6+'_pre'],axis=1) 

            # turn_ma(x)
            # temp_str8= 'turn_ma_pre' + str( ma_x_i ) 
            # columns_mom_ma = columns_mom_ma +[temp_str8 ]
            # code_df_ana[temp_str8 ] = pd.rolling_mean(code_df_ana['turn_pre' ],window= ma_x_i )
            # turn/turn_ma(x)
            # temp_str9= 'turn_turn_ma_pre' + str( ma_x_i ) 
            # columns_mom_ma = columns_mom_ma +[temp_str9 ]
            # code_df_ana[temp_str9 ] = code_df_ana.apply(lambda x: x['turn_pre']/x[temp_str8+'_pre'],axis=1) 

 
        return code_df_ana

    def indi_mom_ma_1D(self,code_head,code_df ):
        # Calculate for given date 


        code_df_ana = 1 



        return code_df_ana






 















